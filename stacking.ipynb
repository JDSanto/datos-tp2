{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "\n",
    "df_train = pd.read_csv('./data/train_filtrado.csv')\n",
    "df_train['precio'] = np.log(df_train['precio'])\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "df_train['precio'] = np.log(df_train['precio'])\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.08363501292068126)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8988911725316586,\n",
    " 'bagging_freq': 22.0,\n",
    " 'feature_fraction': 0.6622442122619671,\n",
    " 'learning_rate': 0.16422725363286422,\n",
    " 'max_depth': 22.0,\n",
    " 'num_leaves': 180.0,\n",
    " 'test_size': 0.20892455926004772}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [0.20419658]\n",
      "    fold  1:  [0.20448883]\n",
      "    fold  2:  [0.20467907]\n",
      "    fold  3:  [0.20347208]\n",
      "    ----\n",
      "    MEAN:     [0.20420914] + [0.00045893]\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "[18:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9652\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2902\n",
      "[2]\tvalidation_0-mae:8.84998\n",
      "[3]\tvalidation_0-mae:7.6111\n",
      "[4]\tvalidation_0-mae:6.54574\n",
      "[5]\tvalidation_0-mae:5.62954\n",
      "[6]\tvalidation_0-mae:4.84163\n",
      "[7]\tvalidation_0-mae:4.164\n",
      "[8]\tvalidation_0-mae:3.58128\n",
      "[9]\tvalidation_0-mae:3.08017\n",
      "[10]\tvalidation_0-mae:2.64919\n",
      "[11]\tvalidation_0-mae:2.2786\n",
      "[12]\tvalidation_0-mae:1.95995\n",
      "[13]\tvalidation_0-mae:1.68608\n",
      "[14]\tvalidation_0-mae:1.45074\n",
      "[15]\tvalidation_0-mae:1.24861\n",
      "[16]\tvalidation_0-mae:1.07527\n",
      "[17]\tvalidation_0-mae:0.926672\n",
      "[18]\tvalidation_0-mae:0.799669\n",
      "[19]\tvalidation_0-mae:0.691068\n",
      "[20]\tvalidation_0-mae:0.598525\n",
      "[21]\tvalidation_0-mae:0.519562\n",
      "[22]\tvalidation_0-mae:0.452828\n",
      "[23]\tvalidation_0-mae:0.396278\n",
      "[24]\tvalidation_0-mae:0.348745\n",
      "[25]\tvalidation_0-mae:0.309748\n",
      "[26]\tvalidation_0-mae:0.276382\n",
      "[27]\tvalidation_0-mae:0.249055\n",
      "[28]\tvalidation_0-mae:0.22581\n",
      "[29]\tvalidation_0-mae:0.207025\n",
      "[30]\tvalidation_0-mae:0.191465\n",
      "[31]\tvalidation_0-mae:0.17927\n",
      "[32]\tvalidation_0-mae:0.168735\n",
      "[33]\tvalidation_0-mae:0.160495\n",
      "[34]\tvalidation_0-mae:0.153236\n",
      "[35]\tvalidation_0-mae:0.14696\n",
      "[36]\tvalidation_0-mae:0.141154\n",
      "[37]\tvalidation_0-mae:0.136644\n",
      "[38]\tvalidation_0-mae:0.132859\n",
      "[39]\tvalidation_0-mae:0.12915\n",
      "[40]\tvalidation_0-mae:0.126306\n",
      "[41]\tvalidation_0-mae:0.122692\n",
      "[42]\tvalidation_0-mae:0.12003\n",
      "[43]\tvalidation_0-mae:0.117479\n",
      "[44]\tvalidation_0-mae:0.115474\n",
      "[45]\tvalidation_0-mae:0.11369\n",
      "[46]\tvalidation_0-mae:0.11206\n",
      "[47]\tvalidation_0-mae:0.109737\n",
      "[48]\tvalidation_0-mae:0.107768\n",
      "[49]\tvalidation_0-mae:0.106643\n",
      "[50]\tvalidation_0-mae:0.104703\n",
      "[51]\tvalidation_0-mae:0.103382\n",
      "[52]\tvalidation_0-mae:0.102133\n",
      "[53]\tvalidation_0-mae:0.100906\n",
      "[54]\tvalidation_0-mae:0.100271\n",
      "[55]\tvalidation_0-mae:0.099227\n",
      "[56]\tvalidation_0-mae:0.097476\n",
      "[57]\tvalidation_0-mae:0.096108\n",
      "[58]\tvalidation_0-mae:0.094976\n",
      "[59]\tvalidation_0-mae:0.093508\n",
      "[60]\tvalidation_0-mae:0.092911\n",
      "[61]\tvalidation_0-mae:0.091837\n",
      "[62]\tvalidation_0-mae:0.090804\n",
      "[63]\tvalidation_0-mae:0.089882\n",
      "[64]\tvalidation_0-mae:0.088881\n",
      "[65]\tvalidation_0-mae:0.088295\n",
      "[66]\tvalidation_0-mae:0.087183\n",
      "[67]\tvalidation_0-mae:0.085845\n",
      "[68]\tvalidation_0-mae:0.084694\n",
      "[69]\tvalidation_0-mae:0.083729\n",
      "[70]\tvalidation_0-mae:0.082973\n",
      "[71]\tvalidation_0-mae:0.081974\n",
      "[72]\tvalidation_0-mae:0.080751\n",
      "[73]\tvalidation_0-mae:0.080129\n",
      "[74]\tvalidation_0-mae:0.079667\n",
      "[75]\tvalidation_0-mae:0.079195\n",
      "[76]\tvalidation_0-mae:0.078442\n",
      "[77]\tvalidation_0-mae:0.077718\n",
      "[78]\tvalidation_0-mae:0.076714\n",
      "[79]\tvalidation_0-mae:0.075984\n",
      "[80]\tvalidation_0-mae:0.075352\n",
      "[81]\tvalidation_0-mae:0.074847\n",
      "[82]\tvalidation_0-mae:0.074603\n",
      "[83]\tvalidation_0-mae:0.073972\n",
      "[84]\tvalidation_0-mae:0.073203\n",
      "[85]\tvalidation_0-mae:0.072508\n",
      "[86]\tvalidation_0-mae:0.071821\n",
      "[87]\tvalidation_0-mae:0.071103\n",
      "[88]\tvalidation_0-mae:0.070703\n",
      "[89]\tvalidation_0-mae:0.070357\n",
      "[90]\tvalidation_0-mae:0.069854\n",
      "[91]\tvalidation_0-mae:0.069518\n",
      "[92]\tvalidation_0-mae:0.069041\n",
      "[93]\tvalidation_0-mae:0.068669\n",
      "[94]\tvalidation_0-mae:0.068382\n",
      "[95]\tvalidation_0-mae:0.068137\n",
      "[96]\tvalidation_0-mae:0.067539\n",
      "[97]\tvalidation_0-mae:0.067329\n",
      "[98]\tvalidation_0-mae:0.066798\n",
      "[99]\tvalidation_0-mae:0.066264\n",
      "[100]\tvalidation_0-mae:0.065965\n",
      "[101]\tvalidation_0-mae:0.065627\n",
      "[102]\tvalidation_0-mae:0.065231\n",
      "[103]\tvalidation_0-mae:0.064562\n",
      "[104]\tvalidation_0-mae:0.063905\n",
      "[105]\tvalidation_0-mae:0.063389\n",
      "[106]\tvalidation_0-mae:0.063114\n",
      "[107]\tvalidation_0-mae:0.062383\n",
      "[108]\tvalidation_0-mae:0.062138\n",
      "[109]\tvalidation_0-mae:0.061863\n",
      "[110]\tvalidation_0-mae:0.061727\n",
      "[111]\tvalidation_0-mae:0.06147\n",
      "[112]\tvalidation_0-mae:0.061263\n",
      "[113]\tvalidation_0-mae:0.060911\n",
      "[114]\tvalidation_0-mae:0.060277\n",
      "[115]\tvalidation_0-mae:0.059703\n",
      "[116]\tvalidation_0-mae:0.059485\n",
      "[117]\tvalidation_0-mae:0.059417\n",
      "[118]\tvalidation_0-mae:0.058623\n",
      "[119]\tvalidation_0-mae:0.058272\n",
      "[120]\tvalidation_0-mae:0.05809\n",
      "[121]\tvalidation_0-mae:0.057746\n",
      "[122]\tvalidation_0-mae:0.05696\n",
      "[123]\tvalidation_0-mae:0.056598\n",
      "[124]\tvalidation_0-mae:0.05628\n",
      "[125]\tvalidation_0-mae:0.055966\n",
      "[126]\tvalidation_0-mae:0.055705\n",
      "[127]\tvalidation_0-mae:0.055425\n",
      "[128]\tvalidation_0-mae:0.054855\n",
      "[129]\tvalidation_0-mae:0.05461\n",
      "[130]\tvalidation_0-mae:0.05425\n",
      "[131]\tvalidation_0-mae:0.054168\n",
      "[132]\tvalidation_0-mae:0.053996\n",
      "[133]\tvalidation_0-mae:0.053457\n",
      "[134]\tvalidation_0-mae:0.053401\n",
      "[135]\tvalidation_0-mae:0.053353\n",
      "[136]\tvalidation_0-mae:0.053202\n",
      "[137]\tvalidation_0-mae:0.053074\n",
      "[138]\tvalidation_0-mae:0.052846\n",
      "[139]\tvalidation_0-mae:0.052255\n",
      "[140]\tvalidation_0-mae:0.051879\n",
      "[141]\tvalidation_0-mae:0.051723\n",
      "[142]\tvalidation_0-mae:0.05138\n",
      "[143]\tvalidation_0-mae:0.051092\n",
      "[144]\tvalidation_0-mae:0.051033\n",
      "[145]\tvalidation_0-mae:0.050853\n",
      "[146]\tvalidation_0-mae:0.050782\n",
      "[147]\tvalidation_0-mae:0.050421\n",
      "[148]\tvalidation_0-mae:0.050365\n",
      "[149]\tvalidation_0-mae:0.050014\n",
      "    fold  0:  [0.18974855]\n",
      "[18:02:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9625\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.288\n",
      "[2]\tvalidation_0-mae:8.84797\n",
      "[3]\tvalidation_0-mae:7.60947\n",
      "[4]\tvalidation_0-mae:6.54432\n",
      "[5]\tvalidation_0-mae:5.6283\n",
      "[6]\tvalidation_0-mae:4.84054\n",
      "[7]\tvalidation_0-mae:4.16308\n",
      "[8]\tvalidation_0-mae:3.58046\n",
      "[9]\tvalidation_0-mae:3.07945\n",
      "[10]\tvalidation_0-mae:2.6486\n",
      "[11]\tvalidation_0-mae:2.27811\n",
      "[12]\tvalidation_0-mae:1.95955\n",
      "[13]\tvalidation_0-mae:1.68575\n",
      "[14]\tvalidation_0-mae:1.45043\n",
      "[15]\tvalidation_0-mae:1.24833\n",
      "[16]\tvalidation_0-mae:1.07495\n",
      "[17]\tvalidation_0-mae:0.92639\n",
      "[18]\tvalidation_0-mae:0.799382\n",
      "[19]\tvalidation_0-mae:0.690858\n",
      "[20]\tvalidation_0-mae:0.598297\n",
      "[21]\tvalidation_0-mae:0.519526\n",
      "[22]\tvalidation_0-mae:0.452759\n",
      "[23]\tvalidation_0-mae:0.396361\n",
      "[24]\tvalidation_0-mae:0.348748\n",
      "[25]\tvalidation_0-mae:0.30978\n",
      "[26]\tvalidation_0-mae:0.276551\n",
      "[27]\tvalidation_0-mae:0.249405\n",
      "[28]\tvalidation_0-mae:0.226224\n",
      "[29]\tvalidation_0-mae:0.207376\n",
      "[30]\tvalidation_0-mae:0.191891\n",
      "[31]\tvalidation_0-mae:0.179205\n",
      "[32]\tvalidation_0-mae:0.168376\n",
      "[33]\tvalidation_0-mae:0.159873\n",
      "[34]\tvalidation_0-mae:0.152939\n",
      "[35]\tvalidation_0-mae:0.146997\n",
      "[36]\tvalidation_0-mae:0.141316\n",
      "[37]\tvalidation_0-mae:0.136717\n",
      "[38]\tvalidation_0-mae:0.132925\n",
      "[39]\tvalidation_0-mae:0.129293\n",
      "[40]\tvalidation_0-mae:0.125579\n",
      "[41]\tvalidation_0-mae:0.122498\n",
      "[42]\tvalidation_0-mae:0.120049\n",
      "[43]\tvalidation_0-mae:0.117528\n",
      "[44]\tvalidation_0-mae:0.115602\n",
      "[45]\tvalidation_0-mae:0.11359\n",
      "[46]\tvalidation_0-mae:0.111302\n",
      "[47]\tvalidation_0-mae:0.109774\n",
      "[48]\tvalidation_0-mae:0.108065\n",
      "[49]\tvalidation_0-mae:0.105936\n",
      "[50]\tvalidation_0-mae:0.104569\n",
      "[51]\tvalidation_0-mae:0.103549\n",
      "[52]\tvalidation_0-mae:0.101966\n",
      "[53]\tvalidation_0-mae:0.100387\n",
      "[54]\tvalidation_0-mae:0.099415\n",
      "[55]\tvalidation_0-mae:0.097393\n",
      "[56]\tvalidation_0-mae:0.095489\n",
      "[57]\tvalidation_0-mae:0.094355\n",
      "[58]\tvalidation_0-mae:0.093089\n",
      "[59]\tvalidation_0-mae:0.091896\n",
      "[60]\tvalidation_0-mae:0.090821\n",
      "[61]\tvalidation_0-mae:0.089863\n",
      "[62]\tvalidation_0-mae:0.088933\n",
      "[63]\tvalidation_0-mae:0.087595\n",
      "[64]\tvalidation_0-mae:0.086559\n",
      "[65]\tvalidation_0-mae:0.08589\n",
      "[66]\tvalidation_0-mae:0.085479\n",
      "[67]\tvalidation_0-mae:0.084186\n",
      "[68]\tvalidation_0-mae:0.0832\n",
      "[69]\tvalidation_0-mae:0.081457\n",
      "[70]\tvalidation_0-mae:0.080873\n",
      "[71]\tvalidation_0-mae:0.079883\n",
      "[72]\tvalidation_0-mae:0.078864\n",
      "[73]\tvalidation_0-mae:0.07782\n",
      "[74]\tvalidation_0-mae:0.077259\n",
      "[75]\tvalidation_0-mae:0.076341\n",
      "[76]\tvalidation_0-mae:0.075336\n",
      "[77]\tvalidation_0-mae:0.074385\n",
      "[78]\tvalidation_0-mae:0.073951\n",
      "[79]\tvalidation_0-mae:0.073638\n",
      "[80]\tvalidation_0-mae:0.072955\n",
      "[81]\tvalidation_0-mae:0.072264\n",
      "[82]\tvalidation_0-mae:0.071546\n",
      "[83]\tvalidation_0-mae:0.070701\n",
      "[84]\tvalidation_0-mae:0.069854\n",
      "[85]\tvalidation_0-mae:0.069396\n",
      "[86]\tvalidation_0-mae:0.068806\n",
      "[87]\tvalidation_0-mae:0.068389\n",
      "[88]\tvalidation_0-mae:0.067959\n",
      "[89]\tvalidation_0-mae:0.067202\n",
      "[90]\tvalidation_0-mae:0.066744\n",
      "[91]\tvalidation_0-mae:0.066499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\tvalidation_0-mae:0.066138\n",
      "[93]\tvalidation_0-mae:0.0659\n",
      "[94]\tvalidation_0-mae:0.065614\n",
      "[95]\tvalidation_0-mae:0.065119\n",
      "[96]\tvalidation_0-mae:0.064805\n",
      "[97]\tvalidation_0-mae:0.064612\n",
      "[98]\tvalidation_0-mae:0.063859\n",
      "[99]\tvalidation_0-mae:0.063547\n",
      "[100]\tvalidation_0-mae:0.063049\n",
      "[101]\tvalidation_0-mae:0.062387\n",
      "[102]\tvalidation_0-mae:0.061902\n",
      "[103]\tvalidation_0-mae:0.061447\n",
      "[104]\tvalidation_0-mae:0.060543\n",
      "[105]\tvalidation_0-mae:0.060296\n",
      "[106]\tvalidation_0-mae:0.05957\n",
      "[107]\tvalidation_0-mae:0.058843\n",
      "[108]\tvalidation_0-mae:0.0584\n",
      "[109]\tvalidation_0-mae:0.058186\n",
      "[110]\tvalidation_0-mae:0.057874\n",
      "[111]\tvalidation_0-mae:0.057553\n",
      "[112]\tvalidation_0-mae:0.057483\n",
      "[113]\tvalidation_0-mae:0.057082\n",
      "[114]\tvalidation_0-mae:0.05688\n",
      "[115]\tvalidation_0-mae:0.056533\n",
      "[116]\tvalidation_0-mae:0.055916\n",
      "[117]\tvalidation_0-mae:0.055684\n",
      "[118]\tvalidation_0-mae:0.055259\n",
      "[119]\tvalidation_0-mae:0.054773\n",
      "[120]\tvalidation_0-mae:0.054587\n",
      "[121]\tvalidation_0-mae:0.054225\n",
      "[122]\tvalidation_0-mae:0.053953\n",
      "[123]\tvalidation_0-mae:0.053477\n",
      "[124]\tvalidation_0-mae:0.053091\n",
      "[125]\tvalidation_0-mae:0.052668\n",
      "[126]\tvalidation_0-mae:0.052513\n",
      "[127]\tvalidation_0-mae:0.052285\n",
      "[128]\tvalidation_0-mae:0.051864\n",
      "[129]\tvalidation_0-mae:0.051711\n",
      "[130]\tvalidation_0-mae:0.051499\n",
      "[131]\tvalidation_0-mae:0.051376\n",
      "[132]\tvalidation_0-mae:0.051255\n",
      "[133]\tvalidation_0-mae:0.050963\n",
      "[134]\tvalidation_0-mae:0.050549\n",
      "[135]\tvalidation_0-mae:0.050178\n",
      "[136]\tvalidation_0-mae:0.049889\n",
      "[137]\tvalidation_0-mae:0.049671\n",
      "[138]\tvalidation_0-mae:0.049496\n",
      "[139]\tvalidation_0-mae:0.049367\n",
      "[140]\tvalidation_0-mae:0.049179\n",
      "[141]\tvalidation_0-mae:0.048859\n",
      "[142]\tvalidation_0-mae:0.048444\n",
      "[143]\tvalidation_0-mae:0.048361\n",
      "[144]\tvalidation_0-mae:0.048174\n",
      "[145]\tvalidation_0-mae:0.047595\n",
      "[146]\tvalidation_0-mae:0.047397\n",
      "[147]\tvalidation_0-mae:0.047229\n",
      "[148]\tvalidation_0-mae:0.04703\n",
      "[149]\tvalidation_0-mae:0.046678\n",
      "    fold  1:  [0.19005437]\n",
      "[18:04:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9632\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2885\n",
      "[2]\tvalidation_0-mae:8.84845\n",
      "[3]\tvalidation_0-mae:7.60986\n",
      "[4]\tvalidation_0-mae:6.54466\n",
      "[5]\tvalidation_0-mae:5.6286\n",
      "[6]\tvalidation_0-mae:4.84081\n",
      "[7]\tvalidation_0-mae:4.16329\n",
      "[8]\tvalidation_0-mae:3.5807\n",
      "[9]\tvalidation_0-mae:3.07966\n",
      "[10]\tvalidation_0-mae:2.64875\n",
      "[11]\tvalidation_0-mae:2.27823\n",
      "[12]\tvalidation_0-mae:1.95965\n",
      "[13]\tvalidation_0-mae:1.68589\n",
      "[14]\tvalidation_0-mae:1.45057\n",
      "[15]\tvalidation_0-mae:1.24852\n",
      "[16]\tvalidation_0-mae:1.07516\n",
      "[17]\tvalidation_0-mae:0.926644\n",
      "[18]\tvalidation_0-mae:0.799635\n",
      "[19]\tvalidation_0-mae:0.691059\n",
      "[20]\tvalidation_0-mae:0.598524\n",
      "[21]\tvalidation_0-mae:0.519589\n",
      "[22]\tvalidation_0-mae:0.452726\n",
      "[23]\tvalidation_0-mae:0.396151\n",
      "[24]\tvalidation_0-mae:0.348348\n",
      "[25]\tvalidation_0-mae:0.309022\n",
      "[26]\tvalidation_0-mae:0.275444\n",
      "[27]\tvalidation_0-mae:0.248234\n",
      "[28]\tvalidation_0-mae:0.225121\n",
      "[29]\tvalidation_0-mae:0.206193\n",
      "[30]\tvalidation_0-mae:0.190673\n",
      "[31]\tvalidation_0-mae:0.178495\n",
      "[32]\tvalidation_0-mae:0.168313\n",
      "[33]\tvalidation_0-mae:0.160141\n",
      "[34]\tvalidation_0-mae:0.152506\n",
      "[35]\tvalidation_0-mae:0.146399\n",
      "[36]\tvalidation_0-mae:0.140871\n",
      "[37]\tvalidation_0-mae:0.13645\n",
      "[38]\tvalidation_0-mae:0.132749\n",
      "[39]\tvalidation_0-mae:0.129411\n",
      "[40]\tvalidation_0-mae:0.126221\n",
      "[41]\tvalidation_0-mae:0.123476\n",
      "[42]\tvalidation_0-mae:0.121466\n",
      "[43]\tvalidation_0-mae:0.119312\n",
      "[44]\tvalidation_0-mae:0.117155\n",
      "[45]\tvalidation_0-mae:0.115163\n",
      "[46]\tvalidation_0-mae:0.112972\n",
      "[47]\tvalidation_0-mae:0.11099\n",
      "[48]\tvalidation_0-mae:0.109435\n",
      "[49]\tvalidation_0-mae:0.107755\n",
      "[50]\tvalidation_0-mae:0.106132\n",
      "[51]\tvalidation_0-mae:0.104158\n",
      "[52]\tvalidation_0-mae:0.102905\n",
      "[53]\tvalidation_0-mae:0.101276\n",
      "[54]\tvalidation_0-mae:0.099965\n",
      "[55]\tvalidation_0-mae:0.098084\n",
      "[56]\tvalidation_0-mae:0.096875\n",
      "[57]\tvalidation_0-mae:0.096131\n",
      "[58]\tvalidation_0-mae:0.094884\n",
      "[59]\tvalidation_0-mae:0.092974\n",
      "[60]\tvalidation_0-mae:0.092113\n",
      "[61]\tvalidation_0-mae:0.091187\n",
      "[62]\tvalidation_0-mae:0.090221\n",
      "[63]\tvalidation_0-mae:0.088979\n",
      "[64]\tvalidation_0-mae:0.088042\n",
      "[65]\tvalidation_0-mae:0.086944\n",
      "[66]\tvalidation_0-mae:0.086642\n",
      "[67]\tvalidation_0-mae:0.085002\n",
      "[68]\tvalidation_0-mae:0.083838\n",
      "[69]\tvalidation_0-mae:0.082473\n",
      "[70]\tvalidation_0-mae:0.082064\n",
      "[71]\tvalidation_0-mae:0.081002\n",
      "[72]\tvalidation_0-mae:0.079973\n",
      "[73]\tvalidation_0-mae:0.079104\n",
      "[74]\tvalidation_0-mae:0.078407\n",
      "[75]\tvalidation_0-mae:0.077788\n",
      "[76]\tvalidation_0-mae:0.077173\n",
      "[77]\tvalidation_0-mae:0.076573\n",
      "[78]\tvalidation_0-mae:0.075639\n",
      "[79]\tvalidation_0-mae:0.074897\n",
      "[80]\tvalidation_0-mae:0.074377\n",
      "[81]\tvalidation_0-mae:0.073921\n",
      "[82]\tvalidation_0-mae:0.072723\n",
      "[83]\tvalidation_0-mae:0.071687\n",
      "[84]\tvalidation_0-mae:0.070887\n",
      "[85]\tvalidation_0-mae:0.070293\n",
      "[86]\tvalidation_0-mae:0.069555\n",
      "[87]\tvalidation_0-mae:0.069147\n",
      "[88]\tvalidation_0-mae:0.068643\n",
      "[89]\tvalidation_0-mae:0.068193\n",
      "[90]\tvalidation_0-mae:0.067975\n",
      "[91]\tvalidation_0-mae:0.067709\n",
      "[92]\tvalidation_0-mae:0.067419\n",
      "[93]\tvalidation_0-mae:0.066824\n",
      "[94]\tvalidation_0-mae:0.066009\n",
      "[95]\tvalidation_0-mae:0.065437\n",
      "[96]\tvalidation_0-mae:0.065129\n",
      "[97]\tvalidation_0-mae:0.064803\n",
      "[98]\tvalidation_0-mae:0.064059\n",
      "[99]\tvalidation_0-mae:0.063304\n",
      "[100]\tvalidation_0-mae:0.062596\n",
      "[101]\tvalidation_0-mae:0.062322\n",
      "[102]\tvalidation_0-mae:0.061987\n",
      "[103]\tvalidation_0-mae:0.061623\n",
      "[104]\tvalidation_0-mae:0.06137\n",
      "[105]\tvalidation_0-mae:0.061145\n",
      "[106]\tvalidation_0-mae:0.060981\n",
      "[107]\tvalidation_0-mae:0.060733\n",
      "[108]\tvalidation_0-mae:0.060362\n",
      "[109]\tvalidation_0-mae:0.060008\n",
      "[110]\tvalidation_0-mae:0.059575\n",
      "[111]\tvalidation_0-mae:0.059024\n",
      "[112]\tvalidation_0-mae:0.058825\n",
      "[113]\tvalidation_0-mae:0.058387\n",
      "[114]\tvalidation_0-mae:0.058174\n",
      "[115]\tvalidation_0-mae:0.057953\n",
      "[116]\tvalidation_0-mae:0.057412\n",
      "[117]\tvalidation_0-mae:0.057221\n",
      "[118]\tvalidation_0-mae:0.056509\n",
      "[119]\tvalidation_0-mae:0.056091\n",
      "[120]\tvalidation_0-mae:0.055938\n",
      "[121]\tvalidation_0-mae:0.055581\n",
      "[122]\tvalidation_0-mae:0.055128\n",
      "[123]\tvalidation_0-mae:0.054884\n",
      "[124]\tvalidation_0-mae:0.054683\n",
      "[125]\tvalidation_0-mae:0.054505\n",
      "[126]\tvalidation_0-mae:0.054348\n",
      "[127]\tvalidation_0-mae:0.05408\n",
      "[128]\tvalidation_0-mae:0.053497\n",
      "[129]\tvalidation_0-mae:0.053234\n",
      "[130]\tvalidation_0-mae:0.052757\n",
      "[131]\tvalidation_0-mae:0.052344\n",
      "[132]\tvalidation_0-mae:0.052187\n",
      "[133]\tvalidation_0-mae:0.05186\n",
      "[134]\tvalidation_0-mae:0.05146\n",
      "[135]\tvalidation_0-mae:0.050826\n",
      "[136]\tvalidation_0-mae:0.05043\n",
      "[137]\tvalidation_0-mae:0.050055\n",
      "[138]\tvalidation_0-mae:0.0499\n",
      "[139]\tvalidation_0-mae:0.049492\n",
      "[140]\tvalidation_0-mae:0.049248\n",
      "[141]\tvalidation_0-mae:0.049111\n",
      "[142]\tvalidation_0-mae:0.04862\n",
      "[143]\tvalidation_0-mae:0.048033\n",
      "[144]\tvalidation_0-mae:0.047757\n",
      "[145]\tvalidation_0-mae:0.047299\n",
      "[146]\tvalidation_0-mae:0.047257\n",
      "[147]\tvalidation_0-mae:0.046829\n",
      "[148]\tvalidation_0-mae:0.046661\n",
      "[149]\tvalidation_0-mae:0.046441\n",
      "    fold  2:  [0.18953391]\n",
      "[18:05:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9626\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.288\n",
      "[2]\tvalidation_0-mae:8.84801\n",
      "[3]\tvalidation_0-mae:7.60951\n",
      "[4]\tvalidation_0-mae:6.54432\n",
      "[5]\tvalidation_0-mae:5.62831\n",
      "[6]\tvalidation_0-mae:4.84052\n",
      "[7]\tvalidation_0-mae:4.16309\n",
      "[8]\tvalidation_0-mae:3.58048\n",
      "[9]\tvalidation_0-mae:3.07948\n",
      "[10]\tvalidation_0-mae:2.64863\n",
      "[11]\tvalidation_0-mae:2.2781\n",
      "[12]\tvalidation_0-mae:1.95957\n",
      "[13]\tvalidation_0-mae:1.68577\n",
      "[14]\tvalidation_0-mae:1.45046\n",
      "[15]\tvalidation_0-mae:1.2484\n",
      "[16]\tvalidation_0-mae:1.07505\n",
      "[17]\tvalidation_0-mae:0.926537\n",
      "[18]\tvalidation_0-mae:0.799553\n",
      "[19]\tvalidation_0-mae:0.691001\n",
      "[20]\tvalidation_0-mae:0.598447\n",
      "[21]\tvalidation_0-mae:0.519601\n",
      "[22]\tvalidation_0-mae:0.452967\n",
      "[23]\tvalidation_0-mae:0.396401\n",
      "[24]\tvalidation_0-mae:0.348612\n",
      "[25]\tvalidation_0-mae:0.309489\n",
      "[26]\tvalidation_0-mae:0.276252\n",
      "[27]\tvalidation_0-mae:0.248945\n",
      "[28]\tvalidation_0-mae:0.225825\n",
      "[29]\tvalidation_0-mae:0.207193\n",
      "[30]\tvalidation_0-mae:0.191931\n",
      "[31]\tvalidation_0-mae:0.179693\n",
      "[32]\tvalidation_0-mae:0.169414\n",
      "[33]\tvalidation_0-mae:0.161012\n",
      "[34]\tvalidation_0-mae:0.15356\n",
      "[35]\tvalidation_0-mae:0.147727\n",
      "[36]\tvalidation_0-mae:0.14216\n",
      "[37]\tvalidation_0-mae:0.137784\n",
      "[38]\tvalidation_0-mae:0.133637\n",
      "[39]\tvalidation_0-mae:0.129855\n",
      "[40]\tvalidation_0-mae:0.126357\n",
      "[41]\tvalidation_0-mae:0.123337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\tvalidation_0-mae:0.121122\n",
      "[43]\tvalidation_0-mae:0.118587\n",
      "[44]\tvalidation_0-mae:0.116832\n",
      "[45]\tvalidation_0-mae:0.114146\n",
      "[46]\tvalidation_0-mae:0.11276\n",
      "[47]\tvalidation_0-mae:0.110885\n",
      "[48]\tvalidation_0-mae:0.108986\n",
      "[49]\tvalidation_0-mae:0.107538\n",
      "[50]\tvalidation_0-mae:0.105899\n",
      "[51]\tvalidation_0-mae:0.104058\n",
      "[52]\tvalidation_0-mae:0.102569\n",
      "[53]\tvalidation_0-mae:0.100944\n",
      "[54]\tvalidation_0-mae:0.100016\n",
      "[55]\tvalidation_0-mae:0.098213\n",
      "[56]\tvalidation_0-mae:0.0971\n",
      "[57]\tvalidation_0-mae:0.095917\n",
      "[58]\tvalidation_0-mae:0.095005\n",
      "[59]\tvalidation_0-mae:0.094389\n",
      "[60]\tvalidation_0-mae:0.093215\n",
      "[61]\tvalidation_0-mae:0.092257\n",
      "[62]\tvalidation_0-mae:0.09081\n",
      "[63]\tvalidation_0-mae:0.090192\n",
      "[64]\tvalidation_0-mae:0.088683\n",
      "[65]\tvalidation_0-mae:0.087276\n",
      "[66]\tvalidation_0-mae:0.086841\n",
      "[67]\tvalidation_0-mae:0.085545\n",
      "[68]\tvalidation_0-mae:0.084438\n",
      "[69]\tvalidation_0-mae:0.083734\n",
      "[70]\tvalidation_0-mae:0.082638\n",
      "[71]\tvalidation_0-mae:0.081776\n",
      "[72]\tvalidation_0-mae:0.080875\n",
      "[73]\tvalidation_0-mae:0.08033\n",
      "[74]\tvalidation_0-mae:0.07967\n",
      "[75]\tvalidation_0-mae:0.078723\n",
      "[76]\tvalidation_0-mae:0.077592\n",
      "[77]\tvalidation_0-mae:0.076699\n",
      "[78]\tvalidation_0-mae:0.076065\n",
      "[79]\tvalidation_0-mae:0.07542\n",
      "[80]\tvalidation_0-mae:0.074715\n",
      "[81]\tvalidation_0-mae:0.0739\n",
      "[82]\tvalidation_0-mae:0.073326\n",
      "[83]\tvalidation_0-mae:0.072594\n",
      "[84]\tvalidation_0-mae:0.072152\n",
      "[85]\tvalidation_0-mae:0.07192\n",
      "[86]\tvalidation_0-mae:0.07123\n",
      "[87]\tvalidation_0-mae:0.070708\n",
      "[88]\tvalidation_0-mae:0.069871\n",
      "[89]\tvalidation_0-mae:0.069594\n",
      "[90]\tvalidation_0-mae:0.06857\n",
      "[91]\tvalidation_0-mae:0.068375\n",
      "[92]\tvalidation_0-mae:0.068127\n",
      "[93]\tvalidation_0-mae:0.067922\n",
      "[94]\tvalidation_0-mae:0.067634\n",
      "[95]\tvalidation_0-mae:0.066982\n",
      "[96]\tvalidation_0-mae:0.066415\n",
      "[97]\tvalidation_0-mae:0.066052\n",
      "[98]\tvalidation_0-mae:0.065795\n",
      "[99]\tvalidation_0-mae:0.065603\n",
      "[100]\tvalidation_0-mae:0.0652\n",
      "[101]\tvalidation_0-mae:0.064856\n",
      "[102]\tvalidation_0-mae:0.064542\n",
      "[103]\tvalidation_0-mae:0.06416\n",
      "[104]\tvalidation_0-mae:0.063801\n",
      "[105]\tvalidation_0-mae:0.06316\n",
      "[106]\tvalidation_0-mae:0.06269\n",
      "[107]\tvalidation_0-mae:0.062454\n",
      "[108]\tvalidation_0-mae:0.062083\n",
      "[109]\tvalidation_0-mae:0.061712\n",
      "[110]\tvalidation_0-mae:0.061313\n",
      "[111]\tvalidation_0-mae:0.061171\n",
      "[112]\tvalidation_0-mae:0.060873\n",
      "[113]\tvalidation_0-mae:0.060604\n",
      "[114]\tvalidation_0-mae:0.060377\n",
      "[115]\tvalidation_0-mae:0.059977\n",
      "[116]\tvalidation_0-mae:0.059521\n",
      "[117]\tvalidation_0-mae:0.059348\n",
      "[118]\tvalidation_0-mae:0.058489\n",
      "[119]\tvalidation_0-mae:0.05815\n",
      "[120]\tvalidation_0-mae:0.057544\n",
      "[121]\tvalidation_0-mae:0.05721\n",
      "[122]\tvalidation_0-mae:0.056849\n",
      "[123]\tvalidation_0-mae:0.05637\n",
      "[124]\tvalidation_0-mae:0.055943\n",
      "[125]\tvalidation_0-mae:0.05565\n",
      "[126]\tvalidation_0-mae:0.055286\n",
      "[127]\tvalidation_0-mae:0.055034\n",
      "[128]\tvalidation_0-mae:0.054695\n",
      "[129]\tvalidation_0-mae:0.053815\n",
      "[130]\tvalidation_0-mae:0.053655\n",
      "[131]\tvalidation_0-mae:0.053378\n",
      "[132]\tvalidation_0-mae:0.053319\n",
      "[133]\tvalidation_0-mae:0.052414\n",
      "[134]\tvalidation_0-mae:0.051547\n",
      "[135]\tvalidation_0-mae:0.051433\n",
      "[136]\tvalidation_0-mae:0.050954\n",
      "[137]\tvalidation_0-mae:0.050716\n",
      "[138]\tvalidation_0-mae:0.050567\n",
      "[139]\tvalidation_0-mae:0.050126\n",
      "[140]\tvalidation_0-mae:0.049977\n",
      "[141]\tvalidation_0-mae:0.049782\n",
      "[142]\tvalidation_0-mae:0.049618\n",
      "[143]\tvalidation_0-mae:0.049104\n",
      "[144]\tvalidation_0-mae:0.048563\n",
      "[145]\tvalidation_0-mae:0.048276\n",
      "[146]\tvalidation_0-mae:0.048221\n",
      "[147]\tvalidation_0-mae:0.048059\n",
      "[148]\tvalidation_0-mae:0.047821\n",
      "[149]\tvalidation_0-mae:0.047769\n",
      "    fold  3:  [0.18920069]\n",
      "    ----\n",
      "    MEAN:     [0.18963438] + [0.00031129]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "features = ['habitaciones', \n",
    "            'garages', \n",
    "            'banos',\n",
    "            'antiguedad',\n",
    "            'metroscubiertos', \n",
    "            'metrostotales',\n",
    "            'lat_norm', 'lng_norm'\n",
    "            'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', \n",
    "                 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                     'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "                 'count_id_zona'\n",
    "                 'dias_desde_datos',\n",
    "                 'meses_desde_datos',\n",
    "                 'porcentaje_metros',\n",
    "                 'promedio_precio_hbg_tipo_propiedad']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', \n",
    "                 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                     'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "                 'count_id_zona'\n",
    "                 'dias_desde_datos',\n",
    "                 'meses_desde_datos',\n",
    "                 'porcentaje_metros',\n",
    "                 'promedio_precio_hbg_tipo_propiedad']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('lightgbm', lgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('xgboost', xgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:27:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.963\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2883\n",
      "[2]\tvalidation_0-mae:8.84807\n",
      "[3]\tvalidation_0-mae:7.60942\n",
      "[4]\tvalidation_0-mae:6.54419\n",
      "[5]\tvalidation_0-mae:5.62819\n",
      "[6]\tvalidation_0-mae:4.84034\n",
      "[7]\tvalidation_0-mae:4.16281\n",
      "[8]\tvalidation_0-mae:3.58011\n",
      "[9]\tvalidation_0-mae:3.07896\n",
      "[10]\tvalidation_0-mae:2.64792\n",
      "[11]\tvalidation_0-mae:2.27724\n",
      "[12]\tvalidation_0-mae:1.95845\n",
      "[13]\tvalidation_0-mae:1.68436\n",
      "[14]\tvalidation_0-mae:1.44858\n",
      "[15]\tvalidation_0-mae:1.24591\n",
      "[16]\tvalidation_0-mae:1.0715\n",
      "[17]\tvalidation_0-mae:0.921609\n",
      "[18]\tvalidation_0-mae:0.792701\n",
      "[19]\tvalidation_0-mae:0.681765\n",
      "[20]\tvalidation_0-mae:0.58641\n",
      "[21]\tvalidation_0-mae:0.504503\n",
      "[22]\tvalidation_0-mae:0.434236\n",
      "[23]\tvalidation_0-mae:0.373886\n",
      "[24]\tvalidation_0-mae:0.322083\n",
      "[25]\tvalidation_0-mae:0.277377\n",
      "[26]\tvalidation_0-mae:0.23902\n",
      "[27]\tvalidation_0-mae:0.206152\n",
      "[28]\tvalidation_0-mae:0.178219\n",
      "[29]\tvalidation_0-mae:0.154607\n",
      "[30]\tvalidation_0-mae:0.134807\n",
      "[31]\tvalidation_0-mae:0.117476\n",
      "[32]\tvalidation_0-mae:0.102789\n",
      "[33]\tvalidation_0-mae:0.090406\n",
      "[34]\tvalidation_0-mae:0.080079\n",
      "[35]\tvalidation_0-mae:0.071439\n",
      "[36]\tvalidation_0-mae:0.064764\n",
      "[37]\tvalidation_0-mae:0.059322\n",
      "[38]\tvalidation_0-mae:0.054039\n",
      "[39]\tvalidation_0-mae:0.049818\n",
      "[40]\tvalidation_0-mae:0.046885\n",
      "[41]\tvalidation_0-mae:0.044456\n",
      "[42]\tvalidation_0-mae:0.041762\n",
      "[43]\tvalidation_0-mae:0.039591\n",
      "[44]\tvalidation_0-mae:0.038158\n",
      "[45]\tvalidation_0-mae:0.036998\n",
      "[46]\tvalidation_0-mae:0.036046\n",
      "[47]\tvalidation_0-mae:0.034686\n",
      "[48]\tvalidation_0-mae:0.033882\n",
      "[49]\tvalidation_0-mae:0.033458\n",
      "[50]\tvalidation_0-mae:0.032399\n",
      "[51]\tvalidation_0-mae:0.031398\n",
      "[52]\tvalidation_0-mae:0.030306\n",
      "[53]\tvalidation_0-mae:0.029202\n",
      "[54]\tvalidation_0-mae:0.028858\n",
      "[55]\tvalidation_0-mae:0.028099\n",
      "[56]\tvalidation_0-mae:0.027449\n",
      "[57]\tvalidation_0-mae:0.026945\n",
      "[58]\tvalidation_0-mae:0.026611\n",
      "[59]\tvalidation_0-mae:0.02604\n",
      "[60]\tvalidation_0-mae:0.025375\n",
      "[61]\tvalidation_0-mae:0.02503\n",
      "[62]\tvalidation_0-mae:0.024523\n",
      "[63]\tvalidation_0-mae:0.023696\n",
      "[64]\tvalidation_0-mae:0.022861\n",
      "[65]\tvalidation_0-mae:0.022452\n",
      "[66]\tvalidation_0-mae:0.02195\n",
      "[67]\tvalidation_0-mae:0.021445\n",
      "[68]\tvalidation_0-mae:0.020801\n",
      "[69]\tvalidation_0-mae:0.020481\n",
      "[70]\tvalidation_0-mae:0.02017\n",
      "[71]\tvalidation_0-mae:0.019824\n",
      "[72]\tvalidation_0-mae:0.019645\n",
      "[73]\tvalidation_0-mae:0.019363\n",
      "[74]\tvalidation_0-mae:0.01883\n",
      "[75]\tvalidation_0-mae:0.018539\n",
      "[76]\tvalidation_0-mae:0.018218\n",
      "[77]\tvalidation_0-mae:0.018022\n",
      "[78]\tvalidation_0-mae:0.01773\n",
      "[79]\tvalidation_0-mae:0.017464\n",
      "[80]\tvalidation_0-mae:0.017\n",
      "[81]\tvalidation_0-mae:0.016728\n",
      "[82]\tvalidation_0-mae:0.016431\n",
      "[83]\tvalidation_0-mae:0.016179\n",
      "[84]\tvalidation_0-mae:0.016007\n",
      "[85]\tvalidation_0-mae:0.015813\n",
      "[86]\tvalidation_0-mae:0.015402\n",
      "[87]\tvalidation_0-mae:0.015158\n",
      "[88]\tvalidation_0-mae:0.014968\n",
      "[89]\tvalidation_0-mae:0.014798\n",
      "[90]\tvalidation_0-mae:0.014589\n",
      "[91]\tvalidation_0-mae:0.014323\n",
      "[92]\tvalidation_0-mae:0.014097\n",
      "[93]\tvalidation_0-mae:0.013889\n",
      "[94]\tvalidation_0-mae:0.013713\n",
      "[95]\tvalidation_0-mae:0.013534\n",
      "[96]\tvalidation_0-mae:0.013428\n",
      "[97]\tvalidation_0-mae:0.013276\n",
      "[98]\tvalidation_0-mae:0.013109\n",
      "[99]\tvalidation_0-mae:0.012923\n",
      "[100]\tvalidation_0-mae:0.012779\n",
      "[101]\tvalidation_0-mae:0.012628\n",
      "[102]\tvalidation_0-mae:0.012536\n",
      "[103]\tvalidation_0-mae:0.012441\n",
      "[104]\tvalidation_0-mae:0.012261\n",
      "[105]\tvalidation_0-mae:0.012142\n",
      "[106]\tvalidation_0-mae:0.012029\n",
      "[107]\tvalidation_0-mae:0.011928\n",
      "[108]\tvalidation_0-mae:0.011893\n",
      "[109]\tvalidation_0-mae:0.01179\n",
      "[110]\tvalidation_0-mae:0.011628\n",
      "[111]\tvalidation_0-mae:0.011562\n",
      "[112]\tvalidation_0-mae:0.011481\n",
      "[113]\tvalidation_0-mae:0.011366\n",
      "[114]\tvalidation_0-mae:0.011222\n",
      "[115]\tvalidation_0-mae:0.011098\n",
      "[116]\tvalidation_0-mae:0.010971\n",
      "[117]\tvalidation_0-mae:0.010899\n",
      "[118]\tvalidation_0-mae:0.010809\n",
      "[119]\tvalidation_0-mae:0.010645\n",
      "[120]\tvalidation_0-mae:0.010451\n",
      "[121]\tvalidation_0-mae:0.010313\n",
      "[122]\tvalidation_0-mae:0.010223\n",
      "[123]\tvalidation_0-mae:0.010114\n",
      "[124]\tvalidation_0-mae:0.01\n",
      "[125]\tvalidation_0-mae:0.009955\n",
      "[126]\tvalidation_0-mae:0.009822\n",
      "[127]\tvalidation_0-mae:0.009705\n",
      "[128]\tvalidation_0-mae:0.00964\n",
      "[129]\tvalidation_0-mae:0.009561\n",
      "[130]\tvalidation_0-mae:0.009468\n",
      "[131]\tvalidation_0-mae:0.009436\n",
      "[132]\tvalidation_0-mae:0.009337\n",
      "[133]\tvalidation_0-mae:0.00929\n",
      "[134]\tvalidation_0-mae:0.009253\n",
      "[135]\tvalidation_0-mae:0.009166\n",
      "[136]\tvalidation_0-mae:0.009119\n",
      "[137]\tvalidation_0-mae:0.009047\n",
      "[138]\tvalidation_0-mae:0.009009\n",
      "[139]\tvalidation_0-mae:0.008954\n",
      "[140]\tvalidation_0-mae:0.008924\n",
      "[141]\tvalidation_0-mae:0.008858\n",
      "[142]\tvalidation_0-mae:0.008826\n",
      "[143]\tvalidation_0-mae:0.008751\n",
      "[144]\tvalidation_0-mae:0.00867\n",
      "[145]\tvalidation_0-mae:0.008635\n",
      "[146]\tvalidation_0-mae:0.008594\n",
      "[147]\tvalidation_0-mae:0.008555\n",
      "[148]\tvalidation_0-mae:0.008472\n",
      "[149]\tvalidation_0-mae:0.008398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBoostWrapper(alpha=20.91434940058063, base_score=0.5, booster='gbtree',\n",
       "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.65,\n",
       "               early_stopping_rounds=5, gamma=0, importance_type='gain',\n",
       "               learning_rate=0.14, max_delta_step=0, max_depth=16,\n",
       "               min_child_weight=1, missing=None, n_estimators=150, n_jobs=4,\n",
       "               nthread=None, objective='reg:linear', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "               silent=None, subsample=1, test_size=0.2, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m_2nd = XGBoostWrapper(**hps)\n",
    "\n",
    "xgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = np.exp(xgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02'])))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta29.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "MAE Stacking (train): 479214.56916\n",
      "MAE Stacking (test): 409282.55733\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
