{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8988911725316586,\n",
    " 'bagging_freq': 22.0,\n",
    " 'feature_fraction': 0.6622442122619671,\n",
    " 'learning_rate': 0.16422725363286422,\n",
    " 'max_depth': 22.0,\n",
    " 'num_leaves': 180.0,\n",
    " 'test_size': 0.20892455926004772}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "[21:31:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18966e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.8909e+06\n",
      "[2]\tvalidation_0-mae:1.63406e+06\n",
      "[3]\tvalidation_0-mae:1.41311e+06\n",
      "[4]\tvalidation_0-mae:1.22468e+06\n",
      "[5]\tvalidation_0-mae:1.06398e+06\n",
      "[6]\tvalidation_0-mae:926426\n",
      "[7]\tvalidation_0-mae:809224\n",
      "[8]\tvalidation_0-mae:710350\n",
      "[9]\tvalidation_0-mae:626254\n",
      "[10]\tvalidation_0-mae:556120\n",
      "[11]\tvalidation_0-mae:496360\n",
      "[12]\tvalidation_0-mae:446509\n",
      "[13]\tvalidation_0-mae:404355\n",
      "[14]\tvalidation_0-mae:368831\n",
      "[15]\tvalidation_0-mae:339917\n",
      "[16]\tvalidation_0-mae:316522\n",
      "[17]\tvalidation_0-mae:295993\n",
      "[18]\tvalidation_0-mae:278357\n",
      "[19]\tvalidation_0-mae:264246\n",
      "[20]\tvalidation_0-mae:251036\n",
      "[21]\tvalidation_0-mae:239954\n",
      "[22]\tvalidation_0-mae:231042\n",
      "[23]\tvalidation_0-mae:222193\n",
      "[24]\tvalidation_0-mae:215625\n",
      "[25]\tvalidation_0-mae:208890\n",
      "[26]\tvalidation_0-mae:202676\n",
      "[27]\tvalidation_0-mae:196519\n",
      "[28]\tvalidation_0-mae:191574\n",
      "[29]\tvalidation_0-mae:186391\n",
      "[30]\tvalidation_0-mae:181832\n",
      "[31]\tvalidation_0-mae:177518\n",
      "[32]\tvalidation_0-mae:173613\n",
      "[33]\tvalidation_0-mae:170248\n",
      "[34]\tvalidation_0-mae:167124\n",
      "[35]\tvalidation_0-mae:164066\n",
      "[36]\tvalidation_0-mae:160912\n",
      "[37]\tvalidation_0-mae:158787\n",
      "[38]\tvalidation_0-mae:156192\n",
      "[39]\tvalidation_0-mae:154028\n",
      "[40]\tvalidation_0-mae:151570\n",
      "[41]\tvalidation_0-mae:149748\n",
      "[42]\tvalidation_0-mae:147805\n",
      "[43]\tvalidation_0-mae:145161\n",
      "[44]\tvalidation_0-mae:142996\n",
      "[45]\tvalidation_0-mae:141296\n",
      "[46]\tvalidation_0-mae:140008\n",
      "[47]\tvalidation_0-mae:138272\n",
      "[48]\tvalidation_0-mae:137158\n",
      "[49]\tvalidation_0-mae:134754\n",
      "[50]\tvalidation_0-mae:132421\n",
      "[51]\tvalidation_0-mae:130645\n",
      "[52]\tvalidation_0-mae:129095\n",
      "[53]\tvalidation_0-mae:127737\n",
      "[54]\tvalidation_0-mae:125985\n",
      "[55]\tvalidation_0-mae:124180\n",
      "[56]\tvalidation_0-mae:122687\n",
      "[57]\tvalidation_0-mae:121260\n",
      "[58]\tvalidation_0-mae:120330\n",
      "[59]\tvalidation_0-mae:119198\n",
      "[60]\tvalidation_0-mae:118153\n",
      "[61]\tvalidation_0-mae:116770\n",
      "[62]\tvalidation_0-mae:115631\n",
      "[63]\tvalidation_0-mae:114765\n",
      "[64]\tvalidation_0-mae:114329\n",
      "[65]\tvalidation_0-mae:113780\n",
      "[66]\tvalidation_0-mae:112334\n",
      "[67]\tvalidation_0-mae:110297\n",
      "[68]\tvalidation_0-mae:109595\n",
      "[69]\tvalidation_0-mae:108744\n",
      "[70]\tvalidation_0-mae:108299\n",
      "[71]\tvalidation_0-mae:107511\n",
      "[72]\tvalidation_0-mae:106471\n",
      "[73]\tvalidation_0-mae:105709\n",
      "[74]\tvalidation_0-mae:105309\n",
      "[75]\tvalidation_0-mae:104997\n",
      "[76]\tvalidation_0-mae:104615\n",
      "[77]\tvalidation_0-mae:104201\n",
      "[78]\tvalidation_0-mae:103570\n",
      "[79]\tvalidation_0-mae:103036\n",
      "[80]\tvalidation_0-mae:102449\n",
      "[81]\tvalidation_0-mae:102021\n",
      "[82]\tvalidation_0-mae:101617\n",
      "[83]\tvalidation_0-mae:101543\n",
      "[84]\tvalidation_0-mae:101389\n",
      "[85]\tvalidation_0-mae:101189\n",
      "[86]\tvalidation_0-mae:101064\n",
      "[87]\tvalidation_0-mae:100614\n",
      "[88]\tvalidation_0-mae:99616.1\n",
      "[89]\tvalidation_0-mae:99204.7\n",
      "[90]\tvalidation_0-mae:98085.3\n",
      "[91]\tvalidation_0-mae:97162.2\n",
      "[92]\tvalidation_0-mae:96438.9\n",
      "[93]\tvalidation_0-mae:96255.5\n",
      "[94]\tvalidation_0-mae:95910.8\n",
      "[95]\tvalidation_0-mae:95497\n",
      "[96]\tvalidation_0-mae:95153.4\n",
      "[97]\tvalidation_0-mae:94790.9\n",
      "[98]\tvalidation_0-mae:94514.9\n",
      "[99]\tvalidation_0-mae:93934.7\n",
      "[100]\tvalidation_0-mae:93508.5\n",
      "[101]\tvalidation_0-mae:92775.6\n",
      "[102]\tvalidation_0-mae:92414.5\n",
      "[103]\tvalidation_0-mae:92286\n",
      "[104]\tvalidation_0-mae:91950.4\n",
      "[105]\tvalidation_0-mae:91373.4\n",
      "[106]\tvalidation_0-mae:90667.4\n",
      "[107]\tvalidation_0-mae:90411.3\n",
      "[108]\tvalidation_0-mae:90050\n",
      "[109]\tvalidation_0-mae:89995\n",
      "[110]\tvalidation_0-mae:89283.7\n",
      "[111]\tvalidation_0-mae:88967.4\n",
      "[112]\tvalidation_0-mae:88886.2\n",
      "[113]\tvalidation_0-mae:88143.5\n",
      "[114]\tvalidation_0-mae:87308.3\n",
      "[115]\tvalidation_0-mae:86904.9\n",
      "[116]\tvalidation_0-mae:86475.8\n",
      "[117]\tvalidation_0-mae:86301.5\n",
      "[118]\tvalidation_0-mae:86052.5\n",
      "[119]\tvalidation_0-mae:86005.5\n",
      "[120]\tvalidation_0-mae:85834.1\n",
      "[121]\tvalidation_0-mae:85337.7\n",
      "[122]\tvalidation_0-mae:84932.3\n",
      "[123]\tvalidation_0-mae:84544\n",
      "[124]\tvalidation_0-mae:84433.4\n",
      "[125]\tvalidation_0-mae:83895.5\n",
      "[126]\tvalidation_0-mae:83167.5\n",
      "[127]\tvalidation_0-mae:82521.7\n",
      "[128]\tvalidation_0-mae:81961.4\n",
      "[129]\tvalidation_0-mae:81687.8\n",
      "[130]\tvalidation_0-mae:81562.3\n",
      "[131]\tvalidation_0-mae:81159.7\n",
      "[132]\tvalidation_0-mae:80877.9\n",
      "[133]\tvalidation_0-mae:80625.6\n",
      "[134]\tvalidation_0-mae:80443.8\n",
      "[135]\tvalidation_0-mae:80389.7\n",
      "[136]\tvalidation_0-mae:80194.6\n",
      "[137]\tvalidation_0-mae:80035.4\n",
      "[138]\tvalidation_0-mae:79730.8\n",
      "[139]\tvalidation_0-mae:79448\n",
      "[140]\tvalidation_0-mae:79332.7\n",
      "[141]\tvalidation_0-mae:79141.4\n",
      "[142]\tvalidation_0-mae:78663\n",
      "[143]\tvalidation_0-mae:78079.4\n",
      "[144]\tvalidation_0-mae:78032.3\n",
      "[145]\tvalidation_0-mae:77667.5\n",
      "[146]\tvalidation_0-mae:77514.6\n",
      "[147]\tvalidation_0-mae:77082.2\n",
      "[148]\tvalidation_0-mae:76942.7\n",
      "[149]\tvalidation_0-mae:76389.6\n",
      "    fold  0:  [469999.60396647]\n",
      "[21:34:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18275e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88494e+06\n",
      "[2]\tvalidation_0-mae:1.6288e+06\n",
      "[3]\tvalidation_0-mae:1.4087e+06\n",
      "[4]\tvalidation_0-mae:1.22098e+06\n",
      "[5]\tvalidation_0-mae:1.0606e+06\n",
      "[6]\tvalidation_0-mae:923318\n",
      "[7]\tvalidation_0-mae:806051\n",
      "[8]\tvalidation_0-mae:707125\n",
      "[9]\tvalidation_0-mae:623169\n",
      "[10]\tvalidation_0-mae:553321\n",
      "[11]\tvalidation_0-mae:493772\n",
      "[12]\tvalidation_0-mae:443528\n",
      "[13]\tvalidation_0-mae:401332\n",
      "[14]\tvalidation_0-mae:365936\n",
      "[15]\tvalidation_0-mae:336741\n",
      "[16]\tvalidation_0-mae:313685\n",
      "[17]\tvalidation_0-mae:293142\n",
      "[18]\tvalidation_0-mae:275356\n",
      "[19]\tvalidation_0-mae:261102\n",
      "[20]\tvalidation_0-mae:248032\n",
      "[21]\tvalidation_0-mae:237464\n",
      "[22]\tvalidation_0-mae:228575\n",
      "[23]\tvalidation_0-mae:220010\n",
      "[24]\tvalidation_0-mae:213209\n",
      "[25]\tvalidation_0-mae:206454\n",
      "[26]\tvalidation_0-mae:200726\n",
      "[27]\tvalidation_0-mae:195018\n",
      "[28]\tvalidation_0-mae:190315\n",
      "[29]\tvalidation_0-mae:184912\n",
      "[30]\tvalidation_0-mae:180276\n",
      "[31]\tvalidation_0-mae:176198\n",
      "[32]\tvalidation_0-mae:172837\n",
      "[33]\tvalidation_0-mae:169280\n",
      "[34]\tvalidation_0-mae:166128\n",
      "[35]\tvalidation_0-mae:163405\n",
      "[36]\tvalidation_0-mae:160230\n",
      "[37]\tvalidation_0-mae:158298\n",
      "[38]\tvalidation_0-mae:155302\n",
      "[39]\tvalidation_0-mae:153178\n",
      "[40]\tvalidation_0-mae:151383\n",
      "[41]\tvalidation_0-mae:149477\n",
      "[42]\tvalidation_0-mae:147628\n",
      "[43]\tvalidation_0-mae:145091\n",
      "[44]\tvalidation_0-mae:142432\n",
      "[45]\tvalidation_0-mae:140422\n",
      "[46]\tvalidation_0-mae:139064\n",
      "[47]\tvalidation_0-mae:137209\n",
      "[48]\tvalidation_0-mae:135953\n",
      "[49]\tvalidation_0-mae:133671\n",
      "[50]\tvalidation_0-mae:131851\n",
      "[51]\tvalidation_0-mae:129952\n",
      "[52]\tvalidation_0-mae:128415\n",
      "[53]\tvalidation_0-mae:127406\n",
      "[54]\tvalidation_0-mae:126062\n",
      "[55]\tvalidation_0-mae:124897\n",
      "[56]\tvalidation_0-mae:122743\n",
      "[57]\tvalidation_0-mae:121613\n",
      "[58]\tvalidation_0-mae:120554\n",
      "[59]\tvalidation_0-mae:119657\n",
      "[60]\tvalidation_0-mae:119030\n",
      "[61]\tvalidation_0-mae:117637\n",
      "[62]\tvalidation_0-mae:116622\n",
      "[63]\tvalidation_0-mae:115805\n",
      "[64]\tvalidation_0-mae:115234\n",
      "[65]\tvalidation_0-mae:114011\n",
      "[66]\tvalidation_0-mae:113819\n",
      "[67]\tvalidation_0-mae:112179\n",
      "[68]\tvalidation_0-mae:111123\n",
      "[69]\tvalidation_0-mae:110721\n",
      "[70]\tvalidation_0-mae:109244\n",
      "[71]\tvalidation_0-mae:108496\n",
      "[72]\tvalidation_0-mae:107811\n",
      "[73]\tvalidation_0-mae:107451\n",
      "[74]\tvalidation_0-mae:106592\n",
      "[75]\tvalidation_0-mae:106083\n",
      "[76]\tvalidation_0-mae:105609\n",
      "[77]\tvalidation_0-mae:104818\n",
      "[78]\tvalidation_0-mae:104075\n",
      "[79]\tvalidation_0-mae:103587\n",
      "[80]\tvalidation_0-mae:103240\n",
      "[81]\tvalidation_0-mae:102838\n",
      "[82]\tvalidation_0-mae:102530\n",
      "[83]\tvalidation_0-mae:102113\n",
      "[84]\tvalidation_0-mae:101787\n",
      "[85]\tvalidation_0-mae:101614\n",
      "[86]\tvalidation_0-mae:100834\n",
      "[87]\tvalidation_0-mae:99811.2\n",
      "[88]\tvalidation_0-mae:99098.5\n",
      "[89]\tvalidation_0-mae:98458.9\n",
      "[90]\tvalidation_0-mae:98391.4\n",
      "[91]\tvalidation_0-mae:97995.5\n",
      "[92]\tvalidation_0-mae:97022.8\n",
      "[93]\tvalidation_0-mae:96519.4\n",
      "[94]\tvalidation_0-mae:96416.5\n",
      "[95]\tvalidation_0-mae:95796.2\n",
      "[96]\tvalidation_0-mae:95354.2\n",
      "[97]\tvalidation_0-mae:95032.6\n",
      "[98]\tvalidation_0-mae:94552\n",
      "[99]\tvalidation_0-mae:93577.3\n",
      "[100]\tvalidation_0-mae:93038.2\n",
      "[101]\tvalidation_0-mae:92206.3\n",
      "[102]\tvalidation_0-mae:91574.9\n",
      "[103]\tvalidation_0-mae:91474\n",
      "[104]\tvalidation_0-mae:90839.5\n",
      "[105]\tvalidation_0-mae:90486.7\n",
      "[106]\tvalidation_0-mae:89690.5\n",
      "[107]\tvalidation_0-mae:89135.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108]\tvalidation_0-mae:88798.6\n",
      "[109]\tvalidation_0-mae:87993.7\n",
      "[110]\tvalidation_0-mae:87785.9\n",
      "[111]\tvalidation_0-mae:87261.1\n",
      "[112]\tvalidation_0-mae:87061.5\n",
      "[113]\tvalidation_0-mae:86876.5\n",
      "[114]\tvalidation_0-mae:86348.4\n",
      "[115]\tvalidation_0-mae:86263.1\n",
      "[116]\tvalidation_0-mae:85733.1\n",
      "[117]\tvalidation_0-mae:85409.7\n",
      "[118]\tvalidation_0-mae:85295.7\n",
      "[119]\tvalidation_0-mae:84835.9\n",
      "[120]\tvalidation_0-mae:84798.4\n",
      "[121]\tvalidation_0-mae:84380.6\n",
      "[122]\tvalidation_0-mae:84208.8\n",
      "[123]\tvalidation_0-mae:84046\n",
      "[124]\tvalidation_0-mae:83396.6\n",
      "[125]\tvalidation_0-mae:83281.5\n",
      "[126]\tvalidation_0-mae:82988.5\n",
      "[127]\tvalidation_0-mae:82539.9\n",
      "[128]\tvalidation_0-mae:82304.7\n",
      "[129]\tvalidation_0-mae:81822.2\n",
      "[130]\tvalidation_0-mae:81242.3\n",
      "[131]\tvalidation_0-mae:80769.5\n",
      "[132]\tvalidation_0-mae:80213.8\n",
      "[133]\tvalidation_0-mae:80007.3\n",
      "[134]\tvalidation_0-mae:79249.1\n",
      "[135]\tvalidation_0-mae:78929\n",
      "[136]\tvalidation_0-mae:78696.9\n",
      "[137]\tvalidation_0-mae:78500.2\n",
      "[138]\tvalidation_0-mae:78272.2\n",
      "[139]\tvalidation_0-mae:77774.4\n",
      "[140]\tvalidation_0-mae:77445.8\n",
      "[141]\tvalidation_0-mae:77222.9\n",
      "[142]\tvalidation_0-mae:76698.7\n",
      "[143]\tvalidation_0-mae:76432.1\n",
      "[144]\tvalidation_0-mae:76162.6\n",
      "[145]\tvalidation_0-mae:75696.8\n",
      "[146]\tvalidation_0-mae:75383.8\n",
      "[147]\tvalidation_0-mae:74812.8\n",
      "[148]\tvalidation_0-mae:74793.2\n",
      "[149]\tvalidation_0-mae:74519.6\n",
      "    fold  1:  [478682.79032626]\n",
      "[21:37:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.1812e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88361e+06\n",
      "[2]\tvalidation_0-mae:1.62764e+06\n",
      "[3]\tvalidation_0-mae:1.40766e+06\n",
      "[4]\tvalidation_0-mae:1.21991e+06\n",
      "[5]\tvalidation_0-mae:1.05971e+06\n",
      "[6]\tvalidation_0-mae:922701\n",
      "[7]\tvalidation_0-mae:805741\n",
      "[8]\tvalidation_0-mae:707065\n",
      "[9]\tvalidation_0-mae:623135\n",
      "[10]\tvalidation_0-mae:553331\n",
      "[11]\tvalidation_0-mae:493629\n",
      "[12]\tvalidation_0-mae:443377\n",
      "[13]\tvalidation_0-mae:401235\n",
      "[14]\tvalidation_0-mae:365593\n",
      "[15]\tvalidation_0-mae:336189\n",
      "[16]\tvalidation_0-mae:312936\n",
      "[17]\tvalidation_0-mae:292192\n",
      "[18]\tvalidation_0-mae:274176\n",
      "[19]\tvalidation_0-mae:259641\n",
      "[20]\tvalidation_0-mae:246079\n",
      "[21]\tvalidation_0-mae:234986\n",
      "[22]\tvalidation_0-mae:226046\n",
      "[23]\tvalidation_0-mae:217642\n",
      "[24]\tvalidation_0-mae:211243\n",
      "[25]\tvalidation_0-mae:204166\n",
      "[26]\tvalidation_0-mae:198080\n",
      "[27]\tvalidation_0-mae:192187\n",
      "[28]\tvalidation_0-mae:187021\n",
      "[29]\tvalidation_0-mae:181454\n",
      "[30]\tvalidation_0-mae:176701\n",
      "[31]\tvalidation_0-mae:172770\n",
      "[32]\tvalidation_0-mae:169500\n",
      "[33]\tvalidation_0-mae:165671\n",
      "[34]\tvalidation_0-mae:162936\n",
      "[35]\tvalidation_0-mae:160034\n",
      "[36]\tvalidation_0-mae:156475\n",
      "[37]\tvalidation_0-mae:154413\n",
      "[38]\tvalidation_0-mae:151560\n",
      "[39]\tvalidation_0-mae:149527\n",
      "[40]\tvalidation_0-mae:147285\n",
      "[41]\tvalidation_0-mae:145878\n",
      "[42]\tvalidation_0-mae:144142\n",
      "[43]\tvalidation_0-mae:141165\n",
      "[44]\tvalidation_0-mae:138614\n",
      "[45]\tvalidation_0-mae:136374\n",
      "[46]\tvalidation_0-mae:134512\n",
      "[47]\tvalidation_0-mae:132568\n",
      "[48]\tvalidation_0-mae:131826\n",
      "[49]\tvalidation_0-mae:129127\n",
      "[50]\tvalidation_0-mae:127360\n",
      "[51]\tvalidation_0-mae:125322\n",
      "[52]\tvalidation_0-mae:123484\n",
      "[53]\tvalidation_0-mae:122237\n",
      "[54]\tvalidation_0-mae:120152\n",
      "[55]\tvalidation_0-mae:119134\n",
      "[56]\tvalidation_0-mae:118021\n",
      "[57]\tvalidation_0-mae:117044\n",
      "[58]\tvalidation_0-mae:116016\n",
      "[59]\tvalidation_0-mae:114562\n",
      "[60]\tvalidation_0-mae:113749\n",
      "[61]\tvalidation_0-mae:112983\n",
      "[62]\tvalidation_0-mae:112344\n",
      "[63]\tvalidation_0-mae:111297\n",
      "[64]\tvalidation_0-mae:110679\n",
      "[65]\tvalidation_0-mae:109495\n",
      "[66]\tvalidation_0-mae:108517\n",
      "[67]\tvalidation_0-mae:106947\n",
      "[68]\tvalidation_0-mae:106152\n",
      "[69]\tvalidation_0-mae:105664\n",
      "[70]\tvalidation_0-mae:104687\n",
      "[71]\tvalidation_0-mae:104113\n",
      "[72]\tvalidation_0-mae:103593\n",
      "[73]\tvalidation_0-mae:102899\n",
      "[74]\tvalidation_0-mae:102366\n",
      "[75]\tvalidation_0-mae:101992\n",
      "[76]\tvalidation_0-mae:101652\n",
      "[77]\tvalidation_0-mae:101237\n",
      "[78]\tvalidation_0-mae:100841\n",
      "[79]\tvalidation_0-mae:100282\n",
      "[80]\tvalidation_0-mae:100093\n",
      "[81]\tvalidation_0-mae:99383\n",
      "[82]\tvalidation_0-mae:98830\n",
      "[83]\tvalidation_0-mae:97658.3\n",
      "[84]\tvalidation_0-mae:97547\n",
      "[85]\tvalidation_0-mae:97433.6\n",
      "[86]\tvalidation_0-mae:97304.1\n",
      "[87]\tvalidation_0-mae:97115.8\n",
      "[88]\tvalidation_0-mae:95439.5\n",
      "[89]\tvalidation_0-mae:95031\n",
      "[90]\tvalidation_0-mae:94280.3\n",
      "[91]\tvalidation_0-mae:93594\n",
      "[92]\tvalidation_0-mae:92792.5\n",
      "[93]\tvalidation_0-mae:92594.1\n",
      "[94]\tvalidation_0-mae:91635.4\n",
      "[95]\tvalidation_0-mae:91201.7\n",
      "[96]\tvalidation_0-mae:90692.3\n",
      "[97]\tvalidation_0-mae:89943.8\n",
      "[98]\tvalidation_0-mae:89662.8\n",
      "[99]\tvalidation_0-mae:88974\n",
      "[100]\tvalidation_0-mae:88502\n",
      "[101]\tvalidation_0-mae:88078.6\n",
      "[102]\tvalidation_0-mae:87786.2\n",
      "[103]\tvalidation_0-mae:87188.1\n",
      "[104]\tvalidation_0-mae:86671.6\n",
      "[105]\tvalidation_0-mae:85602.2\n",
      "[106]\tvalidation_0-mae:85303.1\n",
      "[107]\tvalidation_0-mae:84933\n",
      "[108]\tvalidation_0-mae:84479.3\n",
      "[109]\tvalidation_0-mae:83957\n",
      "[110]\tvalidation_0-mae:83856.1\n",
      "[111]\tvalidation_0-mae:83404.7\n",
      "[112]\tvalidation_0-mae:82993.2\n",
      "[113]\tvalidation_0-mae:82314.6\n",
      "[114]\tvalidation_0-mae:81980.8\n",
      "[115]\tvalidation_0-mae:81531.7\n",
      "[116]\tvalidation_0-mae:81119.3\n",
      "[117]\tvalidation_0-mae:81007.1\n",
      "[118]\tvalidation_0-mae:80530.2\n",
      "[119]\tvalidation_0-mae:80482.2\n",
      "[120]\tvalidation_0-mae:80049.2\n",
      "[121]\tvalidation_0-mae:79921.2\n",
      "[122]\tvalidation_0-mae:79631.2\n",
      "[123]\tvalidation_0-mae:79356.3\n",
      "[124]\tvalidation_0-mae:79331.4\n",
      "[125]\tvalidation_0-mae:79146.9\n",
      "[126]\tvalidation_0-mae:78456.1\n",
      "[127]\tvalidation_0-mae:78151.6\n",
      "[128]\tvalidation_0-mae:77758.1\n",
      "[129]\tvalidation_0-mae:77364.2\n",
      "[130]\tvalidation_0-mae:77261.7\n",
      "[131]\tvalidation_0-mae:76944.3\n",
      "[132]\tvalidation_0-mae:76595.8\n",
      "[133]\tvalidation_0-mae:76313.1\n",
      "[134]\tvalidation_0-mae:76177.4\n",
      "[135]\tvalidation_0-mae:75948\n",
      "[136]\tvalidation_0-mae:75878.9\n",
      "[137]\tvalidation_0-mae:75145.3\n",
      "[138]\tvalidation_0-mae:74881.4\n",
      "[139]\tvalidation_0-mae:74724.5\n",
      "[140]\tvalidation_0-mae:74179.7\n",
      "[141]\tvalidation_0-mae:73905.9\n",
      "[142]\tvalidation_0-mae:73740.9\n",
      "[143]\tvalidation_0-mae:73711.5\n",
      "[144]\tvalidation_0-mae:73600.3\n",
      "[145]\tvalidation_0-mae:73487.7\n",
      "[146]\tvalidation_0-mae:72942.2\n",
      "[147]\tvalidation_0-mae:72468.6\n",
      "[148]\tvalidation_0-mae:72378.8\n",
      "[149]\tvalidation_0-mae:72200.5\n",
      "    fold  2:  [481599.56072244]\n",
      "[21:40:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18353e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88566e+06\n",
      "[2]\tvalidation_0-mae:1.62944e+06\n",
      "[3]\tvalidation_0-mae:1.40928e+06\n",
      "[4]\tvalidation_0-mae:1.22143e+06\n",
      "[5]\tvalidation_0-mae:1.06106e+06\n",
      "[6]\tvalidation_0-mae:923759\n",
      "[7]\tvalidation_0-mae:806722\n",
      "[8]\tvalidation_0-mae:708151\n",
      "[9]\tvalidation_0-mae:624340\n",
      "[10]\tvalidation_0-mae:554414\n",
      "[11]\tvalidation_0-mae:494621\n",
      "[12]\tvalidation_0-mae:444683\n",
      "[13]\tvalidation_0-mae:402926\n",
      "[14]\tvalidation_0-mae:367662\n",
      "[15]\tvalidation_0-mae:338629\n",
      "[16]\tvalidation_0-mae:315332\n",
      "[17]\tvalidation_0-mae:294541\n",
      "[18]\tvalidation_0-mae:276542\n",
      "[19]\tvalidation_0-mae:262128\n",
      "[20]\tvalidation_0-mae:248648\n",
      "[21]\tvalidation_0-mae:237642\n",
      "[22]\tvalidation_0-mae:228820\n",
      "[23]\tvalidation_0-mae:220263\n",
      "[24]\tvalidation_0-mae:213189\n",
      "[25]\tvalidation_0-mae:206355\n",
      "[26]\tvalidation_0-mae:200635\n",
      "[27]\tvalidation_0-mae:194953\n",
      "[28]\tvalidation_0-mae:190092\n",
      "[29]\tvalidation_0-mae:185206\n",
      "[30]\tvalidation_0-mae:180841\n",
      "[31]\tvalidation_0-mae:176836\n",
      "[32]\tvalidation_0-mae:173300\n",
      "[33]\tvalidation_0-mae:170012\n",
      "[34]\tvalidation_0-mae:166796\n",
      "[35]\tvalidation_0-mae:163428\n",
      "[36]\tvalidation_0-mae:160452\n",
      "[37]\tvalidation_0-mae:158766\n",
      "[38]\tvalidation_0-mae:156155\n",
      "[39]\tvalidation_0-mae:153690\n",
      "[40]\tvalidation_0-mae:151212\n",
      "[41]\tvalidation_0-mae:149532\n",
      "[42]\tvalidation_0-mae:147763\n",
      "[43]\tvalidation_0-mae:144693\n",
      "[44]\tvalidation_0-mae:142081\n",
      "[45]\tvalidation_0-mae:140049\n",
      "[46]\tvalidation_0-mae:138715\n",
      "[47]\tvalidation_0-mae:136879\n",
      "[48]\tvalidation_0-mae:135818\n",
      "[49]\tvalidation_0-mae:133849\n",
      "[50]\tvalidation_0-mae:131245\n",
      "[51]\tvalidation_0-mae:129770\n",
      "[52]\tvalidation_0-mae:127964\n",
      "[53]\tvalidation_0-mae:126749\n",
      "[54]\tvalidation_0-mae:124303\n",
      "[55]\tvalidation_0-mae:122836\n",
      "[56]\tvalidation_0-mae:121728\n",
      "[57]\tvalidation_0-mae:120399\n",
      "[58]\tvalidation_0-mae:119164\n",
      "[59]\tvalidation_0-mae:118518\n",
      "[60]\tvalidation_0-mae:117294\n",
      "[61]\tvalidation_0-mae:116433\n",
      "[62]\tvalidation_0-mae:115663\n",
      "[63]\tvalidation_0-mae:114619\n",
      "[64]\tvalidation_0-mae:113887\n",
      "[65]\tvalidation_0-mae:112801\n",
      "[66]\tvalidation_0-mae:112205\n",
      "[67]\tvalidation_0-mae:110841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68]\tvalidation_0-mae:110151\n",
      "[69]\tvalidation_0-mae:109533\n",
      "[70]\tvalidation_0-mae:108322\n",
      "[71]\tvalidation_0-mae:107686\n",
      "[72]\tvalidation_0-mae:107392\n",
      "[73]\tvalidation_0-mae:107086\n",
      "[74]\tvalidation_0-mae:106588\n",
      "[75]\tvalidation_0-mae:105987\n",
      "[76]\tvalidation_0-mae:105343\n",
      "[77]\tvalidation_0-mae:104533\n",
      "[78]\tvalidation_0-mae:103999\n",
      "[79]\tvalidation_0-mae:103565\n",
      "[80]\tvalidation_0-mae:103295\n",
      "[81]\tvalidation_0-mae:102511\n",
      "[82]\tvalidation_0-mae:102121\n",
      "[83]\tvalidation_0-mae:101370\n",
      "[84]\tvalidation_0-mae:101046\n",
      "[85]\tvalidation_0-mae:100952\n",
      "[86]\tvalidation_0-mae:100568\n",
      "[87]\tvalidation_0-mae:99048.7\n",
      "[88]\tvalidation_0-mae:98370.1\n",
      "[89]\tvalidation_0-mae:97906.2\n",
      "[90]\tvalidation_0-mae:97247.6\n",
      "[91]\tvalidation_0-mae:96798.5\n",
      "[92]\tvalidation_0-mae:96004.1\n",
      "[93]\tvalidation_0-mae:95298.8\n",
      "[94]\tvalidation_0-mae:95173.4\n",
      "[95]\tvalidation_0-mae:95126.8\n",
      "[96]\tvalidation_0-mae:94700.1\n",
      "[97]\tvalidation_0-mae:94287.3\n",
      "[98]\tvalidation_0-mae:93039.5\n",
      "[99]\tvalidation_0-mae:92667\n",
      "[100]\tvalidation_0-mae:92090.3\n",
      "[101]\tvalidation_0-mae:91511.4\n",
      "[102]\tvalidation_0-mae:91258.6\n",
      "[103]\tvalidation_0-mae:90769.9\n",
      "[104]\tvalidation_0-mae:90558.2\n",
      "[105]\tvalidation_0-mae:90469.2\n",
      "[106]\tvalidation_0-mae:90040\n",
      "[107]\tvalidation_0-mae:89839.7\n",
      "[108]\tvalidation_0-mae:89607.2\n",
      "[109]\tvalidation_0-mae:89508.6\n",
      "[110]\tvalidation_0-mae:89344\n",
      "[111]\tvalidation_0-mae:89044.6\n",
      "[112]\tvalidation_0-mae:88885.3\n",
      "[113]\tvalidation_0-mae:88560.3\n",
      "[114]\tvalidation_0-mae:87727.2\n",
      "[115]\tvalidation_0-mae:87422.8\n",
      "[116]\tvalidation_0-mae:86834.6\n",
      "[117]\tvalidation_0-mae:86115.1\n",
      "[118]\tvalidation_0-mae:85422.4\n",
      "[119]\tvalidation_0-mae:85155.4\n",
      "[120]\tvalidation_0-mae:84933\n",
      "[121]\tvalidation_0-mae:83911.9\n",
      "[122]\tvalidation_0-mae:83544.6\n",
      "[123]\tvalidation_0-mae:83164\n",
      "[124]\tvalidation_0-mae:82772.2\n",
      "[125]\tvalidation_0-mae:82368.7\n",
      "[126]\tvalidation_0-mae:82281.4\n",
      "[127]\tvalidation_0-mae:82139.9\n",
      "[128]\tvalidation_0-mae:81737.3\n",
      "[129]\tvalidation_0-mae:81434.6\n",
      "[130]\tvalidation_0-mae:81104\n",
      "[131]\tvalidation_0-mae:80726.4\n",
      "[132]\tvalidation_0-mae:80481.5\n",
      "[133]\tvalidation_0-mae:79770.6\n",
      "[134]\tvalidation_0-mae:79579.6\n",
      "[135]\tvalidation_0-mae:79397.2\n",
      "[136]\tvalidation_0-mae:79138.9\n",
      "[137]\tvalidation_0-mae:79081.3\n",
      "[138]\tvalidation_0-mae:78635.2\n",
      "[139]\tvalidation_0-mae:78164.4\n",
      "[140]\tvalidation_0-mae:77972.8\n",
      "[141]\tvalidation_0-mae:77835.2\n",
      "[142]\tvalidation_0-mae:77646.1\n",
      "[143]\tvalidation_0-mae:77638.7\n",
      "[144]\tvalidation_0-mae:77088.6\n",
      "[145]\tvalidation_0-mae:76779.7\n",
      "[146]\tvalidation_0-mae:76548.6\n",
      "[147]\tvalidation_0-mae:76307.2\n",
      "[148]\tvalidation_0-mae:76142.9\n",
      "[149]\tvalidation_0-mae:75767.5\n",
      "    fold  3:  [477750.77967499]\n",
      "[21:42:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18224e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88442e+06\n",
      "[2]\tvalidation_0-mae:1.62821e+06\n",
      "[3]\tvalidation_0-mae:1.40832e+06\n",
      "[4]\tvalidation_0-mae:1.22071e+06\n",
      "[5]\tvalidation_0-mae:1.06032e+06\n",
      "[6]\tvalidation_0-mae:923191\n",
      "[7]\tvalidation_0-mae:806185\n",
      "[8]\tvalidation_0-mae:707505\n",
      "[9]\tvalidation_0-mae:623598\n",
      "[10]\tvalidation_0-mae:553643\n",
      "[11]\tvalidation_0-mae:494052\n",
      "[12]\tvalidation_0-mae:444119\n",
      "[13]\tvalidation_0-mae:401821\n",
      "[14]\tvalidation_0-mae:366559\n",
      "[15]\tvalidation_0-mae:337458\n",
      "[16]\tvalidation_0-mae:314590\n",
      "[17]\tvalidation_0-mae:294108\n",
      "[18]\tvalidation_0-mae:275927\n",
      "[19]\tvalidation_0-mae:261601\n",
      "[20]\tvalidation_0-mae:248388\n",
      "[21]\tvalidation_0-mae:237250\n",
      "[22]\tvalidation_0-mae:228199\n",
      "[23]\tvalidation_0-mae:219460\n",
      "[24]\tvalidation_0-mae:212940\n",
      "[25]\tvalidation_0-mae:206109\n",
      "[26]\tvalidation_0-mae:200073\n",
      "[27]\tvalidation_0-mae:194304\n",
      "[28]\tvalidation_0-mae:189356\n",
      "[29]\tvalidation_0-mae:184243\n",
      "[30]\tvalidation_0-mae:179439\n",
      "[31]\tvalidation_0-mae:175695\n",
      "[32]\tvalidation_0-mae:172234\n",
      "[33]\tvalidation_0-mae:168546\n",
      "[34]\tvalidation_0-mae:165692\n",
      "[35]\tvalidation_0-mae:162304\n",
      "[36]\tvalidation_0-mae:159091\n",
      "[37]\tvalidation_0-mae:156807\n",
      "[38]\tvalidation_0-mae:154266\n",
      "[39]\tvalidation_0-mae:152126\n",
      "[40]\tvalidation_0-mae:150066\n",
      "[41]\tvalidation_0-mae:148322\n",
      "[42]\tvalidation_0-mae:145947\n",
      "[43]\tvalidation_0-mae:142801\n",
      "[44]\tvalidation_0-mae:140236\n",
      "[45]\tvalidation_0-mae:137710\n",
      "[46]\tvalidation_0-mae:136491\n",
      "[47]\tvalidation_0-mae:134892\n",
      "[48]\tvalidation_0-mae:133199\n",
      "[49]\tvalidation_0-mae:130995\n",
      "[50]\tvalidation_0-mae:129033\n",
      "[51]\tvalidation_0-mae:127128\n",
      "[52]\tvalidation_0-mae:125806\n",
      "[53]\tvalidation_0-mae:124070\n",
      "[54]\tvalidation_0-mae:122764\n",
      "[55]\tvalidation_0-mae:121812\n",
      "[56]\tvalidation_0-mae:120592\n",
      "[57]\tvalidation_0-mae:119559\n",
      "[58]\tvalidation_0-mae:118440\n",
      "[59]\tvalidation_0-mae:117222\n",
      "[60]\tvalidation_0-mae:116257\n",
      "[61]\tvalidation_0-mae:115215\n",
      "[62]\tvalidation_0-mae:113832\n",
      "[63]\tvalidation_0-mae:112537\n",
      "[64]\tvalidation_0-mae:112120\n",
      "[65]\tvalidation_0-mae:110984\n",
      "[66]\tvalidation_0-mae:110535\n",
      "[67]\tvalidation_0-mae:109623\n",
      "[68]\tvalidation_0-mae:108846\n",
      "[69]\tvalidation_0-mae:108365\n",
      "[70]\tvalidation_0-mae:107603\n",
      "[71]\tvalidation_0-mae:106427\n",
      "[72]\tvalidation_0-mae:105905\n",
      "[73]\tvalidation_0-mae:105257\n",
      "[74]\tvalidation_0-mae:105045\n",
      "[75]\tvalidation_0-mae:104215\n",
      "[76]\tvalidation_0-mae:103901\n",
      "[77]\tvalidation_0-mae:102916\n",
      "[78]\tvalidation_0-mae:102424\n",
      "[79]\tvalidation_0-mae:102198\n",
      "[80]\tvalidation_0-mae:101845\n",
      "[81]\tvalidation_0-mae:100963\n",
      "[82]\tvalidation_0-mae:100689\n",
      "[83]\tvalidation_0-mae:100456\n",
      "[84]\tvalidation_0-mae:100263\n",
      "[85]\tvalidation_0-mae:99838.4\n",
      "[86]\tvalidation_0-mae:99427\n",
      "[87]\tvalidation_0-mae:98626.6\n",
      "[88]\tvalidation_0-mae:98202.1\n",
      "[89]\tvalidation_0-mae:97617.2\n",
      "[90]\tvalidation_0-mae:96709.6\n",
      "[91]\tvalidation_0-mae:96011.9\n",
      "[92]\tvalidation_0-mae:95533.9\n",
      "[93]\tvalidation_0-mae:95317.3\n",
      "[94]\tvalidation_0-mae:95220.5\n",
      "[95]\tvalidation_0-mae:95039.7\n",
      "[96]\tvalidation_0-mae:94074.3\n",
      "[97]\tvalidation_0-mae:93892.1\n",
      "[98]\tvalidation_0-mae:93601.5\n",
      "[99]\tvalidation_0-mae:92805.9\n",
      "[100]\tvalidation_0-mae:92666.4\n",
      "[101]\tvalidation_0-mae:92476.3\n",
      "[102]\tvalidation_0-mae:92165.4\n",
      "[103]\tvalidation_0-mae:92005.2\n",
      "[104]\tvalidation_0-mae:91559.7\n",
      "[105]\tvalidation_0-mae:91193.7\n",
      "[106]\tvalidation_0-mae:90881.2\n",
      "[107]\tvalidation_0-mae:90289.7\n",
      "[108]\tvalidation_0-mae:89561\n",
      "[109]\tvalidation_0-mae:88982.2\n",
      "[110]\tvalidation_0-mae:88677.9\n",
      "[111]\tvalidation_0-mae:87867.6\n",
      "[112]\tvalidation_0-mae:87500.6\n",
      "[113]\tvalidation_0-mae:86834.1\n",
      "[114]\tvalidation_0-mae:86165.4\n",
      "[115]\tvalidation_0-mae:85922.5\n",
      "[116]\tvalidation_0-mae:85697.9\n",
      "[117]\tvalidation_0-mae:85197.7\n",
      "[118]\tvalidation_0-mae:84808.8\n",
      "[119]\tvalidation_0-mae:84514.5\n",
      "[120]\tvalidation_0-mae:84459.5\n",
      "[121]\tvalidation_0-mae:84175.6\n",
      "[122]\tvalidation_0-mae:83232\n",
      "[123]\tvalidation_0-mae:82680\n",
      "[124]\tvalidation_0-mae:82579.2\n",
      "[125]\tvalidation_0-mae:81976.7\n",
      "[126]\tvalidation_0-mae:81723.6\n",
      "[127]\tvalidation_0-mae:80978.4\n",
      "[128]\tvalidation_0-mae:80913.3\n",
      "[129]\tvalidation_0-mae:80192.9\n",
      "[130]\tvalidation_0-mae:79328.2\n",
      "[131]\tvalidation_0-mae:78650.2\n",
      "[132]\tvalidation_0-mae:78224.1\n",
      "[133]\tvalidation_0-mae:77922.3\n",
      "[134]\tvalidation_0-mae:77677.8\n",
      "[135]\tvalidation_0-mae:77349.6\n",
      "[136]\tvalidation_0-mae:76863.2\n",
      "[137]\tvalidation_0-mae:76533.2\n",
      "[138]\tvalidation_0-mae:76255\n",
      "[139]\tvalidation_0-mae:75897.9\n",
      "[140]\tvalidation_0-mae:75307.4\n",
      "[141]\tvalidation_0-mae:75143.1\n",
      "[142]\tvalidation_0-mae:74751.9\n",
      "[143]\tvalidation_0-mae:74668.2\n",
      "[144]\tvalidation_0-mae:74494.8\n",
      "[145]\tvalidation_0-mae:74410.7\n",
      "[146]\tvalidation_0-mae:74069.7\n",
      "[147]\tvalidation_0-mae:73588.8\n",
      "[148]\tvalidation_0-mae:73525.7\n",
      "[149]\tvalidation_0-mae:73259.9\n",
      "    fold  4:  [479170.72114927]\n",
      "[21:45:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18323e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88543e+06\n",
      "[2]\tvalidation_0-mae:1.62917e+06\n",
      "[3]\tvalidation_0-mae:1.40914e+06\n",
      "[4]\tvalidation_0-mae:1.22147e+06\n",
      "[5]\tvalidation_0-mae:1.06101e+06\n",
      "[6]\tvalidation_0-mae:923848\n",
      "[7]\tvalidation_0-mae:806896\n",
      "[8]\tvalidation_0-mae:708247\n",
      "[9]\tvalidation_0-mae:624166\n",
      "[10]\tvalidation_0-mae:554224\n",
      "[11]\tvalidation_0-mae:494607\n",
      "[12]\tvalidation_0-mae:444929\n",
      "[13]\tvalidation_0-mae:402978\n",
      "[14]\tvalidation_0-mae:367396\n",
      "[15]\tvalidation_0-mae:338301\n",
      "[16]\tvalidation_0-mae:315213\n",
      "[17]\tvalidation_0-mae:294554\n",
      "[18]\tvalidation_0-mae:276944\n",
      "[19]\tvalidation_0-mae:262522\n",
      "[20]\tvalidation_0-mae:249434\n",
      "[21]\tvalidation_0-mae:238546\n",
      "[22]\tvalidation_0-mae:229511\n",
      "[23]\tvalidation_0-mae:220941\n",
      "[24]\tvalidation_0-mae:213999\n",
      "[25]\tvalidation_0-mae:207527\n",
      "[26]\tvalidation_0-mae:201450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalidation_0-mae:195512\n",
      "[28]\tvalidation_0-mae:190450\n",
      "[29]\tvalidation_0-mae:185358\n",
      "[30]\tvalidation_0-mae:180873\n",
      "[31]\tvalidation_0-mae:176480\n",
      "[32]\tvalidation_0-mae:173470\n",
      "[33]\tvalidation_0-mae:169726\n",
      "[34]\tvalidation_0-mae:167186\n",
      "[35]\tvalidation_0-mae:163983\n",
      "[36]\tvalidation_0-mae:161109\n",
      "[37]\tvalidation_0-mae:159282\n",
      "[38]\tvalidation_0-mae:156276\n",
      "[39]\tvalidation_0-mae:154029\n",
      "[40]\tvalidation_0-mae:152081\n",
      "[41]\tvalidation_0-mae:150099\n",
      "[42]\tvalidation_0-mae:147924\n",
      "[43]\tvalidation_0-mae:144798\n",
      "[44]\tvalidation_0-mae:142347\n",
      "[45]\tvalidation_0-mae:140326\n",
      "[46]\tvalidation_0-mae:138693\n",
      "[47]\tvalidation_0-mae:136931\n",
      "[48]\tvalidation_0-mae:135465\n",
      "[49]\tvalidation_0-mae:133052\n",
      "[50]\tvalidation_0-mae:130851\n",
      "[51]\tvalidation_0-mae:129182\n",
      "[52]\tvalidation_0-mae:127745\n",
      "[53]\tvalidation_0-mae:126494\n",
      "[54]\tvalidation_0-mae:124333\n",
      "[55]\tvalidation_0-mae:122995\n",
      "[56]\tvalidation_0-mae:121796\n",
      "[57]\tvalidation_0-mae:120463\n",
      "[58]\tvalidation_0-mae:119701\n",
      "[59]\tvalidation_0-mae:117974\n",
      "[60]\tvalidation_0-mae:116820\n",
      "[61]\tvalidation_0-mae:115278\n",
      "[62]\tvalidation_0-mae:114116\n",
      "[63]\tvalidation_0-mae:113118\n",
      "[64]\tvalidation_0-mae:112656\n",
      "[65]\tvalidation_0-mae:111465\n",
      "[66]\tvalidation_0-mae:110731\n",
      "[67]\tvalidation_0-mae:109420\n",
      "[68]\tvalidation_0-mae:108685\n",
      "[69]\tvalidation_0-mae:107457\n",
      "[70]\tvalidation_0-mae:106784\n",
      "[71]\tvalidation_0-mae:106195\n",
      "[72]\tvalidation_0-mae:104651\n",
      "[73]\tvalidation_0-mae:103579\n",
      "[74]\tvalidation_0-mae:102826\n",
      "[75]\tvalidation_0-mae:102132\n",
      "[76]\tvalidation_0-mae:101866\n",
      "[77]\tvalidation_0-mae:100228\n",
      "[78]\tvalidation_0-mae:99898.2\n",
      "[79]\tvalidation_0-mae:99524.2\n",
      "[80]\tvalidation_0-mae:99426.3\n",
      "[81]\tvalidation_0-mae:99137\n",
      "[82]\tvalidation_0-mae:98740.5\n",
      "[83]\tvalidation_0-mae:97832.3\n",
      "[84]\tvalidation_0-mae:97342.4\n",
      "[85]\tvalidation_0-mae:96910.1\n",
      "[86]\tvalidation_0-mae:96501.9\n",
      "[87]\tvalidation_0-mae:96189.1\n",
      "[88]\tvalidation_0-mae:95934.4\n",
      "[89]\tvalidation_0-mae:95254.1\n",
      "[90]\tvalidation_0-mae:95135.9\n",
      "[91]\tvalidation_0-mae:94225.6\n",
      "[92]\tvalidation_0-mae:93896.7\n",
      "[93]\tvalidation_0-mae:93518.6\n",
      "[94]\tvalidation_0-mae:92816.2\n",
      "[95]\tvalidation_0-mae:92746.5\n",
      "[96]\tvalidation_0-mae:92381.9\n",
      "[97]\tvalidation_0-mae:92312.4\n",
      "[98]\tvalidation_0-mae:91970.9\n",
      "[99]\tvalidation_0-mae:91340.7\n",
      "[100]\tvalidation_0-mae:90848.9\n",
      "[101]\tvalidation_0-mae:90516.9\n",
      "[102]\tvalidation_0-mae:90138.6\n",
      "[103]\tvalidation_0-mae:90051.5\n",
      "[104]\tvalidation_0-mae:89830.4\n",
      "[105]\tvalidation_0-mae:89416.7\n",
      "[106]\tvalidation_0-mae:88986.4\n",
      "[107]\tvalidation_0-mae:88660.8\n",
      "[108]\tvalidation_0-mae:88387\n",
      "[109]\tvalidation_0-mae:88319.6\n",
      "[110]\tvalidation_0-mae:87713.5\n",
      "[111]\tvalidation_0-mae:87536.8\n",
      "[112]\tvalidation_0-mae:86928\n",
      "[113]\tvalidation_0-mae:86750.8\n",
      "[114]\tvalidation_0-mae:86525.3\n",
      "[115]\tvalidation_0-mae:86336.4\n",
      "[116]\tvalidation_0-mae:85574\n",
      "[117]\tvalidation_0-mae:85440.6\n",
      "[118]\tvalidation_0-mae:84945.3\n",
      "[119]\tvalidation_0-mae:84633.4\n",
      "[120]\tvalidation_0-mae:84324.1\n",
      "[121]\tvalidation_0-mae:83907.8\n",
      "[122]\tvalidation_0-mae:83621.8\n",
      "[123]\tvalidation_0-mae:83125.5\n",
      "[124]\tvalidation_0-mae:82598.7\n",
      "[125]\tvalidation_0-mae:82532\n",
      "[126]\tvalidation_0-mae:82136.5\n",
      "[127]\tvalidation_0-mae:81431.3\n",
      "[128]\tvalidation_0-mae:81208.8\n",
      "[129]\tvalidation_0-mae:80893\n",
      "[130]\tvalidation_0-mae:80374.9\n",
      "[131]\tvalidation_0-mae:79965\n",
      "[132]\tvalidation_0-mae:79052.8\n",
      "[133]\tvalidation_0-mae:78196.9\n",
      "[134]\tvalidation_0-mae:78035.4\n",
      "[135]\tvalidation_0-mae:77561.9\n",
      "[136]\tvalidation_0-mae:76772\n",
      "[137]\tvalidation_0-mae:76123.9\n",
      "[138]\tvalidation_0-mae:75702.4\n",
      "[139]\tvalidation_0-mae:75100.3\n",
      "[140]\tvalidation_0-mae:74587.3\n",
      "[141]\tvalidation_0-mae:74421.7\n",
      "[142]\tvalidation_0-mae:74173.9\n",
      "[143]\tvalidation_0-mae:73969.1\n",
      "[144]\tvalidation_0-mae:73674.2\n",
      "[145]\tvalidation_0-mae:73444.8\n",
      "[146]\tvalidation_0-mae:73358.4\n",
      "[147]\tvalidation_0-mae:73247.2\n",
      "[148]\tvalidation_0-mae:73011.1\n",
      "[149]\tvalidation_0-mae:72322.2\n",
      "    fold  5:  [478225.69720345]\n",
      "    ----\n",
      "    MEAN:     [477571.52550715] + [3601.19129314]\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [497516.32984127]\n",
      "    fold  1:  [505865.87629269]\n",
      "    fold  2:  [507302.78467807]\n",
      "    fold  3:  [506641.77927507]\n",
      "    fold  4:  [506872.77215852]\n",
      "    fold  5:  [504404.70677250]\n",
      "    ----\n",
      "    MEAN:     [504767.37483635] + [3373.67949585]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "features = ['habitaciones', \n",
    "            'garages', \n",
    "            'banos',\n",
    "            'antiguedad',\n",
    "            'metroscubiertos', \n",
    "            'metrostotales', \n",
    "            'lat', 'lng',\n",
    "            'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', \n",
    "                 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                     'count_tipo_propiedad_ciudad', \n",
    "#                  'varianza_id_zona',\n",
    "#                  'metros_cubiertos_normalizados',\n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "#                  'promedio_precio_hbg_tipo_propiedad_provincia',\n",
    "#                  'diferencia_metros',\n",
    "                 'count_id_zona'\n",
    "                 'dias_desde_datos',\n",
    "                 'meses_desde_datos',\n",
    "                 'porcentaje_metros',\n",
    "#                  'promedio_por_mes', \n",
    "#                  'count_tipo_propiedad',\n",
    "#                  'tam_ambientes',\n",
    "                 'promedio_precio_hbg_tipo_propiedad']\n",
    "\n",
    "\n",
    "features += features_test\n",
    "\n",
    "features += cols_tipodepropiedad_ohe + cols_provincia_ohe + cols_zona_ohe\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('xgboost', xgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('lightgbm', lgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2, n_folds=6)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.7740520226030885, bagging_freq=7,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.8422472893793045, importance_type='split',\n",
       "                learning_rate=0.1508386725397851, max_depth=12,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=110,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.7740520226030885,\n",
    " 'bagging_freq': int(7.0),\n",
    " 'feature_fraction': 0.8422472893793045,\n",
    " 'learning_rate': 0.1508386725397851,\n",
    " 'max_depth': int(12.0),\n",
    " 'num_leaves': int(110.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta24.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "MAE Stacking (train): 479214.56916\n",
      "MAE Stacking (test): 409282.55733\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
