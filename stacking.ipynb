{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "import ipynb.fs.full.features_distancias as f_distancias\n",
    "\n",
    "df_train = pd.read_csv('./data/train_filtrado.csv')\n",
    "df_train = utils.dolarizar_df(df_train)\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cluster = pd.read_csv('./data/clustering_train.csv').rename(columns={'label': 'clustering_label'})\n",
    "df_test_cluster = pd.read_csv('./data/clustering_test.csv').rename(columns={'label': 'clustering_label'})\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_cluster, on='id')\n",
    "df_test = pd.merge(df_test, df_test_cluster, on='id')\n",
    "\n",
    "df_train_idf = pd.read_csv('./data/train_idf.csv')\n",
    "df_test_idf = pd.read_csv('./data/test_idf.csv')\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_idf, on= 'id', how= 'left')\n",
    "df_test = pd.merge(df_test, df_test_idf, on= 'id', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "\n",
    "df_train_f = f_distancias.feature_distancias(df_train_f)\n",
    "df_test_f = f_distancias.feature_distancias(df_test_f, df_train_f)\n",
    "\n",
    "\n",
    "# df_train_f = features.KD_feature(df_train_f)\n",
    "# df_test_f =  features.KD_feature(df_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selector de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class FeatureSelector(BaseEstimator):\n",
    "    \n",
    "    base_features = list(df_train_f.drop('precio', axis=1, errors='ignore').columns)\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        base_features = FeatureSelector.base_features\n",
    "\n",
    "        self.features = features\n",
    "        self.features_index = [i for i in range(len(base_features)) if base_features[i] in features]\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x[:, self.features_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        return super(LightGBMWrapper, self).fit(x, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X,num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.5,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'feature_fraction': 0.9,\n",
    " 'learning_rate': 0.25,\n",
    " 'max_depth': 10,\n",
    " 'metric': 'mae',\n",
    " 'n_jobs': 2,\n",
    " 'num_leaves': 200,\n",
    " 'objective': 'regression'}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "#     'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = Pipeline(steps=[\n",
    "    ('feature_selector', FeatureSelector(['antiguedad', 'habitaciones', 'garages', 'banos', 'metroscubiertos',\n",
    "       'metrostotales', 'lat', 'lng', 'fecha', 'piscina', 'escuelascercanas',\n",
    "       'centroscomercialescercanos', 'clustering_label', 'idf_titulo',\n",
    "       'idf_descripcion', 'peso_titulo', 'peso_descripcion',\n",
    "       'porcentaje_metros', 'diferencia_metros', 'metros_totales_normalizados',\n",
    "       'metros_cubiertos_normalizados', 'escomercial',\n",
    "       'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad',\n",
    "       'prop_frecuente', 'top_provincia', 'es_ciudad_centrica',\n",
    "       'promedio_metros_totales_provincia',\n",
    "       'promedio_metros_cubiertos_provincia', 'mes', 'dia', 'trimestre',\n",
    "       'dias_desde_datos', 'meses_desde_datos', 'antiguedad_bins_perc',\n",
    "       'cantidad_inquilinos', 'tam_ambientes', 'promedio_precio_provincia',\n",
    "       'promedio_precio_ciudad', 'varianza_precio_ciudad', 'count_ciudad',\n",
    "       'promedio_id_zona', 'promedio_id_zona_gen', 'varianza_id_zona',\n",
    "       'count_id_zona', 'promedio_precio_tipo_propiedad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad_gen', 'count_tipo_propiedad',\n",
    "       'count_tipo_propiedad_ciudad', 'promedio_por_mes', 'varianza_por_mes',\n",
    "       'promedio_precio_habitaciones',\n",
    "       'promedio_precio_habitaciones_banos_garages',\n",
    "       'promedio_precio_banos_garages', 'promedio_precio_hbg_tipo_propiedad',\n",
    "       'lat_norm', 'lng_norm', 'promedio_precio_booleanos', 'puntaje',\n",
    "       'distancia_ciudad_centrica', 'distancia_centro_mexico',\n",
    "       'distancia_ciudad_cara'])),\n",
    "    ('lightgbm', LightGBMWrapper(**params))\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "features = ['antiguedad', 'habitaciones', 'garages', 'banos', 'metroscubiertos', 'metrostotales', 'lat',\n",
    " 'lng', 'fecha', 'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos',\n",
    " 'precio', 'clustering_label', 'idf_titulo', 'idf_descripcion', 'peso_titulo', 'peso_descripcion', 'porcentaje_metros', 'diferencia_metros', \n",
    " 'metroscubiertos_bins_unif', 'metroscubiertos_bins_perc', 'metros_totales_normalizados', 'metros_cubiertos_normalizados', \n",
    " 'escomercial', 'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad', 'tipo_propiedad_compartida',\n",
    " 'prop_frecuente', 'top_provincia', 'es_ciudad_centrica', 'promedio_metros_totales_provincia',\n",
    " 'promedio_metros_cubiertos_provincia', 'anio', 'mes', 'dia', 'trimestre', 'dias_desde_datos',  'meses_desde_datos',  \n",
    " 'delincuencia',  'turismo',  'es_antigua', 'antiguedad_bins_unif', 'antiguedad_bins_perc', \n",
    " 'cantidad_inquilinos',  'tam_ambientes', 'promedio_precio_provincia', 'promedio_precio_ciudad', 'promedio_precio_ciudad_gen', \n",
    " 'varianza_precio_ciudad', 'count_ciudad', 'promedio_id_zona', 'promedio_id_zona_gen',\n",
    " 'varianza_id_zona',  'count_id_zona',  'promedio_precio_tipo_propiedad', 'promedio_precio_tipo_propiedad_ciudad',\n",
    " 'promedio_precio_tipo_propiedad_ciudad_gen', 'count_tipo_propiedad', 'count_tipo_propiedad_ciudad', 'promedio_por_mes', \n",
    " 'varianza_por_mes', 'promedio_precio_habitaciones', 'promedio_precio_habitaciones_banos_garages', 'promedio_precio_banos_garages', \n",
    " 'promedio_precio_hbg_tipo_propiedad', 'lat_norm', 'lng_norm', 'promedio_precio_booleanos', 'puntaje', 'distancia_ciudad_centrica',\n",
    " 'distancia_centro_mexico', 'distancia_ciudad_cara']\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=2)\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)\n",
    "\n",
    "selector = RFECV(lgb_m, cv=4)\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "x_train.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=200, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=200, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=200, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])  \n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "hps = {'colsample_bytree': 0.9,\n",
    " 'eval_metric': 'mae',\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 10,\n",
    " 'n_estimators': 120,\n",
    " 'n_jobs': 4,\n",
    " 'objective': 'reg:squarederror',\n",
    " 'scale_pos_weight': 1,\n",
    " 'verbosity': 0}\n",
    "\n",
    "\n",
    "# n_estimators = int(hps['n_estimators'])\n",
    "# max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = Pipeline([\n",
    "    ('feature_selector', FeatureSelector(['antiguedad', 'habitaciones', 'garages', 'banos', 'metroscubiertos',\n",
    "       'metrostotales', 'lat', 'lng', 'fecha', 'gimnasio', 'usosmultiples',\n",
    "       'piscina', 'escuelascercanas', 'centroscomercialescercanos',\n",
    "       'clustering_label', 'idf_titulo', 'idf_descripcion', 'peso_titulo',\n",
    "       'peso_descripcion', 'porcentaje_metros', 'diferencia_metros',\n",
    "       'metroscubiertos_bins_unif', 'metros_totales_normalizados',\n",
    "       'metros_cubiertos_normalizados', 'escomercial',\n",
    "       'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad',\n",
    "       'tipo_propiedad_compartida', 'prop_frecuente', 'top_provincia',\n",
    "       'promedio_metros_totales_provincia',\n",
    "       'promedio_metros_cubiertos_provincia', 'anio', 'mes', 'dia',\n",
    "       'trimestre', 'dias_desde_datos', 'meses_desde_datos', 'delincuencia',\n",
    "       'turismo', 'es_antigua', 'antiguedad_bins_unif', 'antiguedad_bins_perc',\n",
    "       'cantidad_inquilinos', 'tam_ambientes', 'promedio_precio_provincia',\n",
    "       'promedio_precio_ciudad', 'promedio_precio_ciudad_gen',\n",
    "       'varianza_precio_ciudad', 'count_ciudad', 'promedio_id_zona',\n",
    "       'promedio_id_zona_gen', 'varianza_id_zona', 'count_id_zona',\n",
    "       'promedio_precio_tipo_propiedad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad_gen', 'count_tipo_propiedad',\n",
    "       'count_tipo_propiedad_ciudad', 'promedio_por_mes', 'varianza_por_mes',\n",
    "       'promedio_precio_habitaciones',\n",
    "       'promedio_precio_habitaciones_banos_garages',\n",
    "       'promedio_precio_banos_garages', 'promedio_precio_hbg_tipo_propiedad',\n",
    "       'lat_norm', 'lng_norm', 'promedio_precio_booleanos', 'puntaje',\n",
    "       'distancia_ciudad_centrica', 'distancia_centro_mexico',\n",
    "       'distancia_ciudad_cara'])),\n",
    "    ('xgboost', XGBoostWrapper(**hps))\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "features = ['antiguedad', 'habitaciones', 'garages', 'banos', 'metroscubiertos', 'metrostotales', 'lat',\n",
    " 'lng', 'fecha', 'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos',\n",
    " 'precio', 'clustering_label', 'idf_titulo', 'idf_descripcion', 'peso_titulo', 'peso_descripcion', 'porcentaje_metros', 'diferencia_metros', \n",
    " 'metroscubiertos_bins_unif', 'metroscubiertos_bins_perc', 'metros_totales_normalizados', 'metros_cubiertos_normalizados', \n",
    " 'escomercial', 'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad', 'tipo_propiedad_compartida',\n",
    " 'prop_frecuente', 'top_provincia', 'es_ciudad_centrica', 'promedio_metros_totales_provincia',\n",
    " 'promedio_metros_cubiertos_provincia', 'anio', 'mes', 'dia', 'trimestre', 'dias_desde_datos',  'meses_desde_datos',  \n",
    " 'delincuencia',  'turismo',  'es_antigua', 'antiguedad_bins_unif', 'antiguedad_bins_perc', \n",
    " 'cantidad_inquilinos',  'tam_ambientes', 'promedio_precio_provincia', 'promedio_precio_ciudad', 'promedio_precio_ciudad_gen', \n",
    " 'varianza_precio_ciudad', 'count_ciudad', 'promedio_id_zona', 'promedio_id_zona_gen',\n",
    " 'varianza_id_zona',  'count_id_zona',  'promedio_precio_tipo_propiedad', 'promedio_precio_tipo_propiedad_ciudad',\n",
    " 'promedio_precio_tipo_propiedad_ciudad_gen', 'count_tipo_propiedad', 'count_tipo_propiedad_ciudad', 'promedio_por_mes', \n",
    " 'varianza_por_mes', 'promedio_precio_habitaciones', 'promedio_precio_habitaciones_banos_garages', 'promedio_precio_banos_garages', \n",
    " 'promedio_precio_hbg_tipo_propiedad', 'lat_norm', 'lng_norm', 'promedio_precio_booleanos', 'puntaje', 'distancia_ciudad_centrica',\n",
    " 'distancia_centro_mexico', 'distancia_ciudad_cara']\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=2)\n",
    "\n",
    "hps['n_estimators'] = 20\n",
    "\n",
    "xgb_m_rfecv = XGBoostWrapper(**hps)\n",
    "\n",
    "selector = RFECV(xgb_m_rfecv, cv=4)\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "x_train.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {'bootstrap': False,\n",
    "          'max_features': 'sqrt',\n",
    "          'min_samples_split': 4,\n",
    "          'n_jobs': 2,\n",
    "          'n_estimators': 100}\n",
    "\n",
    "forest_m = Pipeline([\n",
    "    ('feature_selector', FeatureSelector(['antiguedad', 'garages', 'banos', 'metroscubiertos', 'metrostotales',\n",
    "       'lat', 'lng', 'fecha', 'idf_titulo', 'idf_descripcion',\n",
    "       'peso_descripcion', 'porcentaje_metros', 'diferencia_metros',\n",
    "       'metroscubiertos_bins_unif', 'metroscubiertos_bins_perc',\n",
    "       'metros_totales_normalizados', 'metros_cubiertos_normalizados',\n",
    "       'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad',\n",
    "       'promedio_metros_cubiertos_provincia', 'mes', 'dia', 'dias_desde_datos',\n",
    "       'meses_desde_datos', 'antiguedad_bins_perc', 'tam_ambientes',\n",
    "       'promedio_precio_provincia', 'promedio_precio_ciudad',\n",
    "       'promedio_precio_ciudad_gen', 'varianza_precio_ciudad', 'count_ciudad',\n",
    "       'promedio_id_zona', 'promedio_id_zona_gen', 'varianza_id_zona',\n",
    "       'count_id_zona', 'promedio_precio_tipo_propiedad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "       'count_tipo_propiedad_ciudad', 'promedio_por_mes', 'varianza_por_mes',\n",
    "       'promedio_precio_habitaciones_banos_garages',\n",
    "       'promedio_precio_banos_garages', 'promedio_precio_hbg_tipo_propiedad',\n",
    "       'lat_norm', 'lng_norm', 'puntaje', 'distancia_ciudad_centrica',\n",
    "       'distancia_centro_mexico', 'distancia_ciudad_cara'])),\n",
    "    ('random_forest', RandomForestRegressor(**params))\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "features = ['antiguedad', 'habitaciones', 'garages', 'banos', 'metroscubiertos', 'metrostotales', 'lat',\n",
    " 'lng', 'fecha', 'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos',\n",
    " 'precio', 'clustering_label', 'idf_titulo', 'idf_descripcion', 'peso_titulo', 'peso_descripcion', 'porcentaje_metros', 'diferencia_metros', \n",
    " 'metroscubiertos_bins_unif', 'metroscubiertos_bins_perc', 'metros_totales_normalizados', 'metros_cubiertos_normalizados', \n",
    " 'escomercial', 'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad', 'tipo_propiedad_compartida',\n",
    " 'prop_frecuente', 'top_provincia', 'es_ciudad_centrica', 'promedio_metros_totales_provincia',\n",
    " 'promedio_metros_cubiertos_provincia', 'anio', 'mes', 'dia', 'trimestre', 'dias_desde_datos',  'meses_desde_datos',  \n",
    " 'delincuencia',  'turismo',  'es_antigua', 'antiguedad_bins_unif', 'antiguedad_bins_perc', \n",
    " 'cantidad_inquilinos',  'tam_ambientes', 'promedio_precio_provincia', 'promedio_precio_ciudad', 'promedio_precio_ciudad_gen', \n",
    " 'varianza_precio_ciudad', 'count_ciudad', 'promedio_id_zona', 'promedio_id_zona_gen',\n",
    " 'varianza_id_zona',  'count_id_zona',  'promedio_precio_tipo_propiedad', 'promedio_precio_tipo_propiedad_ciudad',\n",
    " 'promedio_precio_tipo_propiedad_ciudad_gen', 'count_tipo_propiedad', 'count_tipo_propiedad_ciudad', 'promedio_por_mes', \n",
    " 'varianza_por_mes', 'promedio_precio_habitaciones', 'promedio_precio_habitaciones_banos_garages', 'promedio_precio_banos_garages', \n",
    " 'promedio_precio_hbg_tipo_propiedad', 'lat_norm', 'lng_norm', 'promedio_precio_booleanos', 'puntaje', 'distancia_ciudad_centrica',\n",
    " 'distancia_centro_mexico', 'distancia_ciudad_cara']\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=2)\n",
    "\n",
    "params['n_estimators'] = 20\n",
    "\n",
    "forest_m_rfecv = RandomForestRegressor(**params)\n",
    "\n",
    "selector = RFECV(forest_m_rfecv, cv=4)\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "x_train.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "params = {'criterion': 'mse',\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_split': 4}\n",
    "\n",
    "extratrees_m =  Pipeline([\n",
    "    ('feature_selector', FeatureSelector(['antiguedad', 'garages', 'banos', 'metroscubiertos', 'metrostotales',\n",
    "       'lat', 'lng', 'fecha', 'idf_titulo', 'idf_descripcion',\n",
    "       'peso_descripcion', 'porcentaje_metros', 'diferencia_metros',\n",
    "       'metroscubiertos_bins_unif', 'metroscubiertos_bins_perc',\n",
    "       'metros_totales_normalizados', 'metros_cubiertos_normalizados',\n",
    "       'promedio_metros_tipo_propiedad', 'promedio_metros_cub_tipo_propiedad',\n",
    "       'promedio_metros_cubiertos_provincia', 'mes', 'dia', 'dias_desde_datos',\n",
    "       'meses_desde_datos', 'antiguedad_bins_perc', 'tam_ambientes',\n",
    "       'promedio_precio_provincia', 'promedio_precio_ciudad',\n",
    "       'promedio_precio_ciudad_gen', 'varianza_precio_ciudad', 'count_ciudad',\n",
    "       'promedio_id_zona', 'promedio_id_zona_gen', 'varianza_id_zona',\n",
    "       'count_id_zona', 'promedio_precio_tipo_propiedad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "       'count_tipo_propiedad_ciudad', 'promedio_por_mes', 'varianza_por_mes',\n",
    "       'promedio_precio_habitaciones_banos_garages',\n",
    "       'promedio_precio_banos_garages', 'promedio_precio_hbg_tipo_propiedad',\n",
    "       'lat_norm', 'lng_norm', 'puntaje', 'distancia_ciudad_centrica',\n",
    "       'distancia_centro_mexico', 'distancia_ciudad_cara'])),\n",
    "    ('extra_trees', ExtraTreesRegressor(n_estimators=50, **params))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [4]\n",
      "\n",
      "estimator  0: [lightgbm: Pipeline]\n",
      "    fold  0:  [30894.48877436]\n",
      "    fold  1:  [30773.43711385]\n",
      "    fold  2:  [30738.06005553]\n",
      "    fold  3:  [31034.08139174]\n",
      "    ----\n",
      "    MEAN:     [30860.01683387] + [116.03478863]\n",
      "\n",
      "estimator  1: [randomforest: Pipeline]\n",
      "    fold  0:  [29562.01964742]\n",
      "    fold  1:  [29578.82410809]\n",
      "    fold  2:  [29625.88735087]\n",
      "    fold  3:  [29764.68936975]\n",
      "    ----\n",
      "    MEAN:     [29632.85511903] + [79.63327451]\n",
      "\n",
      "estimator  2: [extratrees: Pipeline]\n",
      "    fold  0:  [30936.64356105]\n",
      "    fold  1:  [30973.31970189]\n",
      "    fold  2:  [30972.46584201]\n",
      "    fold  3:  [31149.64898602]\n",
      "    ----\n",
      "    MEAN:     [31008.01952274] + [83.09869818]\n",
      "\n",
      "estimator  3: [xgboost: Pipeline]\n",
      "    fold  0:  [29742.79297482]\n",
      "    fold  1:  [29662.30533126]\n",
      "    fold  2:  [29722.12012999]\n",
      "    fold  3:  [29801.85740774]\n",
      "    ----\n",
      "    MEAN:     [29732.26896095] + [49.87788850]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingTransformer(estimators=[('lightgbm',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('feature_selector',\n",
       "                                                  FeatureSelector(features=['antiguedad',\n",
       "                                                                            'habitaciones',\n",
       "                                                                            'garages',\n",
       "                                                                            'banos',\n",
       "                                                                            'metroscubiertos',\n",
       "                                                                            'metrostotales',\n",
       "                                                                            'lat',\n",
       "                                                                            'lng',\n",
       "                                                                            'fecha',\n",
       "                                                                            'piscina',\n",
       "                                                                            'escuelascercanas',\n",
       "                                                                            'centroscomercialescercanos',\n",
       "                                                                            'clustering_label',\n",
       "                                                                            'idf_titulo',\n",
       "                                                                            'idf_descripcion',\n",
       "                                                                            'peso_titulo',\n",
       "                                                                            'peso_desc...\n",
       "                                                                 n_estimators=120,\n",
       "                                                                 n_jobs=4,\n",
       "                                                                 nthread=None,\n",
       "                                                                 objective='reg:squarederror',\n",
       "                                                                 random_state=0,\n",
       "                                                                 reg_alpha=0,\n",
       "                                                                 reg_lambda=1,\n",
       "                                                                 scale_pos_weight=1,\n",
       "                                                                 seed=None,\n",
       "                                                                 silent=None,\n",
       "                                                                 subsample=1,\n",
       "                                                                 verbosity=0))],\n",
       "                                          verbose=False))],\n",
       "                    metric=None, n_folds=4, needs_proba=False, random_state=0,\n",
       "                    regression=True, shuffle=False, stratified=False,\n",
       "                    transform_pred=None, transform_target=None, variant='A',\n",
       "                    verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from vecstack import stacking\n",
    "from vecstack_sk import StackingTransformer\n",
    "\n",
    "modelos = [\n",
    "           ('lightgbm', lgb_m), \n",
    "           ('randomforest', forest_m),\n",
    "           ('extratrees', extratrees_m),\n",
    "           ('xgboost', xgb_m)\n",
    "          ]\n",
    "\n",
    "stack = StackingTransformer(modelos, \n",
    "                          regression=True, verbose=2, n_folds=4)\n",
    "\n",
    "stack.fit(df_train_f.drop('precio', axis=1).values, \n",
    "                          df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [randomforest: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [extratrees: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [xgboost: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [randomforest: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [extratrees: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [xgboost: Pipeline]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(df_train_f.drop('precio', axis=1).values)\n",
    "s_test = stack.transform(df_test_f.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'], df_train_s['stack03'], df_train_s['stack04'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'], df_test_s['stack03'], df_test_s['stack04'] = zip(*s_test)\n",
    "\n",
    "features_stacking = ['stack01', 'stack02', 'stack03', 'stack04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8999882607358867, bagging_freq=95,\n",
       "                boosting_type='dart', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.2570109385381975, importance_type='split',\n",
       "                learning_rate=0.13601832720254403, max_depth=26, metric='mae',\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                num_boost_round=800, num_leaves=175, objective='regression',\n",
       "                random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "                test_size=0.08363501292068126)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['habitaciones', 'garages','banos','antiguedad', 'metroscubiertos',  'metrostotales','lat_norm', \n",
    "           'lng_norm', 'gimnasio', 'usosmultiples', 'piscina']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', 'anio', 'promedio_id_zona', \n",
    "                 'promedio_precio_tipo_propiedad', 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                 'count_tipo_propiedad_ciudad', 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "                 'dias_desde_datos','meses_desde_datos','porcentaje_metros','distancia_ciudad_centrica', \n",
    "                 'clustering_label', 'distancia_centro_mexico'\n",
    "                ]\n",
    "\n",
    "features += features_test\n",
    "\n",
    "\n",
    "params_2nd = {'bagging_fraction': 0.8999882607358867,\n",
    " 'bagging_freq': int(95.0),\n",
    " 'feature_fraction': 0.2570109385381975,\n",
    " 'learning_rate': 0.13601832720254403,\n",
    " 'max_depth': int(26.0),\n",
    " 'num_leaves': int(175.0),\n",
    " 'test_size': 0.08363501292068126,\n",
    " 'boosting_type': 'dart',\n",
    " 'num_boost_round': 800,\n",
    " 'objective': 'regression',\n",
    " 'metric': 'mae'}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + features_stacking), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + features_stacking))\n",
    "df_test_s = utils.pesificar_df(df_test_s, col_precio_in='target', col_precio_out='target')\n",
    "df_test_s[['id', 'target']].to_csv('respuesta45.csv', index = False)\n",
    "\n",
    "# print(f'MAE Stacking-full: {utils.MAE(df_test_s[\"precio\"].values, df_test_s[\"target\"].values)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    "#  'bagging_freq': int(36.0),\n",
    "#  'feature_fraction': 0.16167385124183287,\n",
    "#  'learning_rate': 0.054693418899570134,\n",
    "#  'max_depth': int(4.0),\n",
    "#  'num_leaves': int(93.0),\n",
    "#  'objective': 'regression',\n",
    "#  'boosting_type': 'gbdt',\n",
    "#  'metric': 'mae'}\n",
    "\n",
    "params_2nd = {'bagging_fraction': 0.8243831977099841,\n",
    " 'bagging_freq': int(10.0),\n",
    " 'feature_fraction': 0.9228324501365147,\n",
    " 'learning_rate': 0.050664243951241736,\n",
    " 'max_depth': int(3.0),\n",
    " 'num_leaves': int(78.0),\n",
    " 'objective': 'regression',\n",
    " 'boosting_type': 'dart',\n",
    " 'metric': 'mae'}\n",
    "\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(s_train, df_train_f['precio'].values)\n",
    "\n",
    "df_test_f['target'] = lgb_m_2nd.predict(s_test)\n",
    "df_test_f[['id', 'target']].to_csv('respuesta43.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:21<00:00,  2.60s/it, best loss: 511432.09539443516]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8243831977099841,\n",
       " 'bagging_freq': 10.0,\n",
       " 'feature_fraction': 0.9228324501365147,\n",
       " 'learning_rate': 0.050664243951241736,\n",
       " 'max_depth': 3.0,\n",
       " 'num_leaves': 78.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03', 'stack04']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, df_train['precio'].values)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=250,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(df_test['precio'].values, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 15, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.90, 1), hp.uniform('bagging_fraction', 0.70, 1),\n",
    "        hp.quniform('bagging_freq', 0, 40, 1), hp.quniform('max_depth', 3, 15, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=400, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f['target'] = np.average(s_test, axis=1)\n",
    "df_test_f[['id', 'target']].to_csv('respuesta44.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Stacking only: 519840.412728738\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_test = mode(s_test, axis=1)[0]\n",
    "print(f\"MAE Stacking only: {utils.MAE(y_pred_test, df_test_f['precio'].values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Stacking only: 502391.48180612386\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred_test = np.average(s_test, axis=1)\n",
    "print(f\"MAE Stacking only: {utils.MAE(y_pred_test, df_test_f['precio'].values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 497375.416620218\n",
       " hess_inv: array([[ 7.64527106e-05, -6.84363088e-05,  5.18102889e-04,\n",
       "         1.30966978e-03],\n",
       "       [-6.84363088e-05,  6.84021400e-05, -4.91721763e-04,\n",
       "        -1.17091868e-03],\n",
       "       [ 5.18102889e-04, -4.91721763e-04,  4.00738244e-03,\n",
       "         9.31303274e-03],\n",
       "       [ 1.30966978e-03, -1.17091868e-03,  9.31303274e-03,\n",
       "         2.30019160e-02]])\n",
       "      jac: array([5.8359375 , 2.96484375, 0.3671875 , 1.5859375 ])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 702\n",
       "      nit: 15\n",
       "     njev: 115\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 0.40410989, -0.16217251,  2.30245548,  0.39816892])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def mae_res(weights):\n",
    "    y_pred_test = np.average(s_test, weights=weights, axis=1)\n",
    "    return utils.MAE(y_pred_test, df_test_f['precio'].values)\n",
    "\n",
    "x0 = [1] * len(s_test.T)\n",
    "minimize(mae_res, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 497375.4169548869\n",
       "     jac: array([-0.58207661, -0.83819032, -0.23283064,  1.65309757])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 425\n",
       "     nit: 5\n",
       " success: True\n",
       "       x: array([ 0.49248228, -0.19790651,  2.80637364,  0.48548681])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "def mae_res(weights):\n",
    "    y_pred_test = np.average(s_test, weights=weights, axis=1)\n",
    "    return utils.MAE(y_pred_test, df_test_f['precio'].values)\n",
    "\n",
    "x0 = [(-3, 4)] * len(s_test.T)\n",
    "differential_evolution(mae_res, bounds=x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
