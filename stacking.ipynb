{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "\n",
    "df_train = pd.read_csv('./data/train_filtrado.csv')\n",
    "df_train['precio'] = np.log(df_train['precio'])\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.08363501292068126)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8988911725316586,\n",
    " 'bagging_freq': 22.0,\n",
    " 'feature_fraction': 0.6622442122619671,\n",
    " 'learning_rate': 0.16422725363286422,\n",
    " 'max_depth': 22.0,\n",
    " 'num_leaves': 180.0,\n",
    " 'test_size': 0.20892455926004772}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [0.19816413]\n",
      "    fold  1:  [0.19671501]\n",
      "    fold  2:  [0.19689668]\n",
      "    fold  3:  [0.19677309]\n",
      "    ----\n",
      "    MEAN:     [0.19713723] + [0.00059650]\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "[16:11:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9622\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2878\n",
      "[2]\tvalidation_0-mae:8.84783\n",
      "[3]\tvalidation_0-mae:7.60936\n",
      "[4]\tvalidation_0-mae:6.54425\n",
      "[5]\tvalidation_0-mae:5.62825\n",
      "[6]\tvalidation_0-mae:4.84051\n",
      "[7]\tvalidation_0-mae:4.16301\n",
      "[8]\tvalidation_0-mae:3.5804\n",
      "[9]\tvalidation_0-mae:3.07941\n",
      "[10]\tvalidation_0-mae:2.64855\n",
      "[11]\tvalidation_0-mae:2.27806\n",
      "[12]\tvalidation_0-mae:1.95949\n",
      "[13]\tvalidation_0-mae:1.68566\n",
      "[14]\tvalidation_0-mae:1.45036\n",
      "[15]\tvalidation_0-mae:1.24828\n",
      "[16]\tvalidation_0-mae:1.07488\n",
      "[17]\tvalidation_0-mae:0.926344\n",
      "[18]\tvalidation_0-mae:0.799341\n",
      "[19]\tvalidation_0-mae:0.690821\n",
      "[20]\tvalidation_0-mae:0.598202\n",
      "[21]\tvalidation_0-mae:0.519275\n",
      "[22]\tvalidation_0-mae:0.452406\n",
      "[23]\tvalidation_0-mae:0.395753\n",
      "[24]\tvalidation_0-mae:0.347891\n",
      "[25]\tvalidation_0-mae:0.30835\n",
      "[26]\tvalidation_0-mae:0.274626\n",
      "[27]\tvalidation_0-mae:0.246982\n",
      "[28]\tvalidation_0-mae:0.223431\n",
      "[29]\tvalidation_0-mae:0.204688\n",
      "[30]\tvalidation_0-mae:0.188831\n",
      "[31]\tvalidation_0-mae:0.176535\n",
      "[32]\tvalidation_0-mae:0.16591\n",
      "[33]\tvalidation_0-mae:0.157389\n",
      "[34]\tvalidation_0-mae:0.149902\n",
      "[35]\tvalidation_0-mae:0.143288\n",
      "[36]\tvalidation_0-mae:0.138\n",
      "[37]\tvalidation_0-mae:0.133671\n",
      "[38]\tvalidation_0-mae:0.129504\n",
      "[39]\tvalidation_0-mae:0.12641\n",
      "[40]\tvalidation_0-mae:0.123038\n",
      "[41]\tvalidation_0-mae:0.120376\n",
      "[42]\tvalidation_0-mae:0.118167\n",
      "[43]\tvalidation_0-mae:0.115367\n",
      "[44]\tvalidation_0-mae:0.113176\n",
      "[45]\tvalidation_0-mae:0.111205\n",
      "[46]\tvalidation_0-mae:0.109098\n",
      "[47]\tvalidation_0-mae:0.107328\n",
      "[48]\tvalidation_0-mae:0.105338\n",
      "[49]\tvalidation_0-mae:0.103785\n",
      "[50]\tvalidation_0-mae:0.101935\n",
      "[51]\tvalidation_0-mae:0.100399\n",
      "[52]\tvalidation_0-mae:0.098819\n",
      "[53]\tvalidation_0-mae:0.097004\n",
      "[54]\tvalidation_0-mae:0.09532\n",
      "[55]\tvalidation_0-mae:0.094001\n",
      "[56]\tvalidation_0-mae:0.092147\n",
      "[57]\tvalidation_0-mae:0.090923\n",
      "[58]\tvalidation_0-mae:0.08967\n",
      "[59]\tvalidation_0-mae:0.088698\n",
      "[60]\tvalidation_0-mae:0.087201\n",
      "[61]\tvalidation_0-mae:0.085822\n",
      "[62]\tvalidation_0-mae:0.084576\n",
      "[63]\tvalidation_0-mae:0.083403\n",
      "[64]\tvalidation_0-mae:0.082483\n",
      "[65]\tvalidation_0-mae:0.081587\n",
      "[66]\tvalidation_0-mae:0.080959\n",
      "[67]\tvalidation_0-mae:0.080326\n",
      "[68]\tvalidation_0-mae:0.079633\n",
      "[69]\tvalidation_0-mae:0.078438\n",
      "[70]\tvalidation_0-mae:0.077818\n",
      "[71]\tvalidation_0-mae:0.077506\n",
      "[72]\tvalidation_0-mae:0.076646\n",
      "[73]\tvalidation_0-mae:0.07583\n",
      "[74]\tvalidation_0-mae:0.075144\n",
      "[75]\tvalidation_0-mae:0.074655\n",
      "[76]\tvalidation_0-mae:0.073732\n",
      "[77]\tvalidation_0-mae:0.072669\n",
      "[78]\tvalidation_0-mae:0.071594\n",
      "[79]\tvalidation_0-mae:0.070483\n",
      "[80]\tvalidation_0-mae:0.070217\n",
      "[81]\tvalidation_0-mae:0.069473\n",
      "[82]\tvalidation_0-mae:0.068625\n",
      "[83]\tvalidation_0-mae:0.067858\n",
      "[84]\tvalidation_0-mae:0.067618\n",
      "[85]\tvalidation_0-mae:0.067327\n",
      "[86]\tvalidation_0-mae:0.067057\n",
      "[87]\tvalidation_0-mae:0.066769\n",
      "[88]\tvalidation_0-mae:0.066\n",
      "[89]\tvalidation_0-mae:0.065304\n",
      "[90]\tvalidation_0-mae:0.064602\n",
      "[91]\tvalidation_0-mae:0.064332\n",
      "[92]\tvalidation_0-mae:0.064216\n",
      "[93]\tvalidation_0-mae:0.063911\n",
      "[94]\tvalidation_0-mae:0.063694\n",
      "[95]\tvalidation_0-mae:0.063304\n",
      "[96]\tvalidation_0-mae:0.063056\n",
      "[97]\tvalidation_0-mae:0.06232\n",
      "[98]\tvalidation_0-mae:0.062006\n",
      "[99]\tvalidation_0-mae:0.061732\n",
      "[100]\tvalidation_0-mae:0.061044\n",
      "[101]\tvalidation_0-mae:0.060762\n",
      "[102]\tvalidation_0-mae:0.060576\n",
      "[103]\tvalidation_0-mae:0.060404\n",
      "[104]\tvalidation_0-mae:0.060234\n",
      "[105]\tvalidation_0-mae:0.059875\n",
      "[106]\tvalidation_0-mae:0.059595\n",
      "[107]\tvalidation_0-mae:0.059274\n",
      "[108]\tvalidation_0-mae:0.058738\n",
      "[109]\tvalidation_0-mae:0.058573\n",
      "[110]\tvalidation_0-mae:0.05814\n",
      "[111]\tvalidation_0-mae:0.057682\n",
      "[112]\tvalidation_0-mae:0.057423\n",
      "[113]\tvalidation_0-mae:0.05706\n",
      "[114]\tvalidation_0-mae:0.056978\n",
      "[115]\tvalidation_0-mae:0.056745\n",
      "[116]\tvalidation_0-mae:0.056509\n",
      "[117]\tvalidation_0-mae:0.056074\n",
      "[118]\tvalidation_0-mae:0.05572\n",
      "[119]\tvalidation_0-mae:0.055417\n",
      "[120]\tvalidation_0-mae:0.054996\n",
      "[121]\tvalidation_0-mae:0.0545\n",
      "[122]\tvalidation_0-mae:0.05397\n",
      "[123]\tvalidation_0-mae:0.053628\n",
      "[124]\tvalidation_0-mae:0.053416\n",
      "[125]\tvalidation_0-mae:0.053185\n",
      "[126]\tvalidation_0-mae:0.053031\n",
      "[127]\tvalidation_0-mae:0.05274\n",
      "[128]\tvalidation_0-mae:0.052601\n",
      "[129]\tvalidation_0-mae:0.052245\n",
      "[130]\tvalidation_0-mae:0.052042\n",
      "[131]\tvalidation_0-mae:0.051958\n",
      "[132]\tvalidation_0-mae:0.051847\n",
      "[133]\tvalidation_0-mae:0.050835\n",
      "[134]\tvalidation_0-mae:0.05059\n",
      "[135]\tvalidation_0-mae:0.05016\n",
      "[136]\tvalidation_0-mae:0.050022\n",
      "[137]\tvalidation_0-mae:0.049536\n",
      "[138]\tvalidation_0-mae:0.04931\n",
      "[139]\tvalidation_0-mae:0.048572\n",
      "[140]\tvalidation_0-mae:0.048072\n",
      "[141]\tvalidation_0-mae:0.047757\n",
      "[142]\tvalidation_0-mae:0.047577\n",
      "[143]\tvalidation_0-mae:0.047434\n",
      "[144]\tvalidation_0-mae:0.047042\n",
      "[145]\tvalidation_0-mae:0.04657\n",
      "[146]\tvalidation_0-mae:0.046516\n",
      "[147]\tvalidation_0-mae:0.046195\n",
      "[148]\tvalidation_0-mae:0.046078\n",
      "[149]\tvalidation_0-mae:0.045795\n",
      "    fold  0:  [0.18835141]\n",
      "[16:12:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9627\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2882\n",
      "[2]\tvalidation_0-mae:8.84813\n",
      "[3]\tvalidation_0-mae:7.60963\n",
      "[4]\tvalidation_0-mae:6.54448\n",
      "[5]\tvalidation_0-mae:5.62841\n",
      "[6]\tvalidation_0-mae:4.84062\n",
      "[7]\tvalidation_0-mae:4.16313\n",
      "[8]\tvalidation_0-mae:3.58055\n",
      "[9]\tvalidation_0-mae:3.07951\n",
      "[10]\tvalidation_0-mae:2.64863\n",
      "[11]\tvalidation_0-mae:2.27811\n",
      "[12]\tvalidation_0-mae:1.95953\n",
      "[13]\tvalidation_0-mae:1.68569\n",
      "[14]\tvalidation_0-mae:1.45039\n",
      "[15]\tvalidation_0-mae:1.24829\n",
      "[16]\tvalidation_0-mae:1.07485\n",
      "[17]\tvalidation_0-mae:0.926285\n",
      "[18]\tvalidation_0-mae:0.799263\n",
      "[19]\tvalidation_0-mae:0.690681\n",
      "[20]\tvalidation_0-mae:0.598045\n",
      "[21]\tvalidation_0-mae:0.519207\n",
      "[22]\tvalidation_0-mae:0.452341\n",
      "[23]\tvalidation_0-mae:0.395654\n",
      "[24]\tvalidation_0-mae:0.347745\n",
      "[25]\tvalidation_0-mae:0.308364\n",
      "[26]\tvalidation_0-mae:0.274783\n",
      "[27]\tvalidation_0-mae:0.246827\n",
      "[28]\tvalidation_0-mae:0.223584\n",
      "[29]\tvalidation_0-mae:0.204791\n",
      "[30]\tvalidation_0-mae:0.189051\n",
      "[31]\tvalidation_0-mae:0.176579\n",
      "[32]\tvalidation_0-mae:0.16635\n",
      "[33]\tvalidation_0-mae:0.157739\n",
      "[34]\tvalidation_0-mae:0.150211\n",
      "[35]\tvalidation_0-mae:0.144194\n",
      "[36]\tvalidation_0-mae:0.138454\n",
      "[37]\tvalidation_0-mae:0.133699\n",
      "[38]\tvalidation_0-mae:0.129615\n",
      "[39]\tvalidation_0-mae:0.125514\n",
      "[40]\tvalidation_0-mae:0.122105\n",
      "[41]\tvalidation_0-mae:0.118562\n",
      "[42]\tvalidation_0-mae:0.116111\n",
      "[43]\tvalidation_0-mae:0.113078\n",
      "[44]\tvalidation_0-mae:0.110339\n",
      "[45]\tvalidation_0-mae:0.108408\n",
      "[46]\tvalidation_0-mae:0.106931\n",
      "[47]\tvalidation_0-mae:0.104943\n",
      "[48]\tvalidation_0-mae:0.102928\n",
      "[49]\tvalidation_0-mae:0.101339\n",
      "[50]\tvalidation_0-mae:0.099371\n",
      "[51]\tvalidation_0-mae:0.097555\n",
      "[52]\tvalidation_0-mae:0.095646\n",
      "[53]\tvalidation_0-mae:0.094426\n",
      "[54]\tvalidation_0-mae:0.09286\n",
      "[55]\tvalidation_0-mae:0.09114\n",
      "[56]\tvalidation_0-mae:0.08979\n",
      "[57]\tvalidation_0-mae:0.08882\n",
      "[58]\tvalidation_0-mae:0.087673\n",
      "[59]\tvalidation_0-mae:0.086967\n",
      "[60]\tvalidation_0-mae:0.086519\n",
      "[61]\tvalidation_0-mae:0.085102\n",
      "[62]\tvalidation_0-mae:0.084336\n",
      "[63]\tvalidation_0-mae:0.083877\n",
      "[64]\tvalidation_0-mae:0.082615\n",
      "[65]\tvalidation_0-mae:0.081666\n",
      "[66]\tvalidation_0-mae:0.080764\n",
      "[67]\tvalidation_0-mae:0.079684\n",
      "[68]\tvalidation_0-mae:0.078771\n",
      "[69]\tvalidation_0-mae:0.077826\n",
      "[70]\tvalidation_0-mae:0.077036\n",
      "[71]\tvalidation_0-mae:0.076324\n",
      "[72]\tvalidation_0-mae:0.075278\n",
      "[73]\tvalidation_0-mae:0.075096\n",
      "[74]\tvalidation_0-mae:0.074608\n",
      "[75]\tvalidation_0-mae:0.0737\n",
      "[76]\tvalidation_0-mae:0.072606\n",
      "[77]\tvalidation_0-mae:0.072086\n",
      "[78]\tvalidation_0-mae:0.071824\n",
      "[79]\tvalidation_0-mae:0.071249\n",
      "[80]\tvalidation_0-mae:0.070506\n",
      "[81]\tvalidation_0-mae:0.070155\n",
      "[82]\tvalidation_0-mae:0.068906\n",
      "[83]\tvalidation_0-mae:0.067921\n",
      "[84]\tvalidation_0-mae:0.067743\n",
      "[85]\tvalidation_0-mae:0.067276\n",
      "[86]\tvalidation_0-mae:0.067011\n",
      "[87]\tvalidation_0-mae:0.066608\n",
      "[88]\tvalidation_0-mae:0.066344\n",
      "[89]\tvalidation_0-mae:0.065909\n",
      "[90]\tvalidation_0-mae:0.065537\n",
      "[91]\tvalidation_0-mae:0.064976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\tvalidation_0-mae:0.064766\n",
      "[93]\tvalidation_0-mae:0.064206\n",
      "[94]\tvalidation_0-mae:0.063814\n",
      "[95]\tvalidation_0-mae:0.063618\n",
      "[96]\tvalidation_0-mae:0.063009\n",
      "[97]\tvalidation_0-mae:0.062803\n",
      "[98]\tvalidation_0-mae:0.062441\n",
      "[99]\tvalidation_0-mae:0.06176\n",
      "[100]\tvalidation_0-mae:0.061275\n",
      "[101]\tvalidation_0-mae:0.060987\n",
      "[102]\tvalidation_0-mae:0.060652\n",
      "[103]\tvalidation_0-mae:0.060446\n",
      "[104]\tvalidation_0-mae:0.059618\n",
      "[105]\tvalidation_0-mae:0.059303\n",
      "[106]\tvalidation_0-mae:0.059052\n",
      "[107]\tvalidation_0-mae:0.058516\n",
      "[108]\tvalidation_0-mae:0.057942\n",
      "[109]\tvalidation_0-mae:0.057567\n",
      "[110]\tvalidation_0-mae:0.057369\n",
      "[111]\tvalidation_0-mae:0.056871\n",
      "[112]\tvalidation_0-mae:0.056793\n",
      "[113]\tvalidation_0-mae:0.055902\n",
      "[114]\tvalidation_0-mae:0.055655\n",
      "[115]\tvalidation_0-mae:0.055121\n",
      "[116]\tvalidation_0-mae:0.055049\n",
      "[117]\tvalidation_0-mae:0.054822\n",
      "[118]\tvalidation_0-mae:0.054197\n",
      "[119]\tvalidation_0-mae:0.053884\n",
      "[120]\tvalidation_0-mae:0.053805\n",
      "[121]\tvalidation_0-mae:0.053455\n",
      "[122]\tvalidation_0-mae:0.053004\n",
      "[123]\tvalidation_0-mae:0.052871\n",
      "[124]\tvalidation_0-mae:0.05232\n",
      "[125]\tvalidation_0-mae:0.052242\n",
      "[126]\tvalidation_0-mae:0.051918\n",
      "[127]\tvalidation_0-mae:0.051741\n",
      "[128]\tvalidation_0-mae:0.051476\n",
      "[129]\tvalidation_0-mae:0.05118\n",
      "[130]\tvalidation_0-mae:0.050926\n",
      "[131]\tvalidation_0-mae:0.050824\n",
      "[132]\tvalidation_0-mae:0.050694\n",
      "[133]\tvalidation_0-mae:0.050428\n",
      "[134]\tvalidation_0-mae:0.04999\n",
      "[135]\tvalidation_0-mae:0.049466\n",
      "[136]\tvalidation_0-mae:0.049277\n",
      "[137]\tvalidation_0-mae:0.049119\n",
      "[138]\tvalidation_0-mae:0.048895\n",
      "[139]\tvalidation_0-mae:0.048739\n",
      "[140]\tvalidation_0-mae:0.048397\n",
      "[141]\tvalidation_0-mae:0.048223\n",
      "[142]\tvalidation_0-mae:0.047796\n",
      "[143]\tvalidation_0-mae:0.047665\n",
      "[144]\tvalidation_0-mae:0.047283\n",
      "[145]\tvalidation_0-mae:0.047176\n",
      "[146]\tvalidation_0-mae:0.047071\n",
      "[147]\tvalidation_0-mae:0.046942\n",
      "[148]\tvalidation_0-mae:0.046712\n",
      "[149]\tvalidation_0-mae:0.046606\n",
      "    fold  1:  [0.18706029]\n",
      "[16:13:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9606\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.2864\n",
      "[2]\tvalidation_0-mae:8.8466\n",
      "[3]\tvalidation_0-mae:7.60833\n",
      "[4]\tvalidation_0-mae:6.54333\n",
      "[5]\tvalidation_0-mae:5.62742\n",
      "[6]\tvalidation_0-mae:4.83981\n",
      "[7]\tvalidation_0-mae:4.16245\n",
      "[8]\tvalidation_0-mae:3.57995\n",
      "[9]\tvalidation_0-mae:3.07902\n",
      "[10]\tvalidation_0-mae:2.64818\n",
      "[11]\tvalidation_0-mae:2.27771\n",
      "[12]\tvalidation_0-mae:1.95921\n",
      "[13]\tvalidation_0-mae:1.68546\n",
      "[14]\tvalidation_0-mae:1.45014\n",
      "[15]\tvalidation_0-mae:1.24807\n",
      "[16]\tvalidation_0-mae:1.07471\n",
      "[17]\tvalidation_0-mae:0.926249\n",
      "[18]\tvalidation_0-mae:0.799264\n",
      "[19]\tvalidation_0-mae:0.690793\n",
      "[20]\tvalidation_0-mae:0.598178\n",
      "[21]\tvalidation_0-mae:0.519189\n",
      "[22]\tvalidation_0-mae:0.452309\n",
      "[23]\tvalidation_0-mae:0.395628\n",
      "[24]\tvalidation_0-mae:0.347601\n",
      "[25]\tvalidation_0-mae:0.308101\n",
      "[26]\tvalidation_0-mae:0.274529\n",
      "[27]\tvalidation_0-mae:0.246734\n",
      "[28]\tvalidation_0-mae:0.223473\n",
      "[29]\tvalidation_0-mae:0.204814\n",
      "[30]\tvalidation_0-mae:0.189098\n",
      "[31]\tvalidation_0-mae:0.176661\n",
      "[32]\tvalidation_0-mae:0.166395\n",
      "[33]\tvalidation_0-mae:0.157587\n",
      "[34]\tvalidation_0-mae:0.149809\n",
      "[35]\tvalidation_0-mae:0.143827\n",
      "[36]\tvalidation_0-mae:0.13823\n",
      "[37]\tvalidation_0-mae:0.133428\n",
      "[38]\tvalidation_0-mae:0.129782\n",
      "[39]\tvalidation_0-mae:0.125526\n",
      "[40]\tvalidation_0-mae:0.122418\n",
      "[41]\tvalidation_0-mae:0.11938\n",
      "[42]\tvalidation_0-mae:0.11714\n",
      "[43]\tvalidation_0-mae:0.114676\n",
      "[44]\tvalidation_0-mae:0.112527\n",
      "[45]\tvalidation_0-mae:0.110737\n",
      "[46]\tvalidation_0-mae:0.10899\n",
      "[47]\tvalidation_0-mae:0.107163\n",
      "[48]\tvalidation_0-mae:0.105444\n",
      "[49]\tvalidation_0-mae:0.10375\n",
      "[50]\tvalidation_0-mae:0.102174\n",
      "[51]\tvalidation_0-mae:0.100304\n",
      "[52]\tvalidation_0-mae:0.09891\n",
      "[53]\tvalidation_0-mae:0.097226\n",
      "[54]\tvalidation_0-mae:0.095572\n",
      "[55]\tvalidation_0-mae:0.093526\n",
      "[56]\tvalidation_0-mae:0.091642\n",
      "[57]\tvalidation_0-mae:0.0906\n",
      "[58]\tvalidation_0-mae:0.089963\n",
      "[59]\tvalidation_0-mae:0.088332\n",
      "[60]\tvalidation_0-mae:0.0872\n",
      "[61]\tvalidation_0-mae:0.086212\n",
      "[62]\tvalidation_0-mae:0.085699\n",
      "[63]\tvalidation_0-mae:0.08522\n",
      "[64]\tvalidation_0-mae:0.084418\n",
      "[65]\tvalidation_0-mae:0.083591\n",
      "[66]\tvalidation_0-mae:0.082438\n",
      "[67]\tvalidation_0-mae:0.081375\n",
      "[68]\tvalidation_0-mae:0.080583\n",
      "[69]\tvalidation_0-mae:0.079797\n",
      "[70]\tvalidation_0-mae:0.07843\n",
      "[71]\tvalidation_0-mae:0.077813\n",
      "[72]\tvalidation_0-mae:0.07653\n",
      "[73]\tvalidation_0-mae:0.075548\n",
      "[74]\tvalidation_0-mae:0.074863\n",
      "[75]\tvalidation_0-mae:0.073902\n",
      "[76]\tvalidation_0-mae:0.073559\n",
      "[77]\tvalidation_0-mae:0.072905\n",
      "[78]\tvalidation_0-mae:0.071785\n",
      "[79]\tvalidation_0-mae:0.070907\n",
      "[80]\tvalidation_0-mae:0.070307\n",
      "[81]\tvalidation_0-mae:0.069594\n",
      "[82]\tvalidation_0-mae:0.069026\n",
      "[83]\tvalidation_0-mae:0.068581\n",
      "[84]\tvalidation_0-mae:0.068205\n",
      "[85]\tvalidation_0-mae:0.067787\n",
      "[86]\tvalidation_0-mae:0.067097\n",
      "[87]\tvalidation_0-mae:0.066841\n",
      "[88]\tvalidation_0-mae:0.066712\n",
      "[89]\tvalidation_0-mae:0.066273\n",
      "[90]\tvalidation_0-mae:0.065636\n",
      "[91]\tvalidation_0-mae:0.0654\n",
      "[92]\tvalidation_0-mae:0.064761\n",
      "[93]\tvalidation_0-mae:0.064578\n",
      "[94]\tvalidation_0-mae:0.06362\n",
      "[95]\tvalidation_0-mae:0.063341\n",
      "[96]\tvalidation_0-mae:0.062969\n",
      "[97]\tvalidation_0-mae:0.062534\n",
      "[98]\tvalidation_0-mae:0.061984\n",
      "[99]\tvalidation_0-mae:0.061655\n",
      "[100]\tvalidation_0-mae:0.061454\n",
      "[101]\tvalidation_0-mae:0.060985\n",
      "[102]\tvalidation_0-mae:0.060394\n",
      "[103]\tvalidation_0-mae:0.060176\n",
      "[104]\tvalidation_0-mae:0.059581\n",
      "[105]\tvalidation_0-mae:0.059286\n",
      "[106]\tvalidation_0-mae:0.058886\n",
      "[107]\tvalidation_0-mae:0.058297\n",
      "[108]\tvalidation_0-mae:0.058011\n",
      "[109]\tvalidation_0-mae:0.057644\n",
      "[110]\tvalidation_0-mae:0.057317\n",
      "[111]\tvalidation_0-mae:0.056741\n",
      "[112]\tvalidation_0-mae:0.056467\n",
      "[113]\tvalidation_0-mae:0.056038\n",
      "[114]\tvalidation_0-mae:0.055886\n",
      "[115]\tvalidation_0-mae:0.055465\n",
      "[116]\tvalidation_0-mae:0.055011\n",
      "[117]\tvalidation_0-mae:0.054851\n",
      "[118]\tvalidation_0-mae:0.053919\n",
      "[119]\tvalidation_0-mae:0.053783\n",
      "[120]\tvalidation_0-mae:0.053411\n",
      "[121]\tvalidation_0-mae:0.052954\n",
      "[122]\tvalidation_0-mae:0.052796\n",
      "[123]\tvalidation_0-mae:0.052556\n",
      "[124]\tvalidation_0-mae:0.052478\n",
      "[125]\tvalidation_0-mae:0.052202\n",
      "[126]\tvalidation_0-mae:0.051995\n",
      "[127]\tvalidation_0-mae:0.05187\n",
      "[128]\tvalidation_0-mae:0.051477\n",
      "[129]\tvalidation_0-mae:0.051201\n",
      "[130]\tvalidation_0-mae:0.051033\n",
      "[131]\tvalidation_0-mae:0.050894\n",
      "[132]\tvalidation_0-mae:0.050567\n",
      "[133]\tvalidation_0-mae:0.050436\n",
      "[134]\tvalidation_0-mae:0.049858\n",
      "[135]\tvalidation_0-mae:0.049666\n",
      "[136]\tvalidation_0-mae:0.049535\n",
      "[137]\tvalidation_0-mae:0.049181\n",
      "[138]\tvalidation_0-mae:0.049089\n",
      "[139]\tvalidation_0-mae:0.048756\n",
      "[140]\tvalidation_0-mae:0.048591\n",
      "[141]\tvalidation_0-mae:0.048447\n",
      "[142]\tvalidation_0-mae:0.048031\n",
      "[143]\tvalidation_0-mae:0.047916\n",
      "[144]\tvalidation_0-mae:0.047632\n",
      "[145]\tvalidation_0-mae:0.047443\n",
      "[146]\tvalidation_0-mae:0.047334\n",
      "[147]\tvalidation_0-mae:0.047307\n",
      "[148]\tvalidation_0-mae:0.047186\n",
      "[149]\tvalidation_0-mae:0.046926\n",
      "    fold  2:  [0.18745735]\n",
      "[16:14:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:11.9623\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:10.288\n",
      "[2]\tvalidation_0-mae:8.84798\n",
      "[3]\tvalidation_0-mae:7.60948\n",
      "[4]\tvalidation_0-mae:6.54435\n",
      "[5]\tvalidation_0-mae:5.62834\n",
      "[6]\tvalidation_0-mae:4.84056\n",
      "[7]\tvalidation_0-mae:4.1631\n",
      "[8]\tvalidation_0-mae:3.58051\n",
      "[9]\tvalidation_0-mae:3.07949\n",
      "[10]\tvalidation_0-mae:2.64859\n",
      "[11]\tvalidation_0-mae:2.27804\n",
      "[12]\tvalidation_0-mae:1.95948\n",
      "[13]\tvalidation_0-mae:1.68565\n",
      "[14]\tvalidation_0-mae:1.45035\n",
      "[15]\tvalidation_0-mae:1.24825\n",
      "[16]\tvalidation_0-mae:1.07484\n",
      "[17]\tvalidation_0-mae:0.926244\n",
      "[18]\tvalidation_0-mae:0.799282\n",
      "[19]\tvalidation_0-mae:0.690634\n",
      "[20]\tvalidation_0-mae:0.597997\n",
      "[21]\tvalidation_0-mae:0.519147\n",
      "[22]\tvalidation_0-mae:0.452244\n",
      "[23]\tvalidation_0-mae:0.395387\n",
      "[24]\tvalidation_0-mae:0.347517\n",
      "[25]\tvalidation_0-mae:0.308161\n",
      "[26]\tvalidation_0-mae:0.274782\n",
      "[27]\tvalidation_0-mae:0.247084\n",
      "[28]\tvalidation_0-mae:0.223806\n",
      "[29]\tvalidation_0-mae:0.205101\n",
      "[30]\tvalidation_0-mae:0.189276\n",
      "[31]\tvalidation_0-mae:0.177003\n",
      "[32]\tvalidation_0-mae:0.166351\n",
      "[33]\tvalidation_0-mae:0.157927\n",
      "[34]\tvalidation_0-mae:0.15033\n",
      "[35]\tvalidation_0-mae:0.144004\n",
      "[36]\tvalidation_0-mae:0.138337\n",
      "[37]\tvalidation_0-mae:0.133602\n",
      "[38]\tvalidation_0-mae:0.129841\n",
      "[39]\tvalidation_0-mae:0.126075\n",
      "[40]\tvalidation_0-mae:0.122862\n",
      "[41]\tvalidation_0-mae:0.119278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\tvalidation_0-mae:0.116814\n",
      "[43]\tvalidation_0-mae:0.114086\n",
      "[44]\tvalidation_0-mae:0.111971\n",
      "[45]\tvalidation_0-mae:0.110218\n",
      "[46]\tvalidation_0-mae:0.108589\n",
      "[47]\tvalidation_0-mae:0.106791\n",
      "[48]\tvalidation_0-mae:0.104888\n",
      "[49]\tvalidation_0-mae:0.103163\n",
      "[50]\tvalidation_0-mae:0.101454\n",
      "[51]\tvalidation_0-mae:0.100084\n",
      "[52]\tvalidation_0-mae:0.098202\n",
      "[53]\tvalidation_0-mae:0.096587\n",
      "[54]\tvalidation_0-mae:0.095402\n",
      "[55]\tvalidation_0-mae:0.093613\n",
      "[56]\tvalidation_0-mae:0.091905\n",
      "[57]\tvalidation_0-mae:0.090844\n",
      "[58]\tvalidation_0-mae:0.089486\n",
      "[59]\tvalidation_0-mae:0.088378\n",
      "[60]\tvalidation_0-mae:0.086888\n",
      "[61]\tvalidation_0-mae:0.086217\n",
      "[62]\tvalidation_0-mae:0.085139\n",
      "[63]\tvalidation_0-mae:0.083864\n",
      "[64]\tvalidation_0-mae:0.082948\n",
      "[65]\tvalidation_0-mae:0.081696\n",
      "[66]\tvalidation_0-mae:0.081045\n",
      "[67]\tvalidation_0-mae:0.079947\n",
      "[68]\tvalidation_0-mae:0.079374\n",
      "[69]\tvalidation_0-mae:0.078441\n",
      "[70]\tvalidation_0-mae:0.077534\n",
      "[71]\tvalidation_0-mae:0.077138\n",
      "[72]\tvalidation_0-mae:0.076395\n",
      "[73]\tvalidation_0-mae:0.075936\n",
      "[74]\tvalidation_0-mae:0.075537\n",
      "[75]\tvalidation_0-mae:0.074999\n",
      "[76]\tvalidation_0-mae:0.074156\n",
      "[77]\tvalidation_0-mae:0.07308\n",
      "[78]\tvalidation_0-mae:0.0729\n",
      "[79]\tvalidation_0-mae:0.072713\n",
      "[80]\tvalidation_0-mae:0.072395\n",
      "[81]\tvalidation_0-mae:0.071707\n",
      "[82]\tvalidation_0-mae:0.07062\n",
      "[83]\tvalidation_0-mae:0.069859\n",
      "[84]\tvalidation_0-mae:0.06957\n",
      "[85]\tvalidation_0-mae:0.069083\n",
      "[86]\tvalidation_0-mae:0.068348\n",
      "[87]\tvalidation_0-mae:0.068012\n",
      "[88]\tvalidation_0-mae:0.067621\n",
      "[89]\tvalidation_0-mae:0.067412\n",
      "[90]\tvalidation_0-mae:0.066991\n",
      "[91]\tvalidation_0-mae:0.066266\n",
      "[92]\tvalidation_0-mae:0.065823\n",
      "[93]\tvalidation_0-mae:0.06523\n",
      "[94]\tvalidation_0-mae:0.064987\n",
      "[95]\tvalidation_0-mae:0.064784\n",
      "[96]\tvalidation_0-mae:0.064405\n",
      "[97]\tvalidation_0-mae:0.063967\n",
      "[98]\tvalidation_0-mae:0.063167\n",
      "[99]\tvalidation_0-mae:0.06278\n",
      "[100]\tvalidation_0-mae:0.06263\n",
      "[101]\tvalidation_0-mae:0.062465\n",
      "[102]\tvalidation_0-mae:0.062055\n",
      "[103]\tvalidation_0-mae:0.061867\n",
      "[104]\tvalidation_0-mae:0.061585\n",
      "[105]\tvalidation_0-mae:0.061401\n",
      "[106]\tvalidation_0-mae:0.060712\n",
      "[107]\tvalidation_0-mae:0.060171\n",
      "[108]\tvalidation_0-mae:0.060064\n",
      "[109]\tvalidation_0-mae:0.059824\n",
      "[110]\tvalidation_0-mae:0.059566\n",
      "[111]\tvalidation_0-mae:0.059306\n",
      "[112]\tvalidation_0-mae:0.058926\n",
      "[113]\tvalidation_0-mae:0.058345\n",
      "[114]\tvalidation_0-mae:0.057826\n",
      "[115]\tvalidation_0-mae:0.057333\n",
      "[116]\tvalidation_0-mae:0.05705\n",
      "[117]\tvalidation_0-mae:0.05696\n",
      "[118]\tvalidation_0-mae:0.05657\n",
      "[119]\tvalidation_0-mae:0.05616\n",
      "[120]\tvalidation_0-mae:0.055986\n",
      "[121]\tvalidation_0-mae:0.055862\n",
      "[122]\tvalidation_0-mae:0.05516\n",
      "[123]\tvalidation_0-mae:0.054844\n",
      "[124]\tvalidation_0-mae:0.054741\n",
      "[125]\tvalidation_0-mae:0.054606\n",
      "[126]\tvalidation_0-mae:0.054398\n",
      "[127]\tvalidation_0-mae:0.053944\n",
      "[128]\tvalidation_0-mae:0.053524\n",
      "[129]\tvalidation_0-mae:0.053312\n",
      "[130]\tvalidation_0-mae:0.053119\n",
      "[131]\tvalidation_0-mae:0.052887\n",
      "[132]\tvalidation_0-mae:0.052784\n",
      "[133]\tvalidation_0-mae:0.052538\n",
      "[134]\tvalidation_0-mae:0.052338\n",
      "[135]\tvalidation_0-mae:0.052204\n",
      "[136]\tvalidation_0-mae:0.05215\n",
      "[137]\tvalidation_0-mae:0.051849\n",
      "[138]\tvalidation_0-mae:0.051617\n",
      "[139]\tvalidation_0-mae:0.051094\n",
      "[140]\tvalidation_0-mae:0.050721\n",
      "[141]\tvalidation_0-mae:0.050524\n",
      "[142]\tvalidation_0-mae:0.050104\n",
      "[143]\tvalidation_0-mae:0.049776\n",
      "[144]\tvalidation_0-mae:0.049591\n",
      "[145]\tvalidation_0-mae:0.049289\n",
      "[146]\tvalidation_0-mae:0.049093\n",
      "[147]\tvalidation_0-mae:0.048962\n",
      "[148]\tvalidation_0-mae:0.048867\n",
      "[149]\tvalidation_0-mae:0.048572\n",
      "    fold  3:  [0.18769320]\n",
      "    ----\n",
      "    MEAN:     [0.18764056] + [0.00046860]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "features = ['habitaciones', \n",
    "            'garages', \n",
    "            'banos',\n",
    "            'antiguedad',\n",
    "            'metroscubiertos', \n",
    "            'metrostotales',\n",
    "            'lat_norm', 'lng_norm'\n",
    "            'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', \n",
    "                 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                     'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "                 'count_id_zona'\n",
    "                 'dias_desde_datos',\n",
    "                 'meses_desde_datos',\n",
    "                 'porcentaje_metros',\n",
    "                 'promedio_precio_hbg_tipo_propiedad']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('lightgbm', lgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('xgboost', xgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8999882607358867, bagging_freq=95,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.2570109385381975, importance_type='split',\n",
       "                learning_rate=0.13601832720254403, max_depth=26,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=175,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0,\n",
       "                test_size=0.08363501292068126)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8999882607358867,\n",
    " 'bagging_freq': int(95.0),\n",
    " 'feature_fraction': 0.2570109385381975,\n",
    " 'learning_rate': 0.13601832720254403,\n",
    " 'max_depth': int(26.0),\n",
    " 'num_leaves': int(175.0),\n",
    " 'test_size': 0.08363501292068126}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s['target'] = np.exp(df_test_s['target'])\n",
    "df_test_s[['id', 'target']].to_csv('respuesta33.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "MAE Stacking (train): 479214.56916\n",
      "MAE Stacking (test): 409282.55733\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
