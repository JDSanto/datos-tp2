{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "from ipynb.fs.full.features import features_independientes_precio, features_dependientes_precio, features_de_csvs, columna_a_ohe\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features_independientes_precio(df_test)\n",
    "df_test_f = features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features_independientes_precio(df_train)\n",
    "df_train_f = features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "\n",
    "df_train_f = columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "\n",
    "llenar_nulls(df_train_f)\n",
    "llenar_nulls(df_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.806451877022587,\n",
    " 'bagging_freq': 62.0,\n",
    " 'feature_fraction': 0.5379925983440028,\n",
    " 'learning_rate': 0.1363027714646826,\n",
    " 'max_depth': 11.0,\n",
    " 'num_leaves': 113.0,\n",
    " 'test_size': 0.09575190901892519}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "[13:31:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18892e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88947e+06\n",
      "[2]\tvalidation_0-mae:1.6331e+06\n",
      "[3]\tvalidation_0-mae:1.41342e+06\n",
      "[4]\tvalidation_0-mae:1.22562e+06\n",
      "[5]\tvalidation_0-mae:1.06527e+06\n",
      "[6]\tvalidation_0-mae:929240\n",
      "[7]\tvalidation_0-mae:814510\n",
      "[8]\tvalidation_0-mae:718409\n",
      "[9]\tvalidation_0-mae:637504\n",
      "[10]\tvalidation_0-mae:569539\n",
      "[11]\tvalidation_0-mae:514258\n",
      "[12]\tvalidation_0-mae:468803\n",
      "[13]\tvalidation_0-mae:429418\n",
      "[14]\tvalidation_0-mae:397346\n",
      "[15]\tvalidation_0-mae:371746\n",
      "[16]\tvalidation_0-mae:349020\n",
      "[17]\tvalidation_0-mae:330626\n",
      "[18]\tvalidation_0-mae:315000\n",
      "[19]\tvalidation_0-mae:300747\n",
      "[20]\tvalidation_0-mae:290184\n",
      "[21]\tvalidation_0-mae:279957\n",
      "[22]\tvalidation_0-mae:270578\n",
      "[23]\tvalidation_0-mae:262218\n",
      "[24]\tvalidation_0-mae:254233\n",
      "[25]\tvalidation_0-mae:247381\n",
      "[26]\tvalidation_0-mae:241126\n",
      "[27]\tvalidation_0-mae:235800\n",
      "[28]\tvalidation_0-mae:231010\n",
      "[29]\tvalidation_0-mae:226870\n",
      "[30]\tvalidation_0-mae:222962\n",
      "[31]\tvalidation_0-mae:219479\n",
      "[32]\tvalidation_0-mae:216244\n",
      "[33]\tvalidation_0-mae:213086\n",
      "[34]\tvalidation_0-mae:209616\n",
      "[35]\tvalidation_0-mae:206398\n",
      "[36]\tvalidation_0-mae:203121\n",
      "[37]\tvalidation_0-mae:200054\n",
      "[38]\tvalidation_0-mae:197594\n",
      "[39]\tvalidation_0-mae:195190\n",
      "[40]\tvalidation_0-mae:192314\n",
      "[41]\tvalidation_0-mae:190257\n",
      "[42]\tvalidation_0-mae:188292\n",
      "[43]\tvalidation_0-mae:186857\n",
      "[44]\tvalidation_0-mae:184915\n",
      "[45]\tvalidation_0-mae:183469\n",
      "[46]\tvalidation_0-mae:181231\n",
      "[47]\tvalidation_0-mae:179633\n",
      "[48]\tvalidation_0-mae:178530\n",
      "[49]\tvalidation_0-mae:176951\n",
      "[50]\tvalidation_0-mae:175389\n",
      "[51]\tvalidation_0-mae:174341\n",
      "[52]\tvalidation_0-mae:172274\n",
      "[53]\tvalidation_0-mae:171279\n",
      "[54]\tvalidation_0-mae:170143\n",
      "[55]\tvalidation_0-mae:169140\n",
      "[56]\tvalidation_0-mae:167916\n",
      "[57]\tvalidation_0-mae:167023\n",
      "[58]\tvalidation_0-mae:166037\n",
      "[59]\tvalidation_0-mae:165494\n",
      "[60]\tvalidation_0-mae:164587\n",
      "[61]\tvalidation_0-mae:163602\n",
      "[62]\tvalidation_0-mae:162286\n",
      "[63]\tvalidation_0-mae:160085\n",
      "[64]\tvalidation_0-mae:159122\n",
      "[65]\tvalidation_0-mae:158245\n",
      "[66]\tvalidation_0-mae:156953\n",
      "[67]\tvalidation_0-mae:155895\n",
      "[68]\tvalidation_0-mae:155201\n",
      "[69]\tvalidation_0-mae:154789\n",
      "[70]\tvalidation_0-mae:153297\n",
      "[71]\tvalidation_0-mae:153042\n",
      "[72]\tvalidation_0-mae:151806\n",
      "[73]\tvalidation_0-mae:151130\n",
      "[74]\tvalidation_0-mae:150425\n",
      "[75]\tvalidation_0-mae:149796\n",
      "[76]\tvalidation_0-mae:148400\n",
      "[77]\tvalidation_0-mae:148176\n",
      "[78]\tvalidation_0-mae:147399\n",
      "[79]\tvalidation_0-mae:146180\n",
      "[80]\tvalidation_0-mae:144780\n",
      "[81]\tvalidation_0-mae:144274\n",
      "[82]\tvalidation_0-mae:143977\n",
      "[83]\tvalidation_0-mae:142887\n",
      "[84]\tvalidation_0-mae:142130\n",
      "[85]\tvalidation_0-mae:140834\n",
      "[86]\tvalidation_0-mae:139505\n",
      "[87]\tvalidation_0-mae:138724\n",
      "[88]\tvalidation_0-mae:138197\n",
      "[89]\tvalidation_0-mae:137414\n",
      "[90]\tvalidation_0-mae:135773\n",
      "[91]\tvalidation_0-mae:135314\n",
      "[92]\tvalidation_0-mae:134068\n",
      "[93]\tvalidation_0-mae:133315\n",
      "[94]\tvalidation_0-mae:132951\n",
      "[95]\tvalidation_0-mae:132370\n",
      "[96]\tvalidation_0-mae:131332\n",
      "[97]\tvalidation_0-mae:130977\n",
      "[98]\tvalidation_0-mae:130164\n",
      "[99]\tvalidation_0-mae:129983\n",
      "[100]\tvalidation_0-mae:129331\n",
      "[101]\tvalidation_0-mae:128393\n",
      "[102]\tvalidation_0-mae:127914\n",
      "[103]\tvalidation_0-mae:126820\n",
      "[104]\tvalidation_0-mae:126316\n",
      "[105]\tvalidation_0-mae:125720\n",
      "[106]\tvalidation_0-mae:124798\n",
      "[107]\tvalidation_0-mae:124435\n",
      "[108]\tvalidation_0-mae:123747\n",
      "[109]\tvalidation_0-mae:123086\n",
      "[110]\tvalidation_0-mae:122483\n",
      "[111]\tvalidation_0-mae:121904\n",
      "[112]\tvalidation_0-mae:121607\n",
      "[113]\tvalidation_0-mae:121424\n",
      "[114]\tvalidation_0-mae:120982\n",
      "[115]\tvalidation_0-mae:120762\n",
      "[116]\tvalidation_0-mae:120344\n",
      "[117]\tvalidation_0-mae:119848\n",
      "[118]\tvalidation_0-mae:118950\n",
      "[119]\tvalidation_0-mae:118270\n",
      "[120]\tvalidation_0-mae:117947\n",
      "[121]\tvalidation_0-mae:117464\n",
      "[122]\tvalidation_0-mae:116829\n",
      "[123]\tvalidation_0-mae:115986\n",
      "[124]\tvalidation_0-mae:114744\n",
      "[125]\tvalidation_0-mae:114620\n",
      "[126]\tvalidation_0-mae:114366\n",
      "[127]\tvalidation_0-mae:114112\n",
      "[128]\tvalidation_0-mae:113898\n",
      "[129]\tvalidation_0-mae:113072\n",
      "[130]\tvalidation_0-mae:112349\n",
      "[131]\tvalidation_0-mae:111722\n",
      "[132]\tvalidation_0-mae:110941\n",
      "[133]\tvalidation_0-mae:110240\n",
      "[134]\tvalidation_0-mae:109529\n",
      "[135]\tvalidation_0-mae:109433\n",
      "[136]\tvalidation_0-mae:108866\n",
      "[137]\tvalidation_0-mae:108190\n",
      "[138]\tvalidation_0-mae:107571\n",
      "[139]\tvalidation_0-mae:106705\n",
      "[140]\tvalidation_0-mae:106395\n",
      "[141]\tvalidation_0-mae:106296\n",
      "[142]\tvalidation_0-mae:105405\n",
      "[143]\tvalidation_0-mae:104823\n",
      "[144]\tvalidation_0-mae:104243\n",
      "[145]\tvalidation_0-mae:103591\n",
      "[146]\tvalidation_0-mae:102916\n",
      "[147]\tvalidation_0-mae:102184\n",
      "[148]\tvalidation_0-mae:101888\n",
      "[149]\tvalidation_0-mae:101130\n",
      "    fold  0:  [485875.68227798]\n",
      "[13:34:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.182e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88347e+06\n",
      "[2]\tvalidation_0-mae:1.62781e+06\n",
      "[3]\tvalidation_0-mae:1.40878e+06\n",
      "[4]\tvalidation_0-mae:1.22156e+06\n",
      "[5]\tvalidation_0-mae:1.06189e+06\n",
      "[6]\tvalidation_0-mae:926284\n",
      "[7]\tvalidation_0-mae:811750\n",
      "[8]\tvalidation_0-mae:715767\n",
      "[9]\tvalidation_0-mae:635121\n",
      "[10]\tvalidation_0-mae:567418\n",
      "[11]\tvalidation_0-mae:512341\n",
      "[12]\tvalidation_0-mae:466932\n",
      "[13]\tvalidation_0-mae:428033\n",
      "[14]\tvalidation_0-mae:395882\n",
      "[15]\tvalidation_0-mae:370287\n",
      "[16]\tvalidation_0-mae:347423\n",
      "[17]\tvalidation_0-mae:329373\n",
      "[18]\tvalidation_0-mae:313557\n",
      "[19]\tvalidation_0-mae:299335\n",
      "[20]\tvalidation_0-mae:288379\n",
      "[21]\tvalidation_0-mae:278199\n",
      "[22]\tvalidation_0-mae:269254\n",
      "[23]\tvalidation_0-mae:261585\n",
      "[24]\tvalidation_0-mae:253344\n",
      "[25]\tvalidation_0-mae:247137\n",
      "[26]\tvalidation_0-mae:241791\n",
      "[27]\tvalidation_0-mae:237339\n",
      "[28]\tvalidation_0-mae:232437\n",
      "[29]\tvalidation_0-mae:228195\n",
      "[30]\tvalidation_0-mae:224199\n",
      "[31]\tvalidation_0-mae:220880\n",
      "[32]\tvalidation_0-mae:217580\n",
      "[33]\tvalidation_0-mae:213561\n",
      "[34]\tvalidation_0-mae:210482\n",
      "[35]\tvalidation_0-mae:207070\n",
      "[36]\tvalidation_0-mae:204115\n",
      "[37]\tvalidation_0-mae:201006\n",
      "[38]\tvalidation_0-mae:197960\n",
      "[39]\tvalidation_0-mae:195586\n",
      "[40]\tvalidation_0-mae:193144\n",
      "[41]\tvalidation_0-mae:190164\n",
      "[42]\tvalidation_0-mae:187644\n",
      "[43]\tvalidation_0-mae:185957\n",
      "[44]\tvalidation_0-mae:184396\n",
      "[45]\tvalidation_0-mae:182556\n",
      "[46]\tvalidation_0-mae:179780\n",
      "[47]\tvalidation_0-mae:178289\n",
      "[48]\tvalidation_0-mae:176895\n",
      "[49]\tvalidation_0-mae:174953\n",
      "[50]\tvalidation_0-mae:173199\n",
      "[51]\tvalidation_0-mae:171229\n",
      "[52]\tvalidation_0-mae:170031\n",
      "[53]\tvalidation_0-mae:168805\n",
      "[54]\tvalidation_0-mae:167418\n",
      "[55]\tvalidation_0-mae:165067\n",
      "[56]\tvalidation_0-mae:163633\n",
      "[57]\tvalidation_0-mae:162205\n",
      "[58]\tvalidation_0-mae:160749\n",
      "[59]\tvalidation_0-mae:159571\n",
      "[60]\tvalidation_0-mae:157903\n",
      "[61]\tvalidation_0-mae:157024\n",
      "[62]\tvalidation_0-mae:156502\n",
      "[63]\tvalidation_0-mae:155501\n",
      "[64]\tvalidation_0-mae:155138\n",
      "[65]\tvalidation_0-mae:153371\n",
      "[66]\tvalidation_0-mae:152377\n",
      "[67]\tvalidation_0-mae:151453\n",
      "[68]\tvalidation_0-mae:150757\n",
      "[69]\tvalidation_0-mae:149999\n",
      "[70]\tvalidation_0-mae:149207\n",
      "[71]\tvalidation_0-mae:148782\n",
      "[72]\tvalidation_0-mae:148209\n",
      "[73]\tvalidation_0-mae:147409\n",
      "[74]\tvalidation_0-mae:145904\n",
      "[75]\tvalidation_0-mae:144958\n",
      "[76]\tvalidation_0-mae:144513\n",
      "[77]\tvalidation_0-mae:144088\n",
      "[78]\tvalidation_0-mae:142918\n",
      "[79]\tvalidation_0-mae:141926\n",
      "[80]\tvalidation_0-mae:140889\n",
      "[81]\tvalidation_0-mae:139180\n",
      "[82]\tvalidation_0-mae:138606\n",
      "[83]\tvalidation_0-mae:137895\n",
      "[84]\tvalidation_0-mae:137175\n",
      "[85]\tvalidation_0-mae:135727\n",
      "[86]\tvalidation_0-mae:134474\n",
      "[87]\tvalidation_0-mae:133623\n",
      "[88]\tvalidation_0-mae:133055\n",
      "[89]\tvalidation_0-mae:132404\n",
      "[90]\tvalidation_0-mae:131596\n",
      "[91]\tvalidation_0-mae:131380\n",
      "[92]\tvalidation_0-mae:130967\n",
      "[93]\tvalidation_0-mae:130695\n",
      "[94]\tvalidation_0-mae:129391\n",
      "[95]\tvalidation_0-mae:128846\n",
      "[96]\tvalidation_0-mae:127773\n",
      "[97]\tvalidation_0-mae:127544\n",
      "[98]\tvalidation_0-mae:126602\n",
      "[99]\tvalidation_0-mae:125745\n",
      "[100]\tvalidation_0-mae:125170\n",
      "[101]\tvalidation_0-mae:124124\n",
      "[102]\tvalidation_0-mae:123629\n",
      "[103]\tvalidation_0-mae:123069\n",
      "[104]\tvalidation_0-mae:122221\n",
      "[105]\tvalidation_0-mae:121669\n",
      "[106]\tvalidation_0-mae:121014\n",
      "[107]\tvalidation_0-mae:120222\n",
      "[108]\tvalidation_0-mae:118987\n",
      "[109]\tvalidation_0-mae:118733\n",
      "[110]\tvalidation_0-mae:118426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111]\tvalidation_0-mae:117346\n",
      "[112]\tvalidation_0-mae:116706\n",
      "[113]\tvalidation_0-mae:116482\n",
      "[114]\tvalidation_0-mae:115801\n",
      "[115]\tvalidation_0-mae:115436\n",
      "[116]\tvalidation_0-mae:115187\n",
      "[117]\tvalidation_0-mae:114530\n",
      "[118]\tvalidation_0-mae:113464\n",
      "[119]\tvalidation_0-mae:112653\n",
      "[120]\tvalidation_0-mae:111980\n",
      "[121]\tvalidation_0-mae:111632\n",
      "[122]\tvalidation_0-mae:111299\n",
      "[123]\tvalidation_0-mae:110478\n",
      "[124]\tvalidation_0-mae:109949\n",
      "[125]\tvalidation_0-mae:109297\n",
      "[126]\tvalidation_0-mae:108532\n",
      "[127]\tvalidation_0-mae:108049\n",
      "[128]\tvalidation_0-mae:107373\n",
      "[129]\tvalidation_0-mae:106822\n",
      "[130]\tvalidation_0-mae:106302\n",
      "[131]\tvalidation_0-mae:106030\n",
      "[132]\tvalidation_0-mae:105155\n",
      "[133]\tvalidation_0-mae:104741\n",
      "[134]\tvalidation_0-mae:104293\n",
      "[135]\tvalidation_0-mae:103819\n",
      "[136]\tvalidation_0-mae:103218\n",
      "[137]\tvalidation_0-mae:102988\n",
      "[138]\tvalidation_0-mae:102606\n",
      "[139]\tvalidation_0-mae:101875\n",
      "[140]\tvalidation_0-mae:101193\n",
      "[141]\tvalidation_0-mae:100947\n",
      "[142]\tvalidation_0-mae:100439\n",
      "[143]\tvalidation_0-mae:99868.8\n",
      "[144]\tvalidation_0-mae:99584.7\n",
      "[145]\tvalidation_0-mae:99129.4\n",
      "[146]\tvalidation_0-mae:98769.6\n",
      "[147]\tvalidation_0-mae:98070.8\n",
      "[148]\tvalidation_0-mae:97868.5\n",
      "[149]\tvalidation_0-mae:97475.9\n",
      "    fold  1:  [495478.31815214]\n",
      "[13:38:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18053e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88227e+06\n",
      "[2]\tvalidation_0-mae:1.62702e+06\n",
      "[3]\tvalidation_0-mae:1.4082e+06\n",
      "[4]\tvalidation_0-mae:1.22071e+06\n",
      "[5]\tvalidation_0-mae:1.0609e+06\n",
      "[6]\tvalidation_0-mae:925847\n",
      "[7]\tvalidation_0-mae:811154\n",
      "[8]\tvalidation_0-mae:715058\n",
      "[9]\tvalidation_0-mae:634267\n",
      "[10]\tvalidation_0-mae:566254\n",
      "[11]\tvalidation_0-mae:510960\n",
      "[12]\tvalidation_0-mae:465799\n",
      "[13]\tvalidation_0-mae:427006\n",
      "[14]\tvalidation_0-mae:394915\n",
      "[15]\tvalidation_0-mae:369367\n",
      "[16]\tvalidation_0-mae:346520\n",
      "[17]\tvalidation_0-mae:327978\n",
      "[18]\tvalidation_0-mae:312036\n",
      "[19]\tvalidation_0-mae:297739\n",
      "[20]\tvalidation_0-mae:286825\n",
      "[21]\tvalidation_0-mae:277007\n",
      "[22]\tvalidation_0-mae:267941\n",
      "[23]\tvalidation_0-mae:259703\n",
      "[24]\tvalidation_0-mae:252157\n",
      "[25]\tvalidation_0-mae:246066\n",
      "[26]\tvalidation_0-mae:240397\n",
      "[27]\tvalidation_0-mae:234875\n",
      "[28]\tvalidation_0-mae:230744\n",
      "[29]\tvalidation_0-mae:226274\n",
      "[30]\tvalidation_0-mae:221299\n",
      "[31]\tvalidation_0-mae:217391\n",
      "[32]\tvalidation_0-mae:213845\n",
      "[33]\tvalidation_0-mae:210100\n",
      "[34]\tvalidation_0-mae:206431\n",
      "[35]\tvalidation_0-mae:203152\n",
      "[36]\tvalidation_0-mae:200256\n",
      "[37]\tvalidation_0-mae:197423\n",
      "[38]\tvalidation_0-mae:194703\n",
      "[39]\tvalidation_0-mae:192259\n",
      "[40]\tvalidation_0-mae:189560\n",
      "[41]\tvalidation_0-mae:187137\n",
      "[42]\tvalidation_0-mae:185149\n",
      "[43]\tvalidation_0-mae:183069\n",
      "[44]\tvalidation_0-mae:181459\n",
      "[45]\tvalidation_0-mae:179928\n",
      "[46]\tvalidation_0-mae:177765\n",
      "[47]\tvalidation_0-mae:176018\n",
      "[48]\tvalidation_0-mae:174321\n",
      "[49]\tvalidation_0-mae:172125\n",
      "[50]\tvalidation_0-mae:170850\n",
      "[51]\tvalidation_0-mae:169879\n",
      "[52]\tvalidation_0-mae:168729\n",
      "[53]\tvalidation_0-mae:167433\n",
      "[54]\tvalidation_0-mae:165879\n",
      "[55]\tvalidation_0-mae:164978\n",
      "[56]\tvalidation_0-mae:164196\n",
      "[57]\tvalidation_0-mae:162061\n",
      "[58]\tvalidation_0-mae:160182\n",
      "[59]\tvalidation_0-mae:159203\n",
      "[60]\tvalidation_0-mae:157498\n",
      "[61]\tvalidation_0-mae:156367\n",
      "[62]\tvalidation_0-mae:155202\n",
      "[63]\tvalidation_0-mae:154071\n",
      "[64]\tvalidation_0-mae:152915\n",
      "[65]\tvalidation_0-mae:152432\n",
      "[66]\tvalidation_0-mae:150945\n",
      "[67]\tvalidation_0-mae:149467\n",
      "[68]\tvalidation_0-mae:148774\n",
      "[69]\tvalidation_0-mae:147917\n",
      "[70]\tvalidation_0-mae:146582\n",
      "[71]\tvalidation_0-mae:146239\n",
      "[72]\tvalidation_0-mae:145880\n",
      "[73]\tvalidation_0-mae:145144\n",
      "[74]\tvalidation_0-mae:144453\n",
      "[75]\tvalidation_0-mae:143729\n",
      "[76]\tvalidation_0-mae:142412\n",
      "[77]\tvalidation_0-mae:140858\n",
      "[78]\tvalidation_0-mae:139668\n",
      "[79]\tvalidation_0-mae:137871\n",
      "[80]\tvalidation_0-mae:136947\n",
      "[81]\tvalidation_0-mae:135751\n",
      "[82]\tvalidation_0-mae:135350\n",
      "[83]\tvalidation_0-mae:133868\n",
      "[84]\tvalidation_0-mae:133268\n",
      "[85]\tvalidation_0-mae:132846\n",
      "[86]\tvalidation_0-mae:132365\n",
      "[87]\tvalidation_0-mae:131392\n",
      "[88]\tvalidation_0-mae:130215\n",
      "[89]\tvalidation_0-mae:129534\n",
      "[90]\tvalidation_0-mae:129304\n",
      "[91]\tvalidation_0-mae:128479\n",
      "[92]\tvalidation_0-mae:128149\n",
      "[93]\tvalidation_0-mae:127833\n",
      "[94]\tvalidation_0-mae:126917\n",
      "[95]\tvalidation_0-mae:126571\n",
      "[96]\tvalidation_0-mae:125847\n",
      "[97]\tvalidation_0-mae:125341\n",
      "[98]\tvalidation_0-mae:124881\n",
      "[99]\tvalidation_0-mae:123896\n",
      "[100]\tvalidation_0-mae:123174\n",
      "[101]\tvalidation_0-mae:122340\n",
      "[102]\tvalidation_0-mae:121815\n",
      "[103]\tvalidation_0-mae:121132\n",
      "[104]\tvalidation_0-mae:119655\n",
      "[105]\tvalidation_0-mae:119230\n",
      "[106]\tvalidation_0-mae:118784\n",
      "[107]\tvalidation_0-mae:118447\n",
      "[108]\tvalidation_0-mae:117792\n",
      "[109]\tvalidation_0-mae:117191\n",
      "[110]\tvalidation_0-mae:116657\n",
      "[111]\tvalidation_0-mae:116555\n",
      "[112]\tvalidation_0-mae:116076\n",
      "[113]\tvalidation_0-mae:115994\n",
      "[114]\tvalidation_0-mae:115726\n",
      "[115]\tvalidation_0-mae:115206\n",
      "[116]\tvalidation_0-mae:114159\n",
      "[117]\tvalidation_0-mae:113542\n",
      "[118]\tvalidation_0-mae:113039\n",
      "[119]\tvalidation_0-mae:112612\n",
      "[120]\tvalidation_0-mae:112379\n",
      "[121]\tvalidation_0-mae:111714\n",
      "[122]\tvalidation_0-mae:110616\n",
      "[123]\tvalidation_0-mae:109785\n",
      "[124]\tvalidation_0-mae:109247\n",
      "[125]\tvalidation_0-mae:108568\n",
      "[126]\tvalidation_0-mae:108015\n",
      "[127]\tvalidation_0-mae:107365\n",
      "[128]\tvalidation_0-mae:107233\n",
      "[129]\tvalidation_0-mae:105853\n",
      "[130]\tvalidation_0-mae:105456\n",
      "[131]\tvalidation_0-mae:104563\n",
      "[132]\tvalidation_0-mae:104155\n",
      "[133]\tvalidation_0-mae:103504\n",
      "[134]\tvalidation_0-mae:102591\n",
      "[135]\tvalidation_0-mae:102403\n",
      "[136]\tvalidation_0-mae:101982\n",
      "[137]\tvalidation_0-mae:101148\n",
      "[138]\tvalidation_0-mae:100724\n",
      "[139]\tvalidation_0-mae:99907\n",
      "[140]\tvalidation_0-mae:99116.6\n",
      "[141]\tvalidation_0-mae:98315.6\n",
      "[142]\tvalidation_0-mae:97633.8\n",
      "[143]\tvalidation_0-mae:96825.4\n",
      "[144]\tvalidation_0-mae:96504.8\n",
      "[145]\tvalidation_0-mae:95686.4\n",
      "[146]\tvalidation_0-mae:95333.3\n",
      "[147]\tvalidation_0-mae:94773.5\n",
      "[148]\tvalidation_0-mae:94594.9\n",
      "[149]\tvalidation_0-mae:94371.9\n",
      "    fold  2:  [498125.86674487]\n",
      "[13:40:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18281e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.8843e+06\n",
      "[2]\tvalidation_0-mae:1.62859e+06\n",
      "[3]\tvalidation_0-mae:1.40965e+06\n",
      "[4]\tvalidation_0-mae:1.2222e+06\n",
      "[5]\tvalidation_0-mae:1.06252e+06\n",
      "[6]\tvalidation_0-mae:926905\n",
      "[7]\tvalidation_0-mae:812174\n",
      "[8]\tvalidation_0-mae:716086\n",
      "[9]\tvalidation_0-mae:635071\n",
      "[10]\tvalidation_0-mae:567245\n",
      "[11]\tvalidation_0-mae:511971\n",
      "[12]\tvalidation_0-mae:466305\n",
      "[13]\tvalidation_0-mae:426997\n",
      "[14]\tvalidation_0-mae:394766\n",
      "[15]\tvalidation_0-mae:369576\n",
      "[16]\tvalidation_0-mae:346671\n",
      "[17]\tvalidation_0-mae:328343\n",
      "[18]\tvalidation_0-mae:312771\n",
      "[19]\tvalidation_0-mae:298644\n",
      "[20]\tvalidation_0-mae:287767\n",
      "[21]\tvalidation_0-mae:277519\n",
      "[22]\tvalidation_0-mae:268174\n",
      "[23]\tvalidation_0-mae:259509\n",
      "[24]\tvalidation_0-mae:251392\n",
      "[25]\tvalidation_0-mae:244851\n",
      "[26]\tvalidation_0-mae:238238\n",
      "[27]\tvalidation_0-mae:232949\n",
      "[28]\tvalidation_0-mae:228848\n",
      "[29]\tvalidation_0-mae:224711\n",
      "[30]\tvalidation_0-mae:219697\n",
      "[31]\tvalidation_0-mae:216459\n",
      "[32]\tvalidation_0-mae:212063\n",
      "[33]\tvalidation_0-mae:208270\n",
      "[34]\tvalidation_0-mae:204873\n",
      "[35]\tvalidation_0-mae:201829\n",
      "[36]\tvalidation_0-mae:198519\n",
      "[37]\tvalidation_0-mae:195798\n",
      "[38]\tvalidation_0-mae:193436\n",
      "[39]\tvalidation_0-mae:190838\n",
      "[40]\tvalidation_0-mae:187367\n",
      "[41]\tvalidation_0-mae:184531\n",
      "[42]\tvalidation_0-mae:181920\n",
      "[43]\tvalidation_0-mae:179763\n",
      "[44]\tvalidation_0-mae:177854\n",
      "[45]\tvalidation_0-mae:176556\n",
      "[46]\tvalidation_0-mae:174848\n",
      "[47]\tvalidation_0-mae:173460\n",
      "[48]\tvalidation_0-mae:171616\n",
      "[49]\tvalidation_0-mae:170124\n",
      "[50]\tvalidation_0-mae:167589\n",
      "[51]\tvalidation_0-mae:165901\n",
      "[52]\tvalidation_0-mae:163783\n",
      "[53]\tvalidation_0-mae:162629\n",
      "[54]\tvalidation_0-mae:160982\n",
      "[55]\tvalidation_0-mae:159733\n",
      "[56]\tvalidation_0-mae:158656\n",
      "[57]\tvalidation_0-mae:156705\n",
      "[58]\tvalidation_0-mae:155266\n",
      "[59]\tvalidation_0-mae:154691\n",
      "[60]\tvalidation_0-mae:152993\n",
      "[61]\tvalidation_0-mae:151389\n",
      "[62]\tvalidation_0-mae:150389\n",
      "[63]\tvalidation_0-mae:149886\n",
      "[64]\tvalidation_0-mae:149281\n",
      "[65]\tvalidation_0-mae:148101\n",
      "[66]\tvalidation_0-mae:147618\n",
      "[67]\tvalidation_0-mae:146559\n",
      "[68]\tvalidation_0-mae:145976\n",
      "[69]\tvalidation_0-mae:145554\n",
      "[70]\tvalidation_0-mae:144685\n",
      "[71]\tvalidation_0-mae:144412\n",
      "[72]\tvalidation_0-mae:143674\n",
      "[73]\tvalidation_0-mae:142411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74]\tvalidation_0-mae:142029\n",
      "[75]\tvalidation_0-mae:141517\n",
      "[76]\tvalidation_0-mae:141298\n",
      "[77]\tvalidation_0-mae:140608\n",
      "[78]\tvalidation_0-mae:138671\n",
      "[79]\tvalidation_0-mae:137313\n",
      "[80]\tvalidation_0-mae:136573\n",
      "[81]\tvalidation_0-mae:135761\n",
      "[82]\tvalidation_0-mae:135570\n",
      "[83]\tvalidation_0-mae:134859\n",
      "[84]\tvalidation_0-mae:134122\n",
      "[85]\tvalidation_0-mae:132989\n",
      "[86]\tvalidation_0-mae:132445\n",
      "[87]\tvalidation_0-mae:132098\n",
      "[88]\tvalidation_0-mae:130908\n",
      "[89]\tvalidation_0-mae:130461\n",
      "[90]\tvalidation_0-mae:128805\n",
      "[91]\tvalidation_0-mae:127755\n",
      "[92]\tvalidation_0-mae:126895\n",
      "[93]\tvalidation_0-mae:126271\n",
      "[94]\tvalidation_0-mae:125141\n",
      "[95]\tvalidation_0-mae:123008\n",
      "[96]\tvalidation_0-mae:122076\n",
      "[97]\tvalidation_0-mae:121645\n",
      "[98]\tvalidation_0-mae:121157\n",
      "[99]\tvalidation_0-mae:119718\n",
      "[100]\tvalidation_0-mae:119005\n",
      "[101]\tvalidation_0-mae:118671\n",
      "[102]\tvalidation_0-mae:117866\n",
      "[103]\tvalidation_0-mae:117213\n",
      "[104]\tvalidation_0-mae:116450\n",
      "[105]\tvalidation_0-mae:115776\n",
      "[106]\tvalidation_0-mae:114005\n",
      "[107]\tvalidation_0-mae:113727\n",
      "[108]\tvalidation_0-mae:113135\n",
      "[109]\tvalidation_0-mae:112528\n",
      "[110]\tvalidation_0-mae:112061\n",
      "[111]\tvalidation_0-mae:111189\n",
      "[112]\tvalidation_0-mae:110477\n",
      "[113]\tvalidation_0-mae:110291\n",
      "[114]\tvalidation_0-mae:110159\n",
      "[115]\tvalidation_0-mae:109712\n",
      "[116]\tvalidation_0-mae:109605\n",
      "[117]\tvalidation_0-mae:108871\n",
      "[118]\tvalidation_0-mae:108253\n",
      "[119]\tvalidation_0-mae:107423\n",
      "[120]\tvalidation_0-mae:107300\n",
      "[121]\tvalidation_0-mae:106860\n",
      "[122]\tvalidation_0-mae:106280\n",
      "[123]\tvalidation_0-mae:105805\n",
      "[124]\tvalidation_0-mae:105175\n",
      "[125]\tvalidation_0-mae:104681\n",
      "[126]\tvalidation_0-mae:103602\n",
      "[127]\tvalidation_0-mae:103212\n",
      "[128]\tvalidation_0-mae:102871\n",
      "[129]\tvalidation_0-mae:102398\n",
      "[130]\tvalidation_0-mae:101883\n",
      "[131]\tvalidation_0-mae:101453\n",
      "[132]\tvalidation_0-mae:101174\n",
      "[133]\tvalidation_0-mae:100839\n",
      "[134]\tvalidation_0-mae:100434\n",
      "[135]\tvalidation_0-mae:100320\n",
      "[136]\tvalidation_0-mae:99871.5\n",
      "[137]\tvalidation_0-mae:99577.3\n",
      "[138]\tvalidation_0-mae:99371.5\n",
      "[139]\tvalidation_0-mae:98547.3\n",
      "[140]\tvalidation_0-mae:98057.9\n",
      "[141]\tvalidation_0-mae:97861.4\n",
      "[142]\tvalidation_0-mae:96860.8\n",
      "[143]\tvalidation_0-mae:96613.1\n",
      "[144]\tvalidation_0-mae:96438.5\n",
      "[145]\tvalidation_0-mae:96026.2\n",
      "[146]\tvalidation_0-mae:95337.2\n",
      "[147]\tvalidation_0-mae:94599.5\n",
      "[148]\tvalidation_0-mae:94037.4\n",
      "[149]\tvalidation_0-mae:93837.9\n",
      "    fold  3:  [493259.40598059]\n",
      "[13:44:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18166e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88314e+06\n",
      "[2]\tvalidation_0-mae:1.62764e+06\n",
      "[3]\tvalidation_0-mae:1.40898e+06\n",
      "[4]\tvalidation_0-mae:1.22165e+06\n",
      "[5]\tvalidation_0-mae:1.06201e+06\n",
      "[6]\tvalidation_0-mae:926418\n",
      "[7]\tvalidation_0-mae:811876\n",
      "[8]\tvalidation_0-mae:715884\n",
      "[9]\tvalidation_0-mae:634876\n",
      "[10]\tvalidation_0-mae:567024\n",
      "[11]\tvalidation_0-mae:511807\n",
      "[12]\tvalidation_0-mae:466198\n",
      "[13]\tvalidation_0-mae:427351\n",
      "[14]\tvalidation_0-mae:395250\n",
      "[15]\tvalidation_0-mae:369709\n",
      "[16]\tvalidation_0-mae:346662\n",
      "[17]\tvalidation_0-mae:328240\n",
      "[18]\tvalidation_0-mae:312178\n",
      "[19]\tvalidation_0-mae:297376\n",
      "[20]\tvalidation_0-mae:286498\n",
      "[21]\tvalidation_0-mae:276101\n",
      "[22]\tvalidation_0-mae:267091\n",
      "[23]\tvalidation_0-mae:258984\n",
      "[24]\tvalidation_0-mae:250904\n",
      "[25]\tvalidation_0-mae:244493\n",
      "[26]\tvalidation_0-mae:238229\n",
      "[27]\tvalidation_0-mae:232921\n",
      "[28]\tvalidation_0-mae:228386\n",
      "[29]\tvalidation_0-mae:224024\n",
      "[30]\tvalidation_0-mae:219441\n",
      "[31]\tvalidation_0-mae:216335\n",
      "[32]\tvalidation_0-mae:212640\n",
      "[33]\tvalidation_0-mae:208900\n",
      "[34]\tvalidation_0-mae:205174\n",
      "[35]\tvalidation_0-mae:202089\n",
      "[36]\tvalidation_0-mae:199415\n",
      "[37]\tvalidation_0-mae:196756\n",
      "[38]\tvalidation_0-mae:193943\n",
      "[39]\tvalidation_0-mae:192071\n",
      "[40]\tvalidation_0-mae:189391\n",
      "[41]\tvalidation_0-mae:186847\n",
      "[42]\tvalidation_0-mae:184189\n",
      "[43]\tvalidation_0-mae:181796\n",
      "[44]\tvalidation_0-mae:180119\n",
      "[45]\tvalidation_0-mae:178321\n",
      "[46]\tvalidation_0-mae:176475\n",
      "[47]\tvalidation_0-mae:174782\n",
      "[48]\tvalidation_0-mae:172937\n",
      "[49]\tvalidation_0-mae:170566\n",
      "[50]\tvalidation_0-mae:169543\n",
      "[51]\tvalidation_0-mae:168134\n",
      "[52]\tvalidation_0-mae:167044\n",
      "[53]\tvalidation_0-mae:166074\n",
      "[54]\tvalidation_0-mae:164824\n",
      "[55]\tvalidation_0-mae:163281\n",
      "[56]\tvalidation_0-mae:162626\n",
      "[57]\tvalidation_0-mae:160619\n",
      "[58]\tvalidation_0-mae:158767\n",
      "[59]\tvalidation_0-mae:157039\n",
      "[60]\tvalidation_0-mae:155403\n",
      "[61]\tvalidation_0-mae:154483\n",
      "[62]\tvalidation_0-mae:152695\n",
      "[63]\tvalidation_0-mae:151456\n",
      "[64]\tvalidation_0-mae:150674\n",
      "[65]\tvalidation_0-mae:149692\n",
      "[66]\tvalidation_0-mae:148674\n",
      "[67]\tvalidation_0-mae:146832\n",
      "[68]\tvalidation_0-mae:145901\n",
      "[69]\tvalidation_0-mae:145317\n",
      "[70]\tvalidation_0-mae:144958\n",
      "[71]\tvalidation_0-mae:144290\n",
      "[72]\tvalidation_0-mae:143406\n",
      "[73]\tvalidation_0-mae:142502\n",
      "[74]\tvalidation_0-mae:141837\n",
      "[75]\tvalidation_0-mae:140447\n",
      "[76]\tvalidation_0-mae:139962\n",
      "[77]\tvalidation_0-mae:138843\n",
      "[78]\tvalidation_0-mae:138421\n",
      "[79]\tvalidation_0-mae:137165\n",
      "[80]\tvalidation_0-mae:135354\n",
      "[81]\tvalidation_0-mae:134757\n",
      "[82]\tvalidation_0-mae:133929\n",
      "[83]\tvalidation_0-mae:133305\n",
      "[84]\tvalidation_0-mae:132405\n",
      "[85]\tvalidation_0-mae:129585\n",
      "[86]\tvalidation_0-mae:129339\n",
      "[87]\tvalidation_0-mae:128722\n",
      "[88]\tvalidation_0-mae:127866\n",
      "[89]\tvalidation_0-mae:127220\n",
      "[90]\tvalidation_0-mae:126786\n",
      "[91]\tvalidation_0-mae:125745\n",
      "[92]\tvalidation_0-mae:125307\n",
      "[93]\tvalidation_0-mae:124179\n",
      "[94]\tvalidation_0-mae:123587\n",
      "[95]\tvalidation_0-mae:121283\n",
      "[96]\tvalidation_0-mae:120700\n",
      "[97]\tvalidation_0-mae:120566\n",
      "[98]\tvalidation_0-mae:119891\n",
      "[99]\tvalidation_0-mae:119560\n",
      "[100]\tvalidation_0-mae:119229\n",
      "[101]\tvalidation_0-mae:117954\n",
      "[102]\tvalidation_0-mae:117202\n",
      "[103]\tvalidation_0-mae:116414\n",
      "[104]\tvalidation_0-mae:115380\n",
      "[105]\tvalidation_0-mae:114802\n",
      "[106]\tvalidation_0-mae:114102\n",
      "[107]\tvalidation_0-mae:113436\n",
      "[108]\tvalidation_0-mae:112925\n",
      "[109]\tvalidation_0-mae:112373\n",
      "[110]\tvalidation_0-mae:112119\n",
      "[111]\tvalidation_0-mae:111719\n",
      "[112]\tvalidation_0-mae:110690\n",
      "[113]\tvalidation_0-mae:110561\n",
      "[114]\tvalidation_0-mae:109950\n",
      "[115]\tvalidation_0-mae:109359\n",
      "[116]\tvalidation_0-mae:108357\n",
      "[117]\tvalidation_0-mae:107946\n",
      "[118]\tvalidation_0-mae:107822\n",
      "[119]\tvalidation_0-mae:107508\n",
      "[120]\tvalidation_0-mae:107350\n",
      "[121]\tvalidation_0-mae:106892\n",
      "[122]\tvalidation_0-mae:106508\n",
      "[123]\tvalidation_0-mae:105648\n",
      "[124]\tvalidation_0-mae:104783\n",
      "[125]\tvalidation_0-mae:104111\n",
      "[126]\tvalidation_0-mae:103326\n",
      "[127]\tvalidation_0-mae:102704\n",
      "[128]\tvalidation_0-mae:102026\n",
      "[129]\tvalidation_0-mae:101572\n",
      "[130]\tvalidation_0-mae:100599\n",
      "[131]\tvalidation_0-mae:100180\n",
      "[132]\tvalidation_0-mae:99384.1\n",
      "[133]\tvalidation_0-mae:98576.2\n",
      "[134]\tvalidation_0-mae:97996\n",
      "[135]\tvalidation_0-mae:97515.2\n",
      "[136]\tvalidation_0-mae:96985.1\n",
      "[137]\tvalidation_0-mae:96687.3\n",
      "[138]\tvalidation_0-mae:96362.8\n",
      "[139]\tvalidation_0-mae:95086.7\n",
      "[140]\tvalidation_0-mae:94542.4\n",
      "[141]\tvalidation_0-mae:93963.6\n",
      "[142]\tvalidation_0-mae:93081\n",
      "[143]\tvalidation_0-mae:92431.3\n",
      "[144]\tvalidation_0-mae:91831.2\n",
      "[145]\tvalidation_0-mae:91029.4\n",
      "[146]\tvalidation_0-mae:89897.2\n",
      "[147]\tvalidation_0-mae:89001.9\n",
      "[148]\tvalidation_0-mae:88572\n",
      "[149]\tvalidation_0-mae:88056.1\n",
      "    fold  4:  [496292.63061030]\n",
      "[13:46:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18263e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88404e+06\n",
      "[2]\tvalidation_0-mae:1.62826e+06\n",
      "[3]\tvalidation_0-mae:1.40932e+06\n",
      "[4]\tvalidation_0-mae:1.22194e+06\n",
      "[5]\tvalidation_0-mae:1.0624e+06\n",
      "[6]\tvalidation_0-mae:926902\n",
      "[7]\tvalidation_0-mae:812492\n",
      "[8]\tvalidation_0-mae:716286\n",
      "[9]\tvalidation_0-mae:635216\n",
      "[10]\tvalidation_0-mae:567103\n",
      "[11]\tvalidation_0-mae:511606\n",
      "[12]\tvalidation_0-mae:465986\n",
      "[13]\tvalidation_0-mae:426658\n",
      "[14]\tvalidation_0-mae:394555\n",
      "[15]\tvalidation_0-mae:369639\n",
      "[16]\tvalidation_0-mae:347009\n",
      "[17]\tvalidation_0-mae:328867\n",
      "[18]\tvalidation_0-mae:313086\n",
      "[19]\tvalidation_0-mae:298998\n",
      "[20]\tvalidation_0-mae:288057\n",
      "[21]\tvalidation_0-mae:277953\n",
      "[22]\tvalidation_0-mae:268725\n",
      "[23]\tvalidation_0-mae:260317\n",
      "[24]\tvalidation_0-mae:252611\n",
      "[25]\tvalidation_0-mae:246148\n",
      "[26]\tvalidation_0-mae:239906\n",
      "[27]\tvalidation_0-mae:234431\n",
      "[28]\tvalidation_0-mae:229552\n",
      "[29]\tvalidation_0-mae:225580\n",
      "[30]\tvalidation_0-mae:221298\n",
      "[31]\tvalidation_0-mae:217822\n",
      "[32]\tvalidation_0-mae:214112\n",
      "[33]\tvalidation_0-mae:210478\n",
      "[34]\tvalidation_0-mae:207323\n",
      "[35]\tvalidation_0-mae:204239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\tvalidation_0-mae:201036\n",
      "[37]\tvalidation_0-mae:198483\n",
      "[38]\tvalidation_0-mae:195765\n",
      "[39]\tvalidation_0-mae:192778\n",
      "[40]\tvalidation_0-mae:190315\n",
      "[41]\tvalidation_0-mae:187517\n",
      "[42]\tvalidation_0-mae:185308\n",
      "[43]\tvalidation_0-mae:182969\n",
      "[44]\tvalidation_0-mae:181192\n",
      "[45]\tvalidation_0-mae:179888\n",
      "[46]\tvalidation_0-mae:178343\n",
      "[47]\tvalidation_0-mae:176959\n",
      "[48]\tvalidation_0-mae:174878\n",
      "[49]\tvalidation_0-mae:172895\n",
      "[50]\tvalidation_0-mae:171321\n",
      "[51]\tvalidation_0-mae:170080\n",
      "[52]\tvalidation_0-mae:168658\n",
      "[53]\tvalidation_0-mae:167116\n",
      "[54]\tvalidation_0-mae:165979\n",
      "[55]\tvalidation_0-mae:163767\n",
      "[56]\tvalidation_0-mae:162726\n",
      "[57]\tvalidation_0-mae:160946\n",
      "[58]\tvalidation_0-mae:159730\n",
      "[59]\tvalidation_0-mae:158537\n",
      "[60]\tvalidation_0-mae:157311\n",
      "[61]\tvalidation_0-mae:156323\n",
      "[62]\tvalidation_0-mae:155157\n",
      "[63]\tvalidation_0-mae:154456\n",
      "[64]\tvalidation_0-mae:153728\n",
      "[65]\tvalidation_0-mae:152857\n",
      "[66]\tvalidation_0-mae:152253\n",
      "[67]\tvalidation_0-mae:151566\n",
      "[68]\tvalidation_0-mae:149581\n",
      "[69]\tvalidation_0-mae:148592\n",
      "[70]\tvalidation_0-mae:147963\n",
      "[71]\tvalidation_0-mae:147520\n",
      "[72]\tvalidation_0-mae:146850\n",
      "[73]\tvalidation_0-mae:146502\n",
      "[74]\tvalidation_0-mae:144253\n",
      "[75]\tvalidation_0-mae:143504\n",
      "[76]\tvalidation_0-mae:142702\n",
      "[77]\tvalidation_0-mae:142176\n",
      "[78]\tvalidation_0-mae:141805\n",
      "[79]\tvalidation_0-mae:140432\n",
      "[80]\tvalidation_0-mae:139329\n",
      "[81]\tvalidation_0-mae:137996\n",
      "[82]\tvalidation_0-mae:137557\n",
      "[83]\tvalidation_0-mae:136881\n",
      "[84]\tvalidation_0-mae:136474\n",
      "[85]\tvalidation_0-mae:135231\n",
      "[86]\tvalidation_0-mae:133904\n",
      "[87]\tvalidation_0-mae:132658\n",
      "[88]\tvalidation_0-mae:131777\n",
      "[89]\tvalidation_0-mae:131073\n",
      "[90]\tvalidation_0-mae:129988\n",
      "[91]\tvalidation_0-mae:128979\n",
      "[92]\tvalidation_0-mae:128570\n",
      "[93]\tvalidation_0-mae:127880\n",
      "[94]\tvalidation_0-mae:127496\n",
      "[95]\tvalidation_0-mae:126630\n",
      "[96]\tvalidation_0-mae:126221\n",
      "[97]\tvalidation_0-mae:125648\n",
      "[98]\tvalidation_0-mae:125433\n",
      "[99]\tvalidation_0-mae:124727\n",
      "[100]\tvalidation_0-mae:124368\n",
      "[101]\tvalidation_0-mae:123519\n",
      "[102]\tvalidation_0-mae:122972\n",
      "[103]\tvalidation_0-mae:121701\n",
      "[104]\tvalidation_0-mae:121462\n",
      "[105]\tvalidation_0-mae:120892\n",
      "[106]\tvalidation_0-mae:119039\n",
      "[107]\tvalidation_0-mae:118233\n",
      "[108]\tvalidation_0-mae:117628\n",
      "[109]\tvalidation_0-mae:116764\n",
      "[110]\tvalidation_0-mae:116275\n",
      "[111]\tvalidation_0-mae:115932\n",
      "[112]\tvalidation_0-mae:115485\n",
      "[113]\tvalidation_0-mae:114383\n",
      "[114]\tvalidation_0-mae:113008\n",
      "[115]\tvalidation_0-mae:112599\n",
      "[116]\tvalidation_0-mae:112308\n",
      "[117]\tvalidation_0-mae:111476\n",
      "[118]\tvalidation_0-mae:110923\n",
      "[119]\tvalidation_0-mae:110014\n",
      "[120]\tvalidation_0-mae:109462\n",
      "[121]\tvalidation_0-mae:109021\n",
      "[122]\tvalidation_0-mae:108441\n",
      "[123]\tvalidation_0-mae:107499\n",
      "[124]\tvalidation_0-mae:107126\n",
      "[125]\tvalidation_0-mae:106110\n",
      "[126]\tvalidation_0-mae:105294\n",
      "[127]\tvalidation_0-mae:105197\n",
      "[128]\tvalidation_0-mae:104983\n",
      "[129]\tvalidation_0-mae:104631\n",
      "[130]\tvalidation_0-mae:103873\n",
      "[131]\tvalidation_0-mae:102958\n",
      "[132]\tvalidation_0-mae:102794\n",
      "[133]\tvalidation_0-mae:102103\n",
      "[134]\tvalidation_0-mae:101448\n",
      "[135]\tvalidation_0-mae:101309\n",
      "[136]\tvalidation_0-mae:100730\n",
      "[137]\tvalidation_0-mae:100215\n",
      "[138]\tvalidation_0-mae:99498.8\n",
      "[139]\tvalidation_0-mae:98470.2\n",
      "[140]\tvalidation_0-mae:98030.1\n",
      "[141]\tvalidation_0-mae:97867.3\n",
      "[142]\tvalidation_0-mae:96882.8\n",
      "[143]\tvalidation_0-mae:96740.1\n",
      "[144]\tvalidation_0-mae:96269.6\n",
      "[145]\tvalidation_0-mae:95387.4\n",
      "[146]\tvalidation_0-mae:93991.3\n",
      "[147]\tvalidation_0-mae:93768\n",
      "[148]\tvalidation_0-mae:93392.5\n",
      "[149]\tvalidation_0-mae:92937.2\n",
      "    fold  5:  [496895.76899087]\n",
      "    ----\n",
      "    MEAN:     [494321.27879279] + [4057.57587099]\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [523883.35939484]\n",
      "    fold  1:  [529896.84017965]\n",
      "    fold  2:  [536047.77413994]\n",
      "    fold  3:  [532263.53671845]\n",
      "    fold  4:  [533769.34320980]\n",
      "    fold  5:  [530358.36289184]\n",
      "    ----\n",
      "    MEAN:     [531036.53608909] + [3808.17179620]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "\n",
    "\n",
    "features = ['habitaciones', 'garages', 'banos',\n",
    "       'metroscubiertos', 'metrostotales', \n",
    "#             'lat', 'lng',\n",
    "       'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'porcentaje_metros', 'diferencia_metros', 'promedio_precio_ciudad', \n",
    "                 'promedio_por_mes', 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'promedio_precio_hbg_tipo_propiedad', 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                 'count_tipo_propiedad', 'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen', 'promedio_precio_hbg_tipo_propiedad_provincia']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "features += cols_tipodepropiedad_ohe + cols_provincia_ohe\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('xgboost', xgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('lightgbm', lgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2, n_folds=6)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_test_f = features_independientes_precio(df_test)\n",
    "df_test_f = features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features_independientes_precio(df_train)\n",
    "df_train_f = features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "\n",
    "df_train_f = columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "\n",
    "llenar_nulls(df_train_f)\n",
    "llenar_nulls(df_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.7740520226030885, bagging_freq=7,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.8422472893793045, importance_type='split',\n",
       "                learning_rate=0.1508386725397851, max_depth=12,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=110,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.7740520226030885,\n",
    " 'bagging_freq': int(7.0),\n",
    " 'feature_fraction': 0.8422472893793045,\n",
    " 'learning_rate': 0.1508386725397851,\n",
    " 'max_depth': int(12.0),\n",
    " 'num_leaves': int(110.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta19.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(s_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Stacking (train): 490724.57530\n",
      "MAE Stacking (test): 444227.92242\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(s_train))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(s_test))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta18.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
