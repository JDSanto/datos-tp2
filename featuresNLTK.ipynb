{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver_info_a_filtrar(df, col):\n",
    "    cant_publicaciones_columna_no_nulo = df[~df[col].isnull()].shape[0]\n",
    "    print('La cantidad de publicaciones con ' + col +' no nulo es:', cant_publicaciones_columna_no_nulo)\n",
    "    print('La cantidad total de publicaciones es:', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_palabras_no_queridas(arr=None):\n",
    "    '''Retorna un set con las palabras a excluir, arr, es un campo opcional para excluir tambien \n",
    "    las palabras en ese arreglo'''\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    puntuacion = [',', '.', '!', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-', '_', '\\'', '\\\"', \n",
    "                  '(', ')', '[', ']', '{', '}', 'i', 'p', 'br', '<', '>', 'col.', '\\\\', '/', '$', 'm2', \n",
    "                  '..', '...', 'ii', '#', ';', ':', 'col']\n",
    "    for x in puntuacion:\n",
    "        stop_words.add(x)\n",
    "    if arr:\n",
    "        for x in arr:\n",
    "            stop_words.add(x)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_palabras_mas_frecuentes(df, col, n):\n",
    "    '''Esta funcion recibe un df, y genera la n palabras mas usadas la columna pasada por parametro, \n",
    "    retorna un arreglo ordenado de mas usadas a menos usadas'''\n",
    "    reviews = df[col].str.cat(sep=' ')\n",
    "\n",
    "    # Splitea los textos en palabras\n",
    "    tokens = word_tokenize(reviews)\n",
    "\n",
    "    # Fuera palabras no necesarias\n",
    "    stop_words = generar_palabras_no_queridas()\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "    vocabulary = set(tokens)\n",
    "    \n",
    "    # Calcula y ordena por frecuencia\n",
    "    frequency_dist = nltk.FreqDist(tokens)\n",
    "    mas_usadas = sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)[0:n]\n",
    "    return mas_usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cantidad_mas_frecuentes(df, col, n):\n",
    "    '''Retorna el df pasado por parametro con la columna nueva \"cant_palabras_mas_frecuentes\", donde dice\n",
    "    el numero de palabras mas frecuentes presentes en la columna pasada por parametro. n es la cantidad \n",
    "    palabras mas frecuentes a usar. Por ejemplo: `feature_cantidad_mas_frecuentes(df, 'titulo', 50)` genera \n",
    "    columna nueva `cant_palabras_mas_frecuentes_titulo`, donde se indica cuantas palabras frecuentes aparecen\n",
    "    en el titulo, siendo las palabras mas frecuentes, la n palabras mas usadas entre todas las columnas \n",
    "    pasadas por parametro'''\n",
    "    \n",
    "    ver_info_a_filtrar(df, col)\n",
    "    \n",
    "    arr_mas_frecuentes = generar_palabras_mas_frecuentes(df, col, n)\n",
    "    set_mas_frecuentes = set(arr_mas_frecuentes)\n",
    "    \n",
    "    def contador_mas_frecuentes(texto):\n",
    "        contador = 0\n",
    "        palabras_del_df = word_tokenize(texto)\n",
    "        for palabra in palabras_del_df:\n",
    "            if palabra in set_mas_frecuentes:\n",
    "                contador = contador + 1\n",
    "        return contador\n",
    "    \n",
    "    df['cant_palabras_mas_frecuentes_' + col] = df[~df[col].isnull()][col].apply(contador_mas_frecuentes)\n",
    "    df['cant_palabras_mas_frecuentes_' + col] = df['cant_palabras_mas_frecuentes_' + col].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejemplo():\n",
    "    # Ejemplo de uso de las palabras mas frecuentes\n",
    "    df_palabras = feature_cantidad_mas_frecuentes(df_train, 'titulo', 200)\n",
    "    df_palabras[['id', 'titulo', 'cant_palabras_mas_frecuentes_titulo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_palabras_menos_frecuentes(df, col, n):\n",
    "    '''Esta funcion recibe un df, y genera la n palabras menos usadas la columna pasada por parametro, \n",
    "    retorna un arreglo ordenado de menos usadas a menos usadas'''\n",
    "    reviews = df[col].str.cat(sep=' ')\n",
    "\n",
    "    # Splitea los textos en palabras\n",
    "    tokens = word_tokenize(reviews)\n",
    "\n",
    "    # Fuera palabras no necesarias\n",
    "    stop_words = generar_palabras_no_queridas()\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "    vocabulary = set(tokens)\n",
    "    \n",
    "    # Calcula y ordena por frecuencia\n",
    "    frequency_dist = nltk.FreqDist(tokens)\n",
    "    menos_usadas = sorted(frequency_dist, key=frequency_dist.__getitem__, reverse=False)[0:n]\n",
    "    return menos_usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cantidad_menos_frecuentes(df, col, n):\n",
    "    '''Retorna el df pasado por parametro con la columna nueva \"cant_palabras_menos_frecuentes\", donde dice\n",
    "    el numero de palabras menos frecuentes presentes en la columna pasada por parametro. n es la cantidad \n",
    "    palabras menos frecuentes a usar. Por ejemplo: `cant_palabras_menos_frecuentes(df, 'titulo', 50)` genera \n",
    "    columna nueva `cant_palabras_menos_frecuentes_titulo`, donde se indica cuantas palabras menos frecuentes aparecen\n",
    "    en el titulo, siendo las palabras menos frecuentes, la n palabras menos usadas entre todas las columnas \n",
    "    pasadas por parametro'''\n",
    "    \n",
    "    ver_info_a_filtrar(df, col)\n",
    "    \n",
    "    arr_menos_frecuentes = generar_palabras_menos_frecuentes(df, col, n)\n",
    "    set_menos_frecuentes = set(arr_menos_frecuentes)\n",
    "    \n",
    "    def contador_menos_frecuentes(texto):\n",
    "        contador = 0\n",
    "        palabras_del_df = word_tokenize(texto)\n",
    "        for palabra in palabras_del_df:\n",
    "            if palabra in set_menos_frecuentes:\n",
    "                contador = contador + 1\n",
    "        return contador\n",
    "    \n",
    "    df['cant_palabras_menos_frecuentes_' + col] = df[~df[col].isnull()][col].apply(contador_menos_frecuentes)\n",
    "    df['cant_palabras_menos_frecuentes_' + col] = df['cant_palabras_menos_frecuentes_' + col].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejemplo():\n",
    "    # Ejemplo de uso de las palabras menos frecuentes\n",
    "    df_palabras = feature_cantidad_menos_frecuentes(df_train, 'titulo', 200)\n",
    "    df_palabras[['id', 'titulo', 'cant_palabras_menos_frecuentes_titulo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_mas_usadas_en_mas_caros_baratos(df, col, n_palabras, n_caros_baratos, df_test=None, mirar_mas_caros=True):\n",
    "    \"\"\"Busca los n_caros mas caros del df, y verifica las n_palabras mas usadas.\"\"\"\n",
    "    \"\"\"Para cada texto de la columna col, cuenta cuantas de estas palabras contiene\"\"\"\n",
    "    \"\"\"Si se pasa un df_test, hace la cuenta teniendo en cuenta las palabras obtenidas en df\"\"\"\n",
    "    \"\"\"Si mirar_mas_caros es True, va a buscar las palabras mas frecuentos de los mas caros, si fuera False,\n",
    "    buscaria las palabras mas frecuentes de los mas baratos\"\"\"\n",
    "    \n",
    "    info = 'CAROS' if mirar_mas_caros else 'BARATOS'\n",
    "    \n",
    "    ver_info_a_filtrar(df, col)\n",
    "    df_busqueda = df.nlargest(n_caros_baratos, 'precio') if mirar_mas_caros else df.nsmallest(n_caros_baratos, 'precio')\n",
    "    arr_mas_frecuentes = generar_palabras_mas_frecuentes(df_busqueda, col, n_palabras)\n",
    "    set_mas_frecuentes = set(arr_mas_frecuentes)\n",
    "\n",
    "    def contador_mas_frecuentes(texto):\n",
    "        contador = 0\n",
    "        palabras_del_df = word_tokenize(texto)\n",
    "        for palabra in palabras_del_df:\n",
    "            if palabra in set_mas_frecuentes:\n",
    "                contador = contador + 1\n",
    "        return contador\n",
    "    \n",
    "    df['palabras_mas_frecuentes_' + info + '_' + col] = df[~df[col].isnull()][col].apply(contador_mas_frecuentes)\n",
    "    df['palabras_mas_frecuentes_' + info + '_' + col] = df['palabras_mas_frecuentes_' + info + '_' + col].fillna(0)\n",
    "    \n",
    "    if df_test is None:\n",
    "        return df, df_test\n",
    "    \n",
    "    df_test['palabras_mas_frecuentes_' + info + '_' + col] = df_test[~df_test[col].isnull()][col].apply(contador_mas_frecuentes)\n",
    "    df_test['palabras_mas_frecuentes_' + info + '_' + col] = df_test['palabras_mas_frecuentes_' + info + '_' + col].fillna(0)\n",
    "    \n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ejemplo():\n",
    "    df = df_train\n",
    "    df_aut = df_test\n",
    "    palabras_mas_usadas_en_mas_caros_baratos(df, 'titulo', 80, 200, df_aut, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es mas lenteja\n",
    "\n",
    "def mas_frecuentes_caros_baratos_ohe(df, col, n_palabras, n_caros_baratos, df_test=None, mirar_mas_caros=True):\n",
    "    \"\"\"Busca los n_caros mas caros del df, y verifica las n_palabras mas usadas.\"\"\"\n",
    "    \"\"\"Hace ohe de las palabras mas usadas obtenidas, sobre la columna col\"\"\"\n",
    "    \"\"\"Si se pasa un df_test, hace la cuenta teniendo en cuenta las palabras obtenidas en df\"\"\"\n",
    "    \"\"\"Si mirar_mas_caros es True, va a buscar las palabras mas frecuentos de los mas caros, si fuera False,\n",
    "    buscaria las palabras mas frecuentes de los mas baratos\"\"\"\n",
    "    \n",
    "    def fill_nans(df, columns, value):\n",
    "        for column in columns:\n",
    "            df[column] = df[column].fillna(value)\n",
    "        return df\n",
    "    \n",
    "    ver_info_a_filtrar(df, col)\n",
    "    df_busqueda = df.nlargest(n_caros_baratos, 'precio') if mirar_mas_caros else df.nsmallest(n_caros_baratos, 'precio')\n",
    "    arr_mas_frecuentes = generar_palabras_mas_frecuentes(df_busqueda, col, n_palabras)\n",
    "    df[col] = df[col].fillna('vacio')\n",
    "    cv = CountVectorizer(vocabulary=arr_mas_frecuentes)    \n",
    "    r = pd.SparseDataFrame(cv.fit_transform(df[col]), df['id'], cv.get_feature_names(), default_fill_value=0)\n",
    "    r = r.reset_index()\n",
    "    df_merge = df.merge(r, on='id')\n",
    "    df_merge = fill_nans(df_merge, cv.get_feature_names(), 0)\n",
    "    \n",
    "    if df_test is None:\n",
    "        return df_merge, df_test\n",
    "    \n",
    "    df_test[col] = df_test[col].fillna('vacio')\n",
    "    r_test = pd.SparseDataFrame(cv.fit_transform(df_test[col]), df_test['id'], cv.get_feature_names(), default_fill_value=0)\n",
    "    r_test = r_test.reset_index()\n",
    "    df_merge_aux = df_test.merge(r_test, on='id')\n",
    "    df_merge_aux = fill_nans(df_merge_aux, cv.get_feature_names(), 0)\n",
    "    \n",
    "    return df_merge, df_merge_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de publicaciones con titulo no nulo es: 234613\n",
      "La cantidad total de publicaciones es: 240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/sparse/frame.py:257: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  sparse_index=BlockIndex(N, blocs, blens),\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/sparse/frame.py:269: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  if column not in sdict\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/generic.py:4583: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(new_data).__finalize__(self)\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/generic.py:5997: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(data).__finalize__(self)\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/frame.py:3471: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/home/tomas/Escritorio/kmeans/datos-tp2/.venv/lib/python3.6/site-packages/pandas/core/sparse/frame.py:745: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  default_fill_value=self._default_fill_value,\n"
     ]
    }
   ],
   "source": [
    "def ejemplo():\n",
    "    df = df_train\n",
    "    df_aut = df_test\n",
    "    df_merge, df_merge_aux = mas_frecuentes_caros_baratos_ohe(df, 'titulo', 200, 1000, df_aut, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
