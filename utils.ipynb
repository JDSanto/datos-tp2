{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_features(df, features=None, label=None):\n",
    "    '''Dado un dataframe, un label y un arreglo de features, devuelve una copia del mismo\n",
    "    con el label y los features especificados.'''\n",
    "    if features is None:\n",
    "        features = df.columns\n",
    "        \n",
    "    else:\n",
    "        features = features.copy()\n",
    "        features += [label]\n",
    "    \n",
    "    s = frozenset(features)\n",
    "    return df[[f for f in df.columns if f in s]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_dataset(df, label, features=None, test_size=0.25):\n",
    "    '''Dado un dataframe df y su label, filtra el mismo por el arreglo de features\n",
    "    y divide el mismo en dos segun test_size para entrenar y testear un modelo. \n",
    "    Si features es None, entonces los dataframes resultantes tendran todas las features.\n",
    "    Devuelve (df_train, df_test, label_train, label_test)\n",
    "    '''\n",
    "    \n",
    "    df = filtrar_features(df, features, label)\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=1)\n",
    "    \n",
    "    y_train = df_train.pop(label)\n",
    "    y_test = df_test.pop(label)\n",
    "    x_train = df_train\n",
    "    x_test = df_test\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_df_testeo(df, test_size=0.25, random_state=None):\n",
    "    '''Dado un dataframe df devuelve dos dataframes, uno para entrenar/validar y el otro para testear\n",
    "    (df_train, df_eval, df_test, label_train, label_eval, label_test)\n",
    "    '''\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(actual, pred):\n",
    "    return (np.mean((np.log(actual + 1) - np.log(pred + 1)) ** 2)) **.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(actual, pred):\n",
    "    return mean_absolute_error(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dolarizar_df(df, col_precio_in='precio', col_precio_out='precio'):\n",
    "    '''Dado un df con columnas para la fecha, id y el precio, pasa el precio\n",
    "    de los mismos a dolares, devolviendo el df.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df_dolares = pd.read_csv('data/cambio_dolar.csv')\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df_dolares['fecha'] = pd.to_datetime(df_dolares['fecha'])\n",
    "    df_merge = pd.merge(df, df_dolares, on='fecha')\n",
    "    assert len(df_merge.values) == len(df.values)\n",
    "    \n",
    "    df = df.sort_values('id')\n",
    "    df_merge = df_merge.sort_values('id')\n",
    "    \n",
    "    df_merge[col_precio_out] = df_merge[col_precio_in] * df_merge['peso_a_dolar']\n",
    "    df[col_precio_out] = df_merge[col_precio_out].values\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def pesificar_df(df, col_precio_in='precio', col_precio_out='precio'):\n",
    "    '''Dado un df con columnas para la fecha, id y el precio, pasa el precio\n",
    "    de los mismos a dolares, devolviendo el df.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df_dolares = pd.read_csv('data/cambio_dolar.csv')\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df_dolares['fecha'] = pd.to_datetime(df_dolares['fecha'])\n",
    "    df_merge = pd.merge(df, df_dolares, on='fecha')\n",
    "    assert len(df_merge.values) == len(df.values)\n",
    "    \n",
    "    df = df.sort_values('id')\n",
    "    df_merge = df_merge.sort_values('id')\n",
    "    \n",
    "    df_merge[col_precio_out] = df_merge[col_precio_in] / df_merge['peso_a_dolar']\n",
    "    df[col_precio_out] = df_merge[col_precio_out].values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'titulo', 'descripcion', 'tipodepropiedad', 'direccion', 'ciudad',\n",
       "       'provincia', 'antiguedad', 'habitaciones', 'garages', 'banos',\n",
       "       'metroscubiertos', 'metrostotales', 'idzona', 'lat', 'lng', 'fecha',\n",
       "       'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas',\n",
       "       'centroscomercialescercanos', 'precio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "filtrar_features(df_train).columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
