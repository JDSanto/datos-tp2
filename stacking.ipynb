{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8988911725316586,\n",
    " 'bagging_freq': 22.0,\n",
    " 'feature_fraction': 0.6622442122619671,\n",
    " 'learning_rate': 0.16422725363286422,\n",
    " 'max_depth': 22.0,\n",
    " 'num_leaves': 180.0,\n",
    " 'test_size': 0.20892455926004772}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "[23:27:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.19093e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.89164e+06\n",
      "[2]\tvalidation_0-mae:1.63443e+06\n",
      "[3]\tvalidation_0-mae:1.41305e+06\n",
      "[4]\tvalidation_0-mae:1.22332e+06\n",
      "[5]\tvalidation_0-mae:1.0611e+06\n",
      "[6]\tvalidation_0-mae:922343\n",
      "[7]\tvalidation_0-mae:803753\n",
      "[8]\tvalidation_0-mae:702876\n",
      "[9]\tvalidation_0-mae:617544\n",
      "[10]\tvalidation_0-mae:545488\n",
      "[11]\tvalidation_0-mae:485060\n",
      "[12]\tvalidation_0-mae:434088\n",
      "[13]\tvalidation_0-mae:391476\n",
      "[14]\tvalidation_0-mae:355909\n",
      "[15]\tvalidation_0-mae:326377\n",
      "[16]\tvalidation_0-mae:301630\n",
      "[17]\tvalidation_0-mae:280903\n",
      "[18]\tvalidation_0-mae:262540\n",
      "[19]\tvalidation_0-mae:247615\n",
      "[20]\tvalidation_0-mae:234889\n",
      "[21]\tvalidation_0-mae:224246\n",
      "[22]\tvalidation_0-mae:215126\n",
      "[23]\tvalidation_0-mae:206164\n",
      "[24]\tvalidation_0-mae:198599\n",
      "[25]\tvalidation_0-mae:192656\n",
      "[26]\tvalidation_0-mae:186973\n",
      "[27]\tvalidation_0-mae:181026\n",
      "[28]\tvalidation_0-mae:175584\n",
      "[29]\tvalidation_0-mae:170651\n",
      "[30]\tvalidation_0-mae:166148\n",
      "[31]\tvalidation_0-mae:161401\n",
      "[32]\tvalidation_0-mae:158024\n",
      "[33]\tvalidation_0-mae:154038\n",
      "[34]\tvalidation_0-mae:151271\n",
      "[35]\tvalidation_0-mae:147679\n",
      "[36]\tvalidation_0-mae:144633\n",
      "[37]\tvalidation_0-mae:141820\n",
      "[38]\tvalidation_0-mae:138505\n",
      "[39]\tvalidation_0-mae:136025\n",
      "[40]\tvalidation_0-mae:133589\n",
      "[41]\tvalidation_0-mae:131174\n",
      "[42]\tvalidation_0-mae:129053\n",
      "[43]\tvalidation_0-mae:126642\n",
      "[44]\tvalidation_0-mae:124732\n",
      "[45]\tvalidation_0-mae:122422\n",
      "[46]\tvalidation_0-mae:120959\n",
      "[47]\tvalidation_0-mae:119623\n",
      "[48]\tvalidation_0-mae:118033\n",
      "[49]\tvalidation_0-mae:115701\n",
      "[50]\tvalidation_0-mae:113985\n",
      "[51]\tvalidation_0-mae:112485\n",
      "[52]\tvalidation_0-mae:111094\n",
      "[53]\tvalidation_0-mae:110447\n",
      "[54]\tvalidation_0-mae:109815\n",
      "[55]\tvalidation_0-mae:108485\n",
      "[56]\tvalidation_0-mae:106972\n",
      "[57]\tvalidation_0-mae:105602\n",
      "[58]\tvalidation_0-mae:104262\n",
      "[59]\tvalidation_0-mae:103296\n",
      "[60]\tvalidation_0-mae:101884\n",
      "[61]\tvalidation_0-mae:100906\n",
      "[62]\tvalidation_0-mae:99648.5\n",
      "[63]\tvalidation_0-mae:98654.6\n",
      "[64]\tvalidation_0-mae:98065.2\n",
      "[65]\tvalidation_0-mae:97258.4\n",
      "[66]\tvalidation_0-mae:96473\n",
      "[67]\tvalidation_0-mae:94186.7\n",
      "[68]\tvalidation_0-mae:93891.1\n",
      "[69]\tvalidation_0-mae:92811.8\n",
      "[70]\tvalidation_0-mae:91791.1\n",
      "[71]\tvalidation_0-mae:90798.6\n",
      "[72]\tvalidation_0-mae:89310.7\n",
      "[73]\tvalidation_0-mae:88794.1\n",
      "[74]\tvalidation_0-mae:88453.6\n",
      "[75]\tvalidation_0-mae:87799.1\n",
      "[76]\tvalidation_0-mae:87317.7\n",
      "[77]\tvalidation_0-mae:86053.3\n",
      "[78]\tvalidation_0-mae:85402.2\n",
      "[79]\tvalidation_0-mae:84498.7\n",
      "[80]\tvalidation_0-mae:84134.4\n",
      "[81]\tvalidation_0-mae:83542.6\n",
      "[82]\tvalidation_0-mae:82831.6\n",
      "[83]\tvalidation_0-mae:81694.6\n",
      "[84]\tvalidation_0-mae:80902.1\n",
      "[85]\tvalidation_0-mae:80162.3\n",
      "[86]\tvalidation_0-mae:79805.8\n",
      "[87]\tvalidation_0-mae:78904.1\n",
      "[88]\tvalidation_0-mae:78674.4\n",
      "[89]\tvalidation_0-mae:78302.4\n",
      "[90]\tvalidation_0-mae:78073.2\n",
      "[91]\tvalidation_0-mae:77839.4\n",
      "[92]\tvalidation_0-mae:77691.7\n",
      "[93]\tvalidation_0-mae:77198.3\n",
      "[94]\tvalidation_0-mae:76921.4\n",
      "[95]\tvalidation_0-mae:76756.5\n",
      "[96]\tvalidation_0-mae:76274.7\n",
      "[97]\tvalidation_0-mae:76143.9\n",
      "[98]\tvalidation_0-mae:75576.2\n",
      "[99]\tvalidation_0-mae:75529\n",
      "[100]\tvalidation_0-mae:74706.2\n",
      "[101]\tvalidation_0-mae:73880.1\n",
      "[102]\tvalidation_0-mae:73169.3\n",
      "[103]\tvalidation_0-mae:72673.2\n",
      "[104]\tvalidation_0-mae:72088.1\n",
      "[105]\tvalidation_0-mae:71822.4\n",
      "[106]\tvalidation_0-mae:71041\n",
      "[107]\tvalidation_0-mae:70382.3\n",
      "[108]\tvalidation_0-mae:69757.2\n",
      "[109]\tvalidation_0-mae:69544.1\n",
      "[110]\tvalidation_0-mae:69261.6\n",
      "[111]\tvalidation_0-mae:68766.7\n",
      "[112]\tvalidation_0-mae:67807.4\n",
      "[113]\tvalidation_0-mae:67593\n",
      "[114]\tvalidation_0-mae:67159.3\n",
      "[115]\tvalidation_0-mae:66918.4\n",
      "[116]\tvalidation_0-mae:66509.8\n",
      "[117]\tvalidation_0-mae:66001.4\n",
      "[118]\tvalidation_0-mae:65753.9\n",
      "[119]\tvalidation_0-mae:65539\n",
      "[120]\tvalidation_0-mae:65464.1\n",
      "[121]\tvalidation_0-mae:65378.7\n",
      "[122]\tvalidation_0-mae:64717.5\n",
      "[123]\tvalidation_0-mae:64400.2\n",
      "[124]\tvalidation_0-mae:64319.8\n",
      "[125]\tvalidation_0-mae:64082.2\n",
      "[126]\tvalidation_0-mae:63725.1\n",
      "[127]\tvalidation_0-mae:63287\n",
      "[128]\tvalidation_0-mae:62969.5\n",
      "[129]\tvalidation_0-mae:62608.2\n",
      "[130]\tvalidation_0-mae:62094.7\n",
      "[131]\tvalidation_0-mae:61769.3\n",
      "[132]\tvalidation_0-mae:61407.6\n",
      "[133]\tvalidation_0-mae:60807.5\n",
      "[134]\tvalidation_0-mae:60641.5\n",
      "[135]\tvalidation_0-mae:60526.2\n",
      "[136]\tvalidation_0-mae:59913.8\n",
      "[137]\tvalidation_0-mae:59780.4\n",
      "[138]\tvalidation_0-mae:59576.4\n",
      "[139]\tvalidation_0-mae:59212.6\n",
      "[140]\tvalidation_0-mae:58491.9\n",
      "[141]\tvalidation_0-mae:58445.8\n",
      "[142]\tvalidation_0-mae:57835.8\n",
      "[143]\tvalidation_0-mae:57415.1\n",
      "[144]\tvalidation_0-mae:56946.1\n",
      "[145]\tvalidation_0-mae:56597.4\n",
      "[146]\tvalidation_0-mae:56272.2\n",
      "[147]\tvalidation_0-mae:55642.6\n",
      "[148]\tvalidation_0-mae:55329.9\n",
      "[149]\tvalidation_0-mae:55114.4\n",
      "    fold  0:  [460575.48596253]\n",
      "[23:29:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18406e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88581e+06\n",
      "[2]\tvalidation_0-mae:1.62926e+06\n",
      "[3]\tvalidation_0-mae:1.40862e+06\n",
      "[4]\tvalidation_0-mae:1.21958e+06\n",
      "[5]\tvalidation_0-mae:1.05779e+06\n",
      "[6]\tvalidation_0-mae:919393\n",
      "[7]\tvalidation_0-mae:801105\n",
      "[8]\tvalidation_0-mae:700529\n",
      "[9]\tvalidation_0-mae:615668\n",
      "[10]\tvalidation_0-mae:543805\n",
      "[11]\tvalidation_0-mae:483555\n",
      "[12]\tvalidation_0-mae:432607\n",
      "[13]\tvalidation_0-mae:390064\n",
      "[14]\tvalidation_0-mae:354346\n",
      "[15]\tvalidation_0-mae:324830\n",
      "[16]\tvalidation_0-mae:300127\n",
      "[17]\tvalidation_0-mae:279534\n",
      "[18]\tvalidation_0-mae:261205\n",
      "[19]\tvalidation_0-mae:246181\n",
      "[20]\tvalidation_0-mae:233260\n",
      "[21]\tvalidation_0-mae:222143\n",
      "[22]\tvalidation_0-mae:213079\n",
      "[23]\tvalidation_0-mae:204119\n",
      "[24]\tvalidation_0-mae:196834\n",
      "[25]\tvalidation_0-mae:190252\n",
      "[26]\tvalidation_0-mae:184755\n",
      "[27]\tvalidation_0-mae:178497\n",
      "[28]\tvalidation_0-mae:173067\n",
      "[29]\tvalidation_0-mae:168044\n",
      "[30]\tvalidation_0-mae:163435\n",
      "[31]\tvalidation_0-mae:159378\n",
      "[32]\tvalidation_0-mae:156678\n",
      "[33]\tvalidation_0-mae:152546\n",
      "[34]\tvalidation_0-mae:149035\n",
      "[35]\tvalidation_0-mae:144961\n",
      "[36]\tvalidation_0-mae:141870\n",
      "[37]\tvalidation_0-mae:138759\n",
      "[38]\tvalidation_0-mae:136100\n",
      "[39]\tvalidation_0-mae:133922\n",
      "[40]\tvalidation_0-mae:130890\n",
      "[41]\tvalidation_0-mae:127790\n",
      "[42]\tvalidation_0-mae:125853\n",
      "[43]\tvalidation_0-mae:122865\n",
      "[44]\tvalidation_0-mae:120196\n",
      "[45]\tvalidation_0-mae:117879\n",
      "[46]\tvalidation_0-mae:115984\n",
      "[47]\tvalidation_0-mae:114428\n",
      "[48]\tvalidation_0-mae:113392\n",
      "[49]\tvalidation_0-mae:111313\n",
      "[50]\tvalidation_0-mae:109749\n",
      "[51]\tvalidation_0-mae:108396\n",
      "[52]\tvalidation_0-mae:107032\n",
      "[53]\tvalidation_0-mae:106197\n",
      "[54]\tvalidation_0-mae:105313\n",
      "[55]\tvalidation_0-mae:103713\n",
      "[56]\tvalidation_0-mae:102287\n",
      "[57]\tvalidation_0-mae:101086\n",
      "[58]\tvalidation_0-mae:100028\n",
      "[59]\tvalidation_0-mae:99124.1\n",
      "[60]\tvalidation_0-mae:98332.7\n",
      "[61]\tvalidation_0-mae:97492.8\n",
      "[62]\tvalidation_0-mae:96271.5\n",
      "[63]\tvalidation_0-mae:95062.4\n",
      "[64]\tvalidation_0-mae:94605\n",
      "[65]\tvalidation_0-mae:94027.7\n",
      "[66]\tvalidation_0-mae:93078\n",
      "[67]\tvalidation_0-mae:91968.3\n",
      "[68]\tvalidation_0-mae:91124.8\n",
      "[69]\tvalidation_0-mae:90716.5\n",
      "[70]\tvalidation_0-mae:89970.3\n",
      "[71]\tvalidation_0-mae:89189.7\n",
      "[72]\tvalidation_0-mae:87741.5\n",
      "[73]\tvalidation_0-mae:87007.4\n",
      "[74]\tvalidation_0-mae:85264.9\n",
      "[75]\tvalidation_0-mae:84780.5\n",
      "[76]\tvalidation_0-mae:84097.7\n",
      "[77]\tvalidation_0-mae:83385.1\n",
      "[78]\tvalidation_0-mae:83035.4\n",
      "[79]\tvalidation_0-mae:82677.3\n",
      "[80]\tvalidation_0-mae:81543.7\n",
      "[81]\tvalidation_0-mae:81221.3\n",
      "[82]\tvalidation_0-mae:80740.2\n",
      "[83]\tvalidation_0-mae:80195\n",
      "[84]\tvalidation_0-mae:79911.2\n",
      "[85]\tvalidation_0-mae:79119\n",
      "[86]\tvalidation_0-mae:78736.5\n",
      "[87]\tvalidation_0-mae:78654.5\n",
      "[88]\tvalidation_0-mae:78512.1\n",
      "[89]\tvalidation_0-mae:77791.8\n",
      "[90]\tvalidation_0-mae:77373.2\n",
      "[91]\tvalidation_0-mae:76803.9\n",
      "[92]\tvalidation_0-mae:76594.5\n",
      "[93]\tvalidation_0-mae:75906.5\n",
      "[94]\tvalidation_0-mae:75265.4\n",
      "[95]\tvalidation_0-mae:75042.9\n",
      "[96]\tvalidation_0-mae:74951.6\n",
      "[97]\tvalidation_0-mae:74666.4\n",
      "[98]\tvalidation_0-mae:74037\n",
      "[99]\tvalidation_0-mae:73526\n",
      "[100]\tvalidation_0-mae:73259.9\n",
      "[101]\tvalidation_0-mae:72247.9\n",
      "[102]\tvalidation_0-mae:72010.1\n",
      "[103]\tvalidation_0-mae:71643.6\n",
      "[104]\tvalidation_0-mae:71263.4\n",
      "[105]\tvalidation_0-mae:70838.5\n",
      "[106]\tvalidation_0-mae:70311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107]\tvalidation_0-mae:69672.7\n",
      "[108]\tvalidation_0-mae:69460.6\n",
      "[109]\tvalidation_0-mae:69192.7\n",
      "[110]\tvalidation_0-mae:68867.2\n",
      "[111]\tvalidation_0-mae:68413.9\n",
      "[112]\tvalidation_0-mae:68192.5\n",
      "[113]\tvalidation_0-mae:67930.9\n",
      "[114]\tvalidation_0-mae:67735.9\n",
      "[115]\tvalidation_0-mae:67641.2\n",
      "[116]\tvalidation_0-mae:67340.4\n",
      "[117]\tvalidation_0-mae:66843.9\n",
      "[118]\tvalidation_0-mae:66535.2\n",
      "[119]\tvalidation_0-mae:66129.2\n",
      "[120]\tvalidation_0-mae:65648.8\n",
      "[121]\tvalidation_0-mae:65459.6\n",
      "[122]\tvalidation_0-mae:65233\n",
      "[123]\tvalidation_0-mae:65003.7\n",
      "[124]\tvalidation_0-mae:64905.8\n",
      "[125]\tvalidation_0-mae:64479.8\n",
      "[126]\tvalidation_0-mae:64259\n",
      "[127]\tvalidation_0-mae:63910.9\n",
      "[128]\tvalidation_0-mae:63491.5\n",
      "[129]\tvalidation_0-mae:63391.7\n",
      "[130]\tvalidation_0-mae:63122.8\n",
      "[131]\tvalidation_0-mae:62963.6\n",
      "[132]\tvalidation_0-mae:62808.8\n",
      "[133]\tvalidation_0-mae:62707.9\n",
      "[134]\tvalidation_0-mae:62485.9\n",
      "[135]\tvalidation_0-mae:62405.2\n",
      "[136]\tvalidation_0-mae:61916.9\n",
      "[137]\tvalidation_0-mae:61629\n",
      "[138]\tvalidation_0-mae:61161.6\n",
      "[139]\tvalidation_0-mae:61037.7\n",
      "[140]\tvalidation_0-mae:60754.2\n",
      "[141]\tvalidation_0-mae:60607.8\n",
      "[142]\tvalidation_0-mae:60181.4\n",
      "[143]\tvalidation_0-mae:59487.2\n",
      "[144]\tvalidation_0-mae:59382\n",
      "[145]\tvalidation_0-mae:59331\n",
      "[146]\tvalidation_0-mae:59196.5\n",
      "[147]\tvalidation_0-mae:59066.2\n",
      "[148]\tvalidation_0-mae:58407.2\n",
      "[149]\tvalidation_0-mae:58110.6\n",
      "    fold  1:  [471598.04388138]\n",
      "[23:32:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18235e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.8844e+06\n",
      "[2]\tvalidation_0-mae:1.62818e+06\n",
      "[3]\tvalidation_0-mae:1.40762e+06\n",
      "[4]\tvalidation_0-mae:1.21871e+06\n",
      "[5]\tvalidation_0-mae:1.05691e+06\n",
      "[6]\tvalidation_0-mae:918774\n",
      "[7]\tvalidation_0-mae:800605\n",
      "[8]\tvalidation_0-mae:700042\n",
      "[9]\tvalidation_0-mae:615188\n",
      "[10]\tvalidation_0-mae:543409\n",
      "[11]\tvalidation_0-mae:483108\n",
      "[12]\tvalidation_0-mae:432091\n",
      "[13]\tvalidation_0-mae:389546\n",
      "[14]\tvalidation_0-mae:353789\n",
      "[15]\tvalidation_0-mae:324174\n",
      "[16]\tvalidation_0-mae:299447\n",
      "[17]\tvalidation_0-mae:278761\n",
      "[18]\tvalidation_0-mae:260517\n",
      "[19]\tvalidation_0-mae:245388\n",
      "[20]\tvalidation_0-mae:232386\n",
      "[21]\tvalidation_0-mae:221267\n",
      "[22]\tvalidation_0-mae:212163\n",
      "[23]\tvalidation_0-mae:203251\n",
      "[24]\tvalidation_0-mae:195829\n",
      "[25]\tvalidation_0-mae:189433\n",
      "[26]\tvalidation_0-mae:183789\n",
      "[27]\tvalidation_0-mae:177438\n",
      "[28]\tvalidation_0-mae:171807\n",
      "[29]\tvalidation_0-mae:166987\n",
      "[30]\tvalidation_0-mae:162298\n",
      "[31]\tvalidation_0-mae:157699\n",
      "[32]\tvalidation_0-mae:154767\n",
      "[33]\tvalidation_0-mae:150949\n",
      "[34]\tvalidation_0-mae:147958\n",
      "[35]\tvalidation_0-mae:144145\n",
      "[36]\tvalidation_0-mae:141230\n",
      "[37]\tvalidation_0-mae:138469\n",
      "[38]\tvalidation_0-mae:135586\n",
      "[39]\tvalidation_0-mae:133204\n",
      "[40]\tvalidation_0-mae:130634\n",
      "[41]\tvalidation_0-mae:127967\n",
      "[42]\tvalidation_0-mae:125994\n",
      "[43]\tvalidation_0-mae:123536\n",
      "[44]\tvalidation_0-mae:121155\n",
      "[45]\tvalidation_0-mae:118610\n",
      "[46]\tvalidation_0-mae:117271\n",
      "[47]\tvalidation_0-mae:114987\n",
      "[48]\tvalidation_0-mae:113913\n",
      "[49]\tvalidation_0-mae:112446\n",
      "[50]\tvalidation_0-mae:110513\n",
      "[51]\tvalidation_0-mae:109006\n",
      "[52]\tvalidation_0-mae:107350\n",
      "[53]\tvalidation_0-mae:106308\n",
      "[54]\tvalidation_0-mae:105389\n",
      "[55]\tvalidation_0-mae:103783\n",
      "[56]\tvalidation_0-mae:102403\n",
      "[57]\tvalidation_0-mae:101659\n",
      "[58]\tvalidation_0-mae:100792\n",
      "[59]\tvalidation_0-mae:99897.9\n",
      "[60]\tvalidation_0-mae:99247.8\n",
      "[61]\tvalidation_0-mae:97455\n",
      "[62]\tvalidation_0-mae:96246.5\n",
      "[63]\tvalidation_0-mae:95607.4\n",
      "[64]\tvalidation_0-mae:95047\n",
      "[65]\tvalidation_0-mae:94186.6\n",
      "[66]\tvalidation_0-mae:93967.7\n",
      "[67]\tvalidation_0-mae:92314.9\n",
      "[68]\tvalidation_0-mae:91903.5\n",
      "[69]\tvalidation_0-mae:91528.6\n",
      "[70]\tvalidation_0-mae:90169.8\n",
      "[71]\tvalidation_0-mae:89632.3\n",
      "[72]\tvalidation_0-mae:88438\n",
      "[73]\tvalidation_0-mae:88038\n",
      "[74]\tvalidation_0-mae:87491.5\n",
      "[75]\tvalidation_0-mae:86621.5\n",
      "[76]\tvalidation_0-mae:86253.4\n",
      "[77]\tvalidation_0-mae:85386.1\n",
      "[78]\tvalidation_0-mae:85147.4\n",
      "[79]\tvalidation_0-mae:83832.7\n",
      "[80]\tvalidation_0-mae:83360.2\n",
      "[81]\tvalidation_0-mae:82658.5\n",
      "[82]\tvalidation_0-mae:82521.5\n",
      "[83]\tvalidation_0-mae:82227.7\n",
      "[84]\tvalidation_0-mae:82063.4\n",
      "[85]\tvalidation_0-mae:81611.2\n",
      "[86]\tvalidation_0-mae:80845.3\n",
      "[87]\tvalidation_0-mae:80456.3\n",
      "[88]\tvalidation_0-mae:80315.7\n",
      "[89]\tvalidation_0-mae:79752.5\n",
      "[90]\tvalidation_0-mae:79253.8\n",
      "[91]\tvalidation_0-mae:77877\n",
      "[92]\tvalidation_0-mae:77168.9\n",
      "[93]\tvalidation_0-mae:76427.4\n",
      "[94]\tvalidation_0-mae:75912.7\n",
      "[95]\tvalidation_0-mae:75425.9\n",
      "[96]\tvalidation_0-mae:75317.2\n",
      "[97]\tvalidation_0-mae:75092.5\n",
      "[98]\tvalidation_0-mae:74184.9\n",
      "[99]\tvalidation_0-mae:73761.9\n",
      "[100]\tvalidation_0-mae:72957.1\n",
      "[101]\tvalidation_0-mae:72432.1\n",
      "[102]\tvalidation_0-mae:72142.7\n",
      "[103]\tvalidation_0-mae:71750.6\n",
      "[104]\tvalidation_0-mae:71626.6\n",
      "[105]\tvalidation_0-mae:71422.2\n",
      "[106]\tvalidation_0-mae:71313.3\n",
      "[107]\tvalidation_0-mae:71060.5\n",
      "[108]\tvalidation_0-mae:70569.7\n",
      "[109]\tvalidation_0-mae:70347.5\n",
      "[110]\tvalidation_0-mae:70034.6\n",
      "[111]\tvalidation_0-mae:69135.3\n",
      "[112]\tvalidation_0-mae:68858.1\n",
      "[113]\tvalidation_0-mae:68497.1\n",
      "[114]\tvalidation_0-mae:67871.7\n",
      "[115]\tvalidation_0-mae:67466.6\n",
      "[116]\tvalidation_0-mae:67092.9\n",
      "[117]\tvalidation_0-mae:66785.9\n",
      "[118]\tvalidation_0-mae:66041\n",
      "[119]\tvalidation_0-mae:65250.7\n",
      "[120]\tvalidation_0-mae:65086\n",
      "[121]\tvalidation_0-mae:64948.7\n",
      "[122]\tvalidation_0-mae:64536.5\n",
      "[123]\tvalidation_0-mae:64253.7\n",
      "[124]\tvalidation_0-mae:64021.1\n",
      "[125]\tvalidation_0-mae:63822.8\n",
      "[126]\tvalidation_0-mae:63685\n",
      "[127]\tvalidation_0-mae:63286.8\n",
      "[128]\tvalidation_0-mae:62864.2\n",
      "[129]\tvalidation_0-mae:62478.1\n",
      "[130]\tvalidation_0-mae:62170.5\n",
      "[131]\tvalidation_0-mae:61649.5\n",
      "[132]\tvalidation_0-mae:61349.7\n",
      "[133]\tvalidation_0-mae:61227.6\n",
      "[134]\tvalidation_0-mae:60952.6\n",
      "[135]\tvalidation_0-mae:60689.3\n",
      "[136]\tvalidation_0-mae:60590.2\n",
      "[137]\tvalidation_0-mae:60432.4\n",
      "[138]\tvalidation_0-mae:60300\n",
      "[139]\tvalidation_0-mae:60128.1\n",
      "[140]\tvalidation_0-mae:59909\n",
      "[141]\tvalidation_0-mae:59798.7\n",
      "[142]\tvalidation_0-mae:59245.4\n",
      "[143]\tvalidation_0-mae:58879\n",
      "[144]\tvalidation_0-mae:58695.5\n",
      "[145]\tvalidation_0-mae:58171.4\n",
      "[146]\tvalidation_0-mae:57671.1\n",
      "[147]\tvalidation_0-mae:57327.6\n",
      "[148]\tvalidation_0-mae:56825.3\n",
      "[149]\tvalidation_0-mae:56540.2\n",
      "    fold  2:  [472375.56408205]\n",
      "[23:35:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18457e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88625e+06\n",
      "[2]\tvalidation_0-mae:1.62969e+06\n",
      "[3]\tvalidation_0-mae:1.40907e+06\n",
      "[4]\tvalidation_0-mae:1.21977e+06\n",
      "[5]\tvalidation_0-mae:1.05779e+06\n",
      "[6]\tvalidation_0-mae:919450\n",
      "[7]\tvalidation_0-mae:801353\n",
      "[8]\tvalidation_0-mae:700855\n",
      "[9]\tvalidation_0-mae:616134\n",
      "[10]\tvalidation_0-mae:544352\n",
      "[11]\tvalidation_0-mae:484132\n",
      "[12]\tvalidation_0-mae:433392\n",
      "[13]\tvalidation_0-mae:391076\n",
      "[14]\tvalidation_0-mae:355560\n",
      "[15]\tvalidation_0-mae:325848\n",
      "[16]\tvalidation_0-mae:301134\n",
      "[17]\tvalidation_0-mae:280352\n",
      "[18]\tvalidation_0-mae:262293\n",
      "[19]\tvalidation_0-mae:247134\n",
      "[20]\tvalidation_0-mae:234367\n",
      "[21]\tvalidation_0-mae:223095\n",
      "[22]\tvalidation_0-mae:214209\n",
      "[23]\tvalidation_0-mae:205413\n",
      "[24]\tvalidation_0-mae:197618\n",
      "[25]\tvalidation_0-mae:191150\n",
      "[26]\tvalidation_0-mae:185430\n",
      "[27]\tvalidation_0-mae:179746\n",
      "[28]\tvalidation_0-mae:174262\n",
      "[29]\tvalidation_0-mae:169504\n",
      "[30]\tvalidation_0-mae:164917\n",
      "[31]\tvalidation_0-mae:161035\n",
      "[32]\tvalidation_0-mae:158043\n",
      "[33]\tvalidation_0-mae:153746\n",
      "[34]\tvalidation_0-mae:150789\n",
      "[35]\tvalidation_0-mae:147226\n",
      "[36]\tvalidation_0-mae:144472\n",
      "[37]\tvalidation_0-mae:141618\n",
      "[38]\tvalidation_0-mae:138652\n",
      "[39]\tvalidation_0-mae:135937\n",
      "[40]\tvalidation_0-mae:133572\n",
      "[41]\tvalidation_0-mae:130991\n",
      "[42]\tvalidation_0-mae:128858\n",
      "[43]\tvalidation_0-mae:126446\n",
      "[44]\tvalidation_0-mae:124083\n",
      "[45]\tvalidation_0-mae:121544\n",
      "[46]\tvalidation_0-mae:119962\n",
      "[47]\tvalidation_0-mae:118103\n",
      "[48]\tvalidation_0-mae:117115\n",
      "[49]\tvalidation_0-mae:115325\n",
      "[50]\tvalidation_0-mae:113881\n",
      "[51]\tvalidation_0-mae:112434\n",
      "[52]\tvalidation_0-mae:110678\n",
      "[53]\tvalidation_0-mae:109703\n",
      "[54]\tvalidation_0-mae:108981\n",
      "[55]\tvalidation_0-mae:107635\n",
      "[56]\tvalidation_0-mae:106113\n",
      "[57]\tvalidation_0-mae:105027\n",
      "[58]\tvalidation_0-mae:104221\n",
      "[59]\tvalidation_0-mae:103187\n",
      "[60]\tvalidation_0-mae:102170\n",
      "[61]\tvalidation_0-mae:101176\n",
      "[62]\tvalidation_0-mae:100035\n",
      "[63]\tvalidation_0-mae:99094.5\n",
      "[64]\tvalidation_0-mae:98580.5\n",
      "[65]\tvalidation_0-mae:97846.5\n",
      "[66]\tvalidation_0-mae:97385.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\tvalidation_0-mae:96678.6\n",
      "[68]\tvalidation_0-mae:96414.2\n",
      "[69]\tvalidation_0-mae:95815.9\n",
      "[70]\tvalidation_0-mae:94931.9\n",
      "[71]\tvalidation_0-mae:94598.7\n",
      "[72]\tvalidation_0-mae:93843.5\n",
      "[73]\tvalidation_0-mae:93173.7\n",
      "[74]\tvalidation_0-mae:92642.1\n",
      "[75]\tvalidation_0-mae:92234.7\n",
      "[76]\tvalidation_0-mae:91080\n",
      "[77]\tvalidation_0-mae:90831.2\n",
      "[78]\tvalidation_0-mae:90266.8\n",
      "[79]\tvalidation_0-mae:89742.1\n",
      "[80]\tvalidation_0-mae:89186.8\n",
      "[81]\tvalidation_0-mae:88839.4\n",
      "[82]\tvalidation_0-mae:87956.5\n",
      "[83]\tvalidation_0-mae:87497.9\n",
      "[84]\tvalidation_0-mae:87310.7\n",
      "[85]\tvalidation_0-mae:87014.8\n",
      "[86]\tvalidation_0-mae:86461.5\n",
      "[87]\tvalidation_0-mae:86238.6\n",
      "[88]\tvalidation_0-mae:85955.1\n",
      "[89]\tvalidation_0-mae:85664\n",
      "[90]\tvalidation_0-mae:85039.9\n",
      "[91]\tvalidation_0-mae:84810.9\n",
      "[92]\tvalidation_0-mae:84398.1\n",
      "[93]\tvalidation_0-mae:83961.1\n",
      "[94]\tvalidation_0-mae:83395.1\n",
      "[95]\tvalidation_0-mae:82884.9\n",
      "[96]\tvalidation_0-mae:82144.4\n",
      "[97]\tvalidation_0-mae:80963.3\n",
      "[98]\tvalidation_0-mae:79927.3\n",
      "[99]\tvalidation_0-mae:79092.2\n",
      "[100]\tvalidation_0-mae:78327.7\n",
      "[101]\tvalidation_0-mae:77644.4\n",
      "[102]\tvalidation_0-mae:77129\n",
      "[103]\tvalidation_0-mae:76699.1\n",
      "[104]\tvalidation_0-mae:76532.8\n",
      "[105]\tvalidation_0-mae:75750.7\n",
      "[106]\tvalidation_0-mae:75597.2\n",
      "[107]\tvalidation_0-mae:75154.4\n",
      "[108]\tvalidation_0-mae:74409.4\n",
      "[109]\tvalidation_0-mae:73953.4\n",
      "[110]\tvalidation_0-mae:73507.7\n",
      "[111]\tvalidation_0-mae:72912.9\n",
      "[112]\tvalidation_0-mae:72407.4\n",
      "[113]\tvalidation_0-mae:71914.8\n",
      "[114]\tvalidation_0-mae:71421.8\n",
      "[115]\tvalidation_0-mae:71072.4\n",
      "[116]\tvalidation_0-mae:70351.1\n",
      "[117]\tvalidation_0-mae:69951.1\n",
      "[118]\tvalidation_0-mae:69526.9\n",
      "[119]\tvalidation_0-mae:69062.5\n",
      "[120]\tvalidation_0-mae:68780.7\n",
      "[121]\tvalidation_0-mae:68436.1\n",
      "[122]\tvalidation_0-mae:68138.2\n",
      "[123]\tvalidation_0-mae:67841.2\n",
      "[124]\tvalidation_0-mae:67515.1\n",
      "[125]\tvalidation_0-mae:67075\n",
      "[126]\tvalidation_0-mae:66631.3\n",
      "[127]\tvalidation_0-mae:66140.8\n",
      "[128]\tvalidation_0-mae:65705.7\n",
      "[129]\tvalidation_0-mae:65360.1\n",
      "[130]\tvalidation_0-mae:65050.6\n",
      "[131]\tvalidation_0-mae:64702.9\n",
      "[132]\tvalidation_0-mae:64138.3\n",
      "[133]\tvalidation_0-mae:63456.9\n",
      "[134]\tvalidation_0-mae:63272.4\n",
      "[135]\tvalidation_0-mae:62528.6\n",
      "[136]\tvalidation_0-mae:61984.8\n",
      "[137]\tvalidation_0-mae:61693.2\n",
      "[138]\tvalidation_0-mae:61146.5\n",
      "[139]\tvalidation_0-mae:60826.2\n",
      "[140]\tvalidation_0-mae:60734\n",
      "[141]\tvalidation_0-mae:59924.9\n",
      "[142]\tvalidation_0-mae:59789.8\n",
      "[143]\tvalidation_0-mae:59459.9\n",
      "[144]\tvalidation_0-mae:59256.3\n",
      "[145]\tvalidation_0-mae:58876.3\n",
      "[146]\tvalidation_0-mae:58529\n",
      "[147]\tvalidation_0-mae:58196.5\n",
      "[148]\tvalidation_0-mae:57822.5\n",
      "[149]\tvalidation_0-mae:57638.8\n",
      "    fold  3:  [467711.78266000]\n",
      "[23:38:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18349e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88528e+06\n",
      "[2]\tvalidation_0-mae:1.62867e+06\n",
      "[3]\tvalidation_0-mae:1.4082e+06\n",
      "[4]\tvalidation_0-mae:1.2192e+06\n",
      "[5]\tvalidation_0-mae:1.0574e+06\n",
      "[6]\tvalidation_0-mae:919230\n",
      "[7]\tvalidation_0-mae:801062\n",
      "[8]\tvalidation_0-mae:700326\n",
      "[9]\tvalidation_0-mae:615447\n",
      "[10]\tvalidation_0-mae:543565\n",
      "[11]\tvalidation_0-mae:483289\n",
      "[12]\tvalidation_0-mae:432403\n",
      "[13]\tvalidation_0-mae:389615\n",
      "[14]\tvalidation_0-mae:353924\n",
      "[15]\tvalidation_0-mae:324337\n",
      "[16]\tvalidation_0-mae:299505\n",
      "[17]\tvalidation_0-mae:278845\n",
      "[18]\tvalidation_0-mae:260799\n",
      "[19]\tvalidation_0-mae:245549\n",
      "[20]\tvalidation_0-mae:232771\n",
      "[21]\tvalidation_0-mae:222095\n",
      "[22]\tvalidation_0-mae:213023\n",
      "[23]\tvalidation_0-mae:204013\n",
      "[24]\tvalidation_0-mae:197057\n",
      "[25]\tvalidation_0-mae:190789\n",
      "[26]\tvalidation_0-mae:185195\n",
      "[27]\tvalidation_0-mae:179302\n",
      "[28]\tvalidation_0-mae:173959\n",
      "[29]\tvalidation_0-mae:169318\n",
      "[30]\tvalidation_0-mae:164477\n",
      "[31]\tvalidation_0-mae:159954\n",
      "[32]\tvalidation_0-mae:157064\n",
      "[33]\tvalidation_0-mae:152907\n",
      "[34]\tvalidation_0-mae:149712\n",
      "[35]\tvalidation_0-mae:145907\n",
      "[36]\tvalidation_0-mae:142517\n",
      "[37]\tvalidation_0-mae:139449\n",
      "[38]\tvalidation_0-mae:136728\n",
      "[39]\tvalidation_0-mae:134283\n",
      "[40]\tvalidation_0-mae:132065\n",
      "[41]\tvalidation_0-mae:129318\n",
      "[42]\tvalidation_0-mae:127538\n",
      "[43]\tvalidation_0-mae:124734\n",
      "[44]\tvalidation_0-mae:122111\n",
      "[45]\tvalidation_0-mae:120184\n",
      "[46]\tvalidation_0-mae:118986\n",
      "[47]\tvalidation_0-mae:117062\n",
      "[48]\tvalidation_0-mae:115329\n",
      "[49]\tvalidation_0-mae:113206\n",
      "[50]\tvalidation_0-mae:111044\n",
      "[51]\tvalidation_0-mae:109978\n",
      "[52]\tvalidation_0-mae:108473\n",
      "[53]\tvalidation_0-mae:107596\n",
      "[54]\tvalidation_0-mae:106887\n",
      "[55]\tvalidation_0-mae:105231\n",
      "[56]\tvalidation_0-mae:104056\n",
      "[57]\tvalidation_0-mae:102947\n",
      "[58]\tvalidation_0-mae:101606\n",
      "[59]\tvalidation_0-mae:100240\n",
      "[60]\tvalidation_0-mae:99393.4\n",
      "[61]\tvalidation_0-mae:98830.8\n",
      "[62]\tvalidation_0-mae:97668\n",
      "[63]\tvalidation_0-mae:96872.1\n",
      "[64]\tvalidation_0-mae:96444.5\n",
      "[65]\tvalidation_0-mae:95584.8\n",
      "[66]\tvalidation_0-mae:95134.8\n",
      "[67]\tvalidation_0-mae:93443.5\n",
      "[68]\tvalidation_0-mae:92225.2\n",
      "[69]\tvalidation_0-mae:91711.2\n",
      "[70]\tvalidation_0-mae:90402.8\n",
      "[71]\tvalidation_0-mae:89443.1\n",
      "[72]\tvalidation_0-mae:89053.7\n",
      "[73]\tvalidation_0-mae:88513\n",
      "[74]\tvalidation_0-mae:87948\n",
      "[75]\tvalidation_0-mae:87611.8\n",
      "[76]\tvalidation_0-mae:87009.2\n",
      "[77]\tvalidation_0-mae:86596.2\n",
      "[78]\tvalidation_0-mae:85799.5\n",
      "[79]\tvalidation_0-mae:84793.6\n",
      "[80]\tvalidation_0-mae:84291.5\n",
      "[81]\tvalidation_0-mae:84076.6\n",
      "[82]\tvalidation_0-mae:83134.2\n",
      "[83]\tvalidation_0-mae:82387.1\n",
      "[84]\tvalidation_0-mae:81852\n",
      "[85]\tvalidation_0-mae:80819.1\n",
      "[86]\tvalidation_0-mae:80335\n",
      "[87]\tvalidation_0-mae:80020.2\n",
      "[88]\tvalidation_0-mae:79588.7\n",
      "[89]\tvalidation_0-mae:78155\n",
      "[90]\tvalidation_0-mae:77431.2\n",
      "[91]\tvalidation_0-mae:76966.9\n",
      "[92]\tvalidation_0-mae:76247.3\n",
      "[93]\tvalidation_0-mae:75609.9\n",
      "[94]\tvalidation_0-mae:75171.2\n",
      "[95]\tvalidation_0-mae:74765.8\n",
      "[96]\tvalidation_0-mae:73768.7\n",
      "[97]\tvalidation_0-mae:73176.7\n",
      "[98]\tvalidation_0-mae:72455.4\n",
      "[99]\tvalidation_0-mae:72017.5\n",
      "[100]\tvalidation_0-mae:70932.5\n",
      "[101]\tvalidation_0-mae:70026.1\n",
      "[102]\tvalidation_0-mae:69551.2\n",
      "[103]\tvalidation_0-mae:68908.1\n",
      "[104]\tvalidation_0-mae:68588.9\n",
      "[105]\tvalidation_0-mae:68291.4\n",
      "[106]\tvalidation_0-mae:68148.7\n",
      "[107]\tvalidation_0-mae:68003.9\n",
      "[108]\tvalidation_0-mae:67414\n",
      "[109]\tvalidation_0-mae:67079.9\n",
      "[110]\tvalidation_0-mae:66718.2\n",
      "[111]\tvalidation_0-mae:65974.7\n",
      "[112]\tvalidation_0-mae:65556.7\n",
      "[113]\tvalidation_0-mae:65457.2\n",
      "[114]\tvalidation_0-mae:64906.4\n",
      "[115]\tvalidation_0-mae:64765.8\n",
      "[116]\tvalidation_0-mae:64316.5\n",
      "[117]\tvalidation_0-mae:63860.6\n",
      "[118]\tvalidation_0-mae:63062.7\n",
      "[119]\tvalidation_0-mae:62699.3\n",
      "[120]\tvalidation_0-mae:62105.1\n",
      "[121]\tvalidation_0-mae:61769.8\n",
      "[122]\tvalidation_0-mae:61391.5\n",
      "[123]\tvalidation_0-mae:61291.3\n",
      "[124]\tvalidation_0-mae:60842.2\n",
      "[125]\tvalidation_0-mae:60653.9\n",
      "[126]\tvalidation_0-mae:60428.7\n",
      "[127]\tvalidation_0-mae:60268.6\n",
      "[128]\tvalidation_0-mae:59626.8\n",
      "[129]\tvalidation_0-mae:59316.9\n",
      "[130]\tvalidation_0-mae:58840.1\n",
      "[131]\tvalidation_0-mae:58674.1\n",
      "[132]\tvalidation_0-mae:58335.1\n",
      "[133]\tvalidation_0-mae:58146.8\n",
      "[134]\tvalidation_0-mae:57855.6\n",
      "[135]\tvalidation_0-mae:57701.5\n",
      "[136]\tvalidation_0-mae:57378.8\n",
      "[137]\tvalidation_0-mae:57281.9\n",
      "[138]\tvalidation_0-mae:56845.8\n",
      "[139]\tvalidation_0-mae:56347.7\n",
      "[140]\tvalidation_0-mae:56120.4\n",
      "[141]\tvalidation_0-mae:55860.9\n",
      "[142]\tvalidation_0-mae:55287.3\n",
      "[143]\tvalidation_0-mae:55034.1\n",
      "[144]\tvalidation_0-mae:54782.2\n",
      "[145]\tvalidation_0-mae:54533.3\n",
      "[146]\tvalidation_0-mae:54451.5\n",
      "[147]\tvalidation_0-mae:54099.5\n",
      "[148]\tvalidation_0-mae:53500.5\n",
      "[149]\tvalidation_0-mae:53217.6\n",
      "    fold  4:  [465790.25658627]\n",
      "[23:42:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18451e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88609e+06\n",
      "[2]\tvalidation_0-mae:1.62964e+06\n",
      "[3]\tvalidation_0-mae:1.40895e+06\n",
      "[4]\tvalidation_0-mae:1.21995e+06\n",
      "[5]\tvalidation_0-mae:1.0581e+06\n",
      "[6]\tvalidation_0-mae:919579\n",
      "[7]\tvalidation_0-mae:801418\n",
      "[8]\tvalidation_0-mae:700709\n",
      "[9]\tvalidation_0-mae:615752\n",
      "[10]\tvalidation_0-mae:544076\n",
      "[11]\tvalidation_0-mae:483801\n",
      "[12]\tvalidation_0-mae:432929\n",
      "[13]\tvalidation_0-mae:390369\n",
      "[14]\tvalidation_0-mae:355122\n",
      "[15]\tvalidation_0-mae:325730\n",
      "[16]\tvalidation_0-mae:301045\n",
      "[17]\tvalidation_0-mae:280519\n",
      "[18]\tvalidation_0-mae:261888\n",
      "[19]\tvalidation_0-mae:246843\n",
      "[20]\tvalidation_0-mae:234152\n",
      "[21]\tvalidation_0-mae:223246\n",
      "[22]\tvalidation_0-mae:214055\n",
      "[23]\tvalidation_0-mae:205229\n",
      "[24]\tvalidation_0-mae:197557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tvalidation_0-mae:190998\n",
      "[26]\tvalidation_0-mae:184913\n",
      "[27]\tvalidation_0-mae:178699\n",
      "[28]\tvalidation_0-mae:173216\n",
      "[29]\tvalidation_0-mae:168624\n",
      "[30]\tvalidation_0-mae:163949\n",
      "[31]\tvalidation_0-mae:159520\n",
      "[32]\tvalidation_0-mae:156560\n",
      "[33]\tvalidation_0-mae:153028\n",
      "[34]\tvalidation_0-mae:149929\n",
      "[35]\tvalidation_0-mae:146395\n",
      "[36]\tvalidation_0-mae:142764\n",
      "[37]\tvalidation_0-mae:139315\n",
      "[38]\tvalidation_0-mae:136272\n",
      "[39]\tvalidation_0-mae:134054\n",
      "[40]\tvalidation_0-mae:131876\n",
      "[41]\tvalidation_0-mae:129324\n",
      "[42]\tvalidation_0-mae:127006\n",
      "[43]\tvalidation_0-mae:123955\n",
      "[44]\tvalidation_0-mae:121778\n",
      "[45]\tvalidation_0-mae:119385\n",
      "[46]\tvalidation_0-mae:117864\n",
      "[47]\tvalidation_0-mae:115753\n",
      "[48]\tvalidation_0-mae:114156\n",
      "[49]\tvalidation_0-mae:111807\n",
      "[50]\tvalidation_0-mae:109703\n",
      "[51]\tvalidation_0-mae:108446\n",
      "[52]\tvalidation_0-mae:106437\n",
      "[53]\tvalidation_0-mae:105728\n",
      "[54]\tvalidation_0-mae:104895\n",
      "[55]\tvalidation_0-mae:103054\n",
      "[56]\tvalidation_0-mae:102015\n",
      "[57]\tvalidation_0-mae:100765\n",
      "[58]\tvalidation_0-mae:99561.5\n",
      "[59]\tvalidation_0-mae:98500.9\n",
      "[60]\tvalidation_0-mae:97649.2\n",
      "[61]\tvalidation_0-mae:96746.6\n",
      "[62]\tvalidation_0-mae:95444.5\n",
      "[63]\tvalidation_0-mae:94785.2\n",
      "[64]\tvalidation_0-mae:94037.8\n",
      "[65]\tvalidation_0-mae:93225.8\n",
      "[66]\tvalidation_0-mae:92519.3\n",
      "[67]\tvalidation_0-mae:91023.5\n",
      "[68]\tvalidation_0-mae:90800.7\n",
      "[69]\tvalidation_0-mae:89920.2\n",
      "[70]\tvalidation_0-mae:88605.8\n",
      "[71]\tvalidation_0-mae:87572\n",
      "[72]\tvalidation_0-mae:86365.4\n",
      "[73]\tvalidation_0-mae:85981.6\n",
      "[74]\tvalidation_0-mae:85257.4\n",
      "[75]\tvalidation_0-mae:84526.1\n",
      "[76]\tvalidation_0-mae:83612.7\n",
      "[77]\tvalidation_0-mae:82976.2\n",
      "[78]\tvalidation_0-mae:82316.3\n",
      "[79]\tvalidation_0-mae:81661.4\n",
      "[80]\tvalidation_0-mae:80628.2\n",
      "[81]\tvalidation_0-mae:80403.2\n",
      "[82]\tvalidation_0-mae:80305.6\n",
      "[83]\tvalidation_0-mae:79744.7\n",
      "[84]\tvalidation_0-mae:78356.3\n",
      "[85]\tvalidation_0-mae:78150.6\n",
      "[86]\tvalidation_0-mae:77963.1\n",
      "[87]\tvalidation_0-mae:77662.6\n",
      "[88]\tvalidation_0-mae:77092.8\n",
      "[89]\tvalidation_0-mae:76662.7\n",
      "[90]\tvalidation_0-mae:76155.7\n",
      "[91]\tvalidation_0-mae:76014.5\n",
      "[92]\tvalidation_0-mae:75046.9\n",
      "[93]\tvalidation_0-mae:74604.2\n",
      "[94]\tvalidation_0-mae:73796.7\n",
      "[95]\tvalidation_0-mae:73246.1\n",
      "[96]\tvalidation_0-mae:72851.5\n",
      "[97]\tvalidation_0-mae:72633.3\n",
      "[98]\tvalidation_0-mae:72165.7\n",
      "[99]\tvalidation_0-mae:72089.5\n",
      "[100]\tvalidation_0-mae:71946.9\n",
      "[101]\tvalidation_0-mae:71449.8\n",
      "[102]\tvalidation_0-mae:70936.5\n",
      "[103]\tvalidation_0-mae:70101.5\n",
      "[104]\tvalidation_0-mae:69064.3\n",
      "[105]\tvalidation_0-mae:68800.8\n",
      "[106]\tvalidation_0-mae:68625.3\n",
      "[107]\tvalidation_0-mae:68120.8\n",
      "[108]\tvalidation_0-mae:67484.1\n",
      "[109]\tvalidation_0-mae:67430.7\n",
      "[110]\tvalidation_0-mae:66832.5\n",
      "[111]\tvalidation_0-mae:66338.4\n",
      "[112]\tvalidation_0-mae:65808.1\n",
      "[113]\tvalidation_0-mae:65396.1\n",
      "[114]\tvalidation_0-mae:64903.2\n",
      "[115]\tvalidation_0-mae:64830.2\n",
      "[116]\tvalidation_0-mae:64560.7\n",
      "[117]\tvalidation_0-mae:64371.8\n",
      "[118]\tvalidation_0-mae:63543.2\n",
      "[119]\tvalidation_0-mae:63059.3\n",
      "[120]\tvalidation_0-mae:62241.1\n",
      "[121]\tvalidation_0-mae:61995.2\n",
      "[122]\tvalidation_0-mae:61529.2\n",
      "[123]\tvalidation_0-mae:61232.1\n",
      "[124]\tvalidation_0-mae:61132.3\n",
      "[125]\tvalidation_0-mae:60490.8\n",
      "[126]\tvalidation_0-mae:60448.2\n",
      "[127]\tvalidation_0-mae:60090.2\n",
      "[128]\tvalidation_0-mae:59716.4\n",
      "[129]\tvalidation_0-mae:59129.3\n",
      "[130]\tvalidation_0-mae:58917.4\n",
      "[131]\tvalidation_0-mae:58345.1\n",
      "[132]\tvalidation_0-mae:57890.4\n",
      "[133]\tvalidation_0-mae:57548.4\n",
      "[134]\tvalidation_0-mae:57311.2\n",
      "[135]\tvalidation_0-mae:56924.4\n",
      "[136]\tvalidation_0-mae:56545.5\n",
      "[137]\tvalidation_0-mae:56224.2\n",
      "[138]\tvalidation_0-mae:56108.1\n",
      "[139]\tvalidation_0-mae:55804\n",
      "[140]\tvalidation_0-mae:55705.3\n",
      "[141]\tvalidation_0-mae:55634.9\n",
      "[142]\tvalidation_0-mae:55437.6\n",
      "[143]\tvalidation_0-mae:54927.9\n",
      "[144]\tvalidation_0-mae:54885.8\n",
      "[145]\tvalidation_0-mae:54673.2\n",
      "[146]\tvalidation_0-mae:54545.4\n",
      "[147]\tvalidation_0-mae:54368.2\n",
      "[148]\tvalidation_0-mae:54181.5\n",
      "[149]\tvalidation_0-mae:53919.1\n",
      "    fold  5:  [469849.92305939]\n",
      "    ----\n",
      "    MEAN:     [467983.50937194] + [3991.68945793]\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [485440.84217078]\n",
      "    fold  1:  [489066.04084440]\n",
      "    fold  2:  [493586.22802802]\n",
      "    fold  3:  [490423.63996631]\n",
      "    fold  4:  [489895.60753327]\n",
      "    fold  5:  [490585.39862395]\n",
      "    ----\n",
      "    MEAN:     [489832.95952779] + [2411.25404185]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "\n",
    "features = ['antiguedad', 'habitaciones', 'garages', 'banos',\n",
    "       'metroscubiertos', 'metrostotales', \n",
    "            'lat', 'lng',\n",
    "       'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas', 'centroscomercialescercanos']\n",
    "\n",
    "features_test = ['prop_frecuente', 'top_provincia', 'porcentaje_metros', 'diferencia_metros', 'promedio_precio_ciudad', \n",
    "                 'promedio_por_mes', 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'promedio_precio_hbg_tipo_propiedad', 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                 'count_tipo_propiedad', 'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen', 'promedio_precio_hbg_tipo_propiedad_provincia',\n",
    "                 'varianza_id_zona', 'tam_ambientes', 'metros_cubiertos_normalizados', 'dias_desde_datos',\n",
    "                 'meses_desde_datos', 'promedio_id_zona_log']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "features += cols_tipodepropiedad_ohe + cols_provincia_ohe + cols_zona_ohe\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('xgboost', xgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('lightgbm', lgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2, n_folds=6)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_test_f = features_independientes_precio(df_test)\n",
    "df_test_f = features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features_independientes_precio(df_train)\n",
    "df_train_f = features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "\n",
    "df_train_f = columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "\n",
    "llenar_nulls(df_train_f)\n",
    "llenar_nulls(df_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.7740520226030885, bagging_freq=7,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.8422472893793045, importance_type='split',\n",
       "                learning_rate=0.1508386725397851, max_depth=12,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=110,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.7740520226030885,\n",
    " 'bagging_freq': int(7.0),\n",
    " 'feature_fraction': 0.8422472893793045,\n",
    " 'learning_rate': 0.1508386725397851,\n",
    " 'max_depth': int(12.0),\n",
    " 'num_leaves': int(110.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta20.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "MAE Stacking (train): 479214.56916\n",
      "MAE Stacking (test): 409282.55733\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
