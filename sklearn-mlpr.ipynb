{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ipynb.fs.full.features import features_independientes_precio, features_dependientes_precio\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(actual, pred):\n",
    "    return (np.mean((np.log(actual + 1) - np.log(pred + 1)) ** 2)) **.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llenar_nulls(df):\n",
    "    df['metrostotales'] = df['metrostotales'].fillna(df['metroscubiertos'])\n",
    "    df['metroscubiertos'] = df['metrostotales'].fillna(df['metrostotales'])\n",
    "    \n",
    "    df['habitaciones'] = df['habitaciones'].fillna(df['habitaciones'].mean())\n",
    "    df['garages'] = df['garages'].fillna(df['garages'].mean())\n",
    "    df['banos'] = df['banos'].fillna(df['banos'].mean())\n",
    "\n",
    "df_train_f = features_independientes_precio(df_train)\n",
    "df_train_f = features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f = features_independientes_precio(df_test)\n",
    "df_test_f = features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "llenar_nulls(df_train_f)\n",
    "llenar_nulls(df_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1394787890012.46240234\n",
      "Iteration 2, loss = 1042875947973.60559082\n",
      "Iteration 3, loss = 1043218417521.38354492\n",
      "Iteration 4, loss = 1043653177685.19995117\n",
      "Iteration 5, loss = 1044120924909.98864746\n",
      "Iteration 6, loss = 1044132027680.98254395\n",
      "Iteration 7, loss = 1045604746821.99597168\n",
      "Iteration 8, loss = 1044935254940.94201660\n",
      "Iteration 9, loss = 1043172127122.99963379\n",
      "Iteration 10, loss = 1043150523005.39855957\n",
      "Iteration 11, loss = 1041603234745.77294922\n",
      "Iteration 12, loss = 1042833573637.39331055\n",
      "Iteration 13, loss = 1042835949078.56176758\n",
      "Iteration 14, loss = 1043155947869.90747070\n",
      "Iteration 15, loss = 1043366285511.87841797\n",
      "Iteration 16, loss = 1043294644818.34509277\n",
      "Iteration 17, loss = 1041606988886.75573730\n",
      "Iteration 18, loss = 1042265198263.03088379\n",
      "Iteration 19, loss = 1042474952868.70849609\n",
      "Iteration 20, loss = 1043533114578.13525391\n",
      "Iteration 21, loss = 1042577328338.64892578\n",
      "Iteration 22, loss = 1041352084930.19775391\n",
      "Iteration 23, loss = 1042111037285.38598633\n",
      "Iteration 24, loss = 1041281221913.51635742\n",
      "Iteration 25, loss = 1041065273013.18737793\n",
      "Iteration 26, loss = 1039601880523.51147461\n",
      "Iteration 27, loss = 1040674749781.37329102\n",
      "Iteration 28, loss = 1039991206213.62390137\n",
      "Iteration 29, loss = 1038956325688.28601074\n",
      "Iteration 30, loss = 1039954087893.73852539\n",
      "Iteration 31, loss = 1039589640363.99304199\n",
      "Iteration 32, loss = 1040001948312.71386719\n",
      "Iteration 33, loss = 1038261507778.55895996\n",
      "Iteration 34, loss = 1037625953641.75903320\n",
      "Iteration 35, loss = 1038384778559.68237305\n",
      "Iteration 36, loss = 1040691856736.53356934\n",
      "Iteration 37, loss = 1038546270090.84167480\n",
      "Iteration 38, loss = 1036068597853.57336426\n",
      "Iteration 39, loss = 1038157070469.06933594\n",
      "Iteration 40, loss = 1036280855523.74462891\n",
      "Iteration 41, loss = 1035890364913.67773438\n",
      "Iteration 42, loss = 1034269065849.02392578\n",
      "Iteration 43, loss = 1036752036753.11755371\n",
      "Iteration 44, loss = 1035647529462.94079590\n",
      "Iteration 45, loss = 1035282366524.47045898\n",
      "Iteration 46, loss = 1033857135162.69458008\n",
      "Iteration 47, loss = 1033438668643.94262695\n",
      "Iteration 48, loss = 1030317690655.45349121\n",
      "Iteration 49, loss = 1030635147155.69897461\n",
      "Iteration 50, loss = 1029112487372.59143066\n",
      "Iteration 51, loss = 1027358987404.62316895\n",
      "Iteration 52, loss = 1026754793075.22155762\n",
      "Iteration 53, loss = 1025376082870.30432129\n",
      "Iteration 54, loss = 1021578127980.68041992\n",
      "Iteration 55, loss = 1016519053254.94445801\n",
      "Iteration 56, loss = 1014485879947.07226562\n",
      "Iteration 57, loss = 1005903126076.26025391\n",
      "Iteration 58, loss = 1000795138981.91101074\n",
      "Iteration 59, loss = 988355090458.38049316\n",
      "Iteration 60, loss = 971451603463.78637695\n",
      "Iteration 61, loss = 965453823097.36157227\n",
      "Iteration 62, loss = 949360517974.14831543\n",
      "Iteration 63, loss = 933581735625.02502441\n",
      "Iteration 64, loss = 926108885286.95214844\n",
      "Iteration 65, loss = 918608709759.60559082\n",
      "Iteration 66, loss = 917972255035.00000000\n",
      "Iteration 67, loss = 903837376923.99157715\n",
      "Iteration 68, loss = 904268190191.27844238\n",
      "Iteration 69, loss = 909746022310.87121582\n",
      "Iteration 70, loss = 900913356443.08264160\n",
      "Iteration 71, loss = 906025765338.77038574\n",
      "Iteration 72, loss = 901098326621.39111328\n",
      "Iteration 73, loss = 895761286266.32019043\n",
      "Iteration 74, loss = 887199810026.41503906\n",
      "Iteration 75, loss = 902223995672.79833984\n",
      "Iteration 76, loss = 898783029429.09814453\n",
      "Iteration 77, loss = 888686439685.17443848\n",
      "Iteration 78, loss = 880154902946.49548340\n",
      "Iteration 79, loss = 884835657576.18444824\n",
      "Iteration 80, loss = 892981561384.40307617\n",
      "Iteration 81, loss = 889852131502.21740723\n",
      "Iteration 82, loss = 880634637173.48803711\n",
      "Iteration 83, loss = 900724408517.14660645\n",
      "Iteration 84, loss = 882264739381.39709473\n",
      "Iteration 85, loss = 905350041213.35693359\n",
      "Iteration 86, loss = 880206028602.64501953\n",
      "Iteration 87, loss = 909643493697.08605957\n",
      "Iteration 88, loss = 880015295342.98937988\n",
      "Iteration 89, loss = 889162747010.04882812\n",
      "Iteration 90, loss = 878291707279.68054199\n",
      "Iteration 91, loss = 871034308989.51525879\n",
      "Iteration 92, loss = 884021661257.55297852\n",
      "Iteration 93, loss = 880474625725.49621582\n",
      "Iteration 94, loss = 883331118946.44067383\n",
      "Iteration 95, loss = 877552053319.50134277\n",
      "Iteration 96, loss = 874428863615.07568359\n",
      "Iteration 97, loss = 878706826310.52722168\n",
      "Iteration 98, loss = 878532118444.14685059\n",
      "Iteration 99, loss = 873409452526.25903320\n",
      "Iteration 100, loss = 876008273400.26354980\n",
      "Iteration 101, loss = 875164212945.17041016\n",
      "Iteration 102, loss = 885962185903.43066406\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "RMSLE MLPRegressor (train): 0.49458\n",
      "RMSLE MLPRegressor: 0.49645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "df_nn = df_train_f.copy().drop(['titulo', 'descripcion', 'tipodepropiedad', 'direccion', 'ciudad', 'provincia',\n",
    "                                'fecha', 'zona', 'intervalo_metros_totales', 'intervalo_metros_cubiertos', 'id', \n",
    "                               'antiguedad', 'idzona', 'lat', 'lng', 'porcentaje_metros',\n",
    "                               'promedio_metros_tipo_propiedad'], axis=1)\n",
    "\n",
    "df_nn = df_nn[['habitaciones', 'garages', 'banos', 'metroscubiertos', 'metrostotales',\n",
    "       'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas',\n",
    "       'centroscomercialescercanos', 'escomercial', 'promedio_precio_ciudad',\n",
    "       'promedio_id_zona', 'precio']]\n",
    "\n",
    "df_nn_test, df_nn_train = train_test_split(df_nn, test_size=0.25, random_state=1)\n",
    "\n",
    "y_test = df_nn_test['precio']\n",
    "y_train = df_nn_train['precio']\n",
    "x_test = df_nn_test.drop('precio', axis=1)\n",
    "x_train = df_nn_train.drop('precio', axis=1)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(30, 30, 30, 30, 30), verbose=True)\n",
    "mlp.fit(x_train,y_train)\n",
    "\n",
    "mlpr_rmsle_train = RMSLE(y_train, mlp.predict(x_train))\n",
    "mlpr_rmsle = RMSLE(y_test, mlp.predict(x_test))\n",
    "print(f\"RMSLE MLPRegressor (train): {mlpr_rmsle_train:.5f}\")\n",
    "print(f\"RMSLE MLPRegressor: {mlpr_rmsle:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
