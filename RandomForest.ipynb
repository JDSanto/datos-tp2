{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "import ipynb.fs.full.features_distancias as f_distancias\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('./data/train_filtrado.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_eval = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train, df_eval = features.features_de_csvs(df_train, df_eval)\n",
    "\n",
    "df_train_idf = pd.read_csv('./data/train_idf.csv')\n",
    "df_eval_idf = pd.read_csv('./data/test_idf.csv')\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_idf, on= 'id', how= 'left')\n",
    "df_eval = pd.merge(df_eval, df_eval_idf, on= 'id', how= 'left')\n",
    "\n",
    "df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.25)\n",
    "\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "df_train = features.llenar_nulls(df_train, hgb_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "# df_train_f = df_train_f.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_train_f = f_distancias.feature_distancias(df_train_f)\n",
    "df_test_f = f_distancias.feature_distancias(df_test_f, df_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 4, 8], 'n_estimators': [10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features = ['habitaciones', 'garages','banos','antiguedad', 'metroscubiertos',  'metrostotales','lat_norm', \n",
    "           'lng_norm', 'gimnasio', 'usosmultiples', 'piscina']\n",
    "\n",
    "features_test = ['top_provincia', 'promedio_precio_ciudad', 'anio', 'promedio_id_zona', \n",
    "                 'promedio_precio_tipo_propiedad', 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "               'count_tipo_propiedad_ciudad', 'promedio_precio_tipo_propiedad_ciudad_gen','count_id_zona'\n",
    "           'dias_desde_datos','meses_desde_datos','porcentaje_metros','distancia_ciudad_centrica', 'puntaje', 'distancia_centro_mexico']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "forest_params = { \n",
    "    \"n_estimators\": [10],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": [2,4,8],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=1)\n",
    "\n",
    "rs_cv = GridSearchCV(estimator=RandomForestRegressor(), \n",
    "                           param_grid=forest_params, \n",
    "                           cv=4, scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "rs_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 10}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rs_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE RandomForest (train): 58145.90947\n",
      "MAE RandomForest (eval): 506702.25115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "params = {'bootstrap': False,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_split': 4}\n",
    "\n",
    "forest = RandomForestRegressor(verbose=1, n_estimators=100, **params)\n",
    "\n",
    "features = ['habitaciones', 'garages','banos','antiguedad', 'metroscubiertos',  'metrostotales','lat_norm', \n",
    "           'lng_norm', 'gimnasio', 'usosmultiples', 'piscina']\n",
    "\n",
    "features_test = ['top_provincia', 'promedio_precio_ciudad', 'anio', 'promedio_id_zona', \n",
    "                 'promedio_precio_tipo_propiedad', 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "               'count_tipo_propiedad_ciudad', 'promedio_precio_tipo_propiedad_ciudad_gen','count_id_zona'\n",
    "           'dias_desde_datos','meses_desde_datos','porcentaje_metros','distancia_ciudad_centrica', \n",
    "                'distancia_centro_mexico', 'distancia_ciudad_cara']\n",
    "\n",
    "features += features_test\n",
    "\n",
    "x_train = utils.filtrar_features(df_train_f, features)\n",
    "y_train = df_train_f['precio']\n",
    "x_eval = utils.filtrar_features(df_test_f, features)\n",
    "y_eval = df_test_f['precio']\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = forest.predict(x_train)\n",
    "y_pred_eval = forest.predict(x_eval)\n",
    "\n",
    "mae_train = utils.MAE(y_train, y_pred_train)\n",
    "mae_eval = utils.MAE(y_eval, y_pred_eval)\n",
    "\n",
    "print(f\"MAE RandomForest (train): {mae_train:.5f}\")\n",
    "print(f\"MAE RandomForest (eval): {mae_eval:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
