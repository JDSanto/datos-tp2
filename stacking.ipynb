{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.08363501292068126)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8999882607358867,\n",
    " 'bagging_freq': 95.0,\n",
    " 'feature_fraction': 0.2570109385381975,\n",
    " 'learning_rate': 0.13601832720254403,\n",
    " 'max_depth': 26.0,\n",
    " 'num_leaves': 175.0,\n",
    " 'test_size': 0.08363501292068126}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 4}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [513908.86251132]\n",
      "    fold  1:  [519487.44676944]\n",
      "    fold  2:  [517465.89578313]\n",
      "    fold  3:  [517615.34308838]\n",
      "    ----\n",
      "    MEAN:     [517119.38703807] + [2017.49940164]\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "[22:55:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18901e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.89059e+06\n",
      "[2]\tvalidation_0-mae:1.63412e+06\n",
      "[3]\tvalidation_0-mae:1.41386e+06\n",
      "[4]\tvalidation_0-mae:1.22503e+06\n",
      "[5]\tvalidation_0-mae:1.06324e+06\n",
      "[6]\tvalidation_0-mae:924910\n",
      "[7]\tvalidation_0-mae:806933\n",
      "[8]\tvalidation_0-mae:706275\n",
      "[9]\tvalidation_0-mae:621479\n",
      "[10]\tvalidation_0-mae:550127\n",
      "[11]\tvalidation_0-mae:489707\n",
      "[12]\tvalidation_0-mae:438620\n",
      "[13]\tvalidation_0-mae:396915\n",
      "[14]\tvalidation_0-mae:361730\n",
      "[15]\tvalidation_0-mae:333319\n",
      "[16]\tvalidation_0-mae:307485\n",
      "[17]\tvalidation_0-mae:286673\n",
      "[18]\tvalidation_0-mae:268407\n",
      "[19]\tvalidation_0-mae:253633\n",
      "[20]\tvalidation_0-mae:240332\n",
      "[21]\tvalidation_0-mae:229361\n",
      "[22]\tvalidation_0-mae:219917\n",
      "[23]\tvalidation_0-mae:210105\n",
      "[24]\tvalidation_0-mae:202547\n",
      "[25]\tvalidation_0-mae:195765\n",
      "[26]\tvalidation_0-mae:188487\n",
      "[27]\tvalidation_0-mae:182092\n",
      "[28]\tvalidation_0-mae:176394\n",
      "[29]\tvalidation_0-mae:171556\n",
      "[30]\tvalidation_0-mae:167025\n",
      "[31]\tvalidation_0-mae:163398\n",
      "[32]\tvalidation_0-mae:159946\n",
      "[33]\tvalidation_0-mae:157044\n",
      "[34]\tvalidation_0-mae:154058\n",
      "[35]\tvalidation_0-mae:151011\n",
      "[36]\tvalidation_0-mae:147765\n",
      "[37]\tvalidation_0-mae:143865\n",
      "[38]\tvalidation_0-mae:141010\n",
      "[39]\tvalidation_0-mae:137532\n",
      "[40]\tvalidation_0-mae:134424\n",
      "[41]\tvalidation_0-mae:131465\n",
      "[42]\tvalidation_0-mae:130147\n",
      "[43]\tvalidation_0-mae:127634\n",
      "[44]\tvalidation_0-mae:125213\n",
      "[45]\tvalidation_0-mae:122795\n",
      "[46]\tvalidation_0-mae:120230\n",
      "[47]\tvalidation_0-mae:118517\n",
      "[48]\tvalidation_0-mae:116458\n",
      "[49]\tvalidation_0-mae:114757\n",
      "[50]\tvalidation_0-mae:113267\n",
      "[51]\tvalidation_0-mae:111980\n",
      "[52]\tvalidation_0-mae:110620\n",
      "[53]\tvalidation_0-mae:108946\n",
      "[54]\tvalidation_0-mae:107968\n",
      "[55]\tvalidation_0-mae:105797\n",
      "[56]\tvalidation_0-mae:104353\n",
      "[57]\tvalidation_0-mae:103392\n",
      "[58]\tvalidation_0-mae:102035\n",
      "[59]\tvalidation_0-mae:100773\n",
      "[60]\tvalidation_0-mae:99888.4\n",
      "[61]\tvalidation_0-mae:98424.2\n",
      "[62]\tvalidation_0-mae:97047.5\n",
      "[63]\tvalidation_0-mae:95659\n",
      "[64]\tvalidation_0-mae:94678.2\n",
      "[65]\tvalidation_0-mae:93986.7\n",
      "[66]\tvalidation_0-mae:93168.9\n",
      "[67]\tvalidation_0-mae:91822.2\n",
      "[68]\tvalidation_0-mae:91512.8\n",
      "[69]\tvalidation_0-mae:90340.8\n",
      "[70]\tvalidation_0-mae:89462.8\n",
      "[71]\tvalidation_0-mae:89316.9\n",
      "[72]\tvalidation_0-mae:88614.6\n",
      "[73]\tvalidation_0-mae:87681.6\n",
      "[74]\tvalidation_0-mae:86980.3\n",
      "[75]\tvalidation_0-mae:86538.2\n",
      "[76]\tvalidation_0-mae:86152\n",
      "[77]\tvalidation_0-mae:85780.1\n",
      "[78]\tvalidation_0-mae:85429.6\n",
      "[79]\tvalidation_0-mae:84413.3\n",
      "[80]\tvalidation_0-mae:83828.6\n",
      "[81]\tvalidation_0-mae:83403.8\n",
      "[82]\tvalidation_0-mae:83142.6\n",
      "[83]\tvalidation_0-mae:82804.2\n",
      "[84]\tvalidation_0-mae:82199.4\n",
      "[85]\tvalidation_0-mae:81589.8\n",
      "[86]\tvalidation_0-mae:81208.3\n",
      "[87]\tvalidation_0-mae:80881.1\n",
      "[88]\tvalidation_0-mae:80530.8\n",
      "[89]\tvalidation_0-mae:80013.7\n",
      "[90]\tvalidation_0-mae:79161.5\n",
      "[91]\tvalidation_0-mae:78678\n",
      "[92]\tvalidation_0-mae:78549.3\n",
      "[93]\tvalidation_0-mae:78407.6\n",
      "[94]\tvalidation_0-mae:78236.6\n",
      "[95]\tvalidation_0-mae:77507.7\n",
      "[96]\tvalidation_0-mae:77243.2\n",
      "[97]\tvalidation_0-mae:77014.1\n",
      "[98]\tvalidation_0-mae:76836.7\n",
      "[99]\tvalidation_0-mae:76305\n",
      "[100]\tvalidation_0-mae:76046.3\n",
      "[101]\tvalidation_0-mae:75831.4\n",
      "[102]\tvalidation_0-mae:75754.6\n",
      "[103]\tvalidation_0-mae:74474.5\n",
      "[104]\tvalidation_0-mae:73697.2\n",
      "[105]\tvalidation_0-mae:73152.6\n",
      "[106]\tvalidation_0-mae:72156.9\n",
      "[107]\tvalidation_0-mae:72037.6\n",
      "[108]\tvalidation_0-mae:71190.7\n",
      "[109]\tvalidation_0-mae:70740.8\n",
      "[110]\tvalidation_0-mae:70444.5\n",
      "[111]\tvalidation_0-mae:70199.7\n",
      "[112]\tvalidation_0-mae:69878.5\n",
      "[113]\tvalidation_0-mae:69555.1\n",
      "[114]\tvalidation_0-mae:69063.9\n",
      "[115]\tvalidation_0-mae:68651.8\n",
      "[116]\tvalidation_0-mae:67636.3\n",
      "[117]\tvalidation_0-mae:66921.6\n",
      "[118]\tvalidation_0-mae:66723.4\n",
      "[119]\tvalidation_0-mae:66215.9\n",
      "[120]\tvalidation_0-mae:65610.3\n",
      "[121]\tvalidation_0-mae:65152.4\n",
      "[122]\tvalidation_0-mae:64770.3\n",
      "[123]\tvalidation_0-mae:64674.8\n",
      "[124]\tvalidation_0-mae:64612.7\n",
      "[125]\tvalidation_0-mae:64523.5\n",
      "[126]\tvalidation_0-mae:64263.3\n",
      "[127]\tvalidation_0-mae:63953.2\n",
      "[128]\tvalidation_0-mae:63731.4\n",
      "[129]\tvalidation_0-mae:63414.3\n",
      "[130]\tvalidation_0-mae:63115\n",
      "[131]\tvalidation_0-mae:62836.5\n",
      "[132]\tvalidation_0-mae:62330.4\n",
      "[133]\tvalidation_0-mae:62251.2\n",
      "[134]\tvalidation_0-mae:61583.3\n",
      "[135]\tvalidation_0-mae:61332.1\n",
      "[136]\tvalidation_0-mae:61197.6\n",
      "[137]\tvalidation_0-mae:60952.7\n",
      "[138]\tvalidation_0-mae:60457.7\n",
      "[139]\tvalidation_0-mae:60162.4\n",
      "[140]\tvalidation_0-mae:59428.3\n",
      "[141]\tvalidation_0-mae:59357.6\n",
      "[142]\tvalidation_0-mae:58870.6\n",
      "[143]\tvalidation_0-mae:58408.1\n",
      "[144]\tvalidation_0-mae:58170.4\n",
      "[145]\tvalidation_0-mae:58036.5\n",
      "[146]\tvalidation_0-mae:57789.4\n",
      "[147]\tvalidation_0-mae:57727.1\n",
      "[148]\tvalidation_0-mae:57304.3\n",
      "[149]\tvalidation_0-mae:57067.9\n",
      "    fold  0:  [486109.84349975]\n",
      "[22:57:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18115e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88397e+06\n",
      "[2]\tvalidation_0-mae:1.6283e+06\n",
      "[3]\tvalidation_0-mae:1.40875e+06\n",
      "[4]\tvalidation_0-mae:1.22064e+06\n",
      "[5]\tvalidation_0-mae:1.05923e+06\n",
      "[6]\tvalidation_0-mae:921632\n",
      "[7]\tvalidation_0-mae:804164\n",
      "[8]\tvalidation_0-mae:703813\n",
      "[9]\tvalidation_0-mae:619086\n",
      "[10]\tvalidation_0-mae:548159\n",
      "[11]\tvalidation_0-mae:487693\n",
      "[12]\tvalidation_0-mae:436715\n",
      "[13]\tvalidation_0-mae:395101\n",
      "[14]\tvalidation_0-mae:360097\n",
      "[15]\tvalidation_0-mae:331704\n",
      "[16]\tvalidation_0-mae:305983\n",
      "[17]\tvalidation_0-mae:284428\n",
      "[18]\tvalidation_0-mae:266495\n",
      "[19]\tvalidation_0-mae:251262\n",
      "[20]\tvalidation_0-mae:238337\n",
      "[21]\tvalidation_0-mae:227070\n",
      "[22]\tvalidation_0-mae:217341\n",
      "[23]\tvalidation_0-mae:206943\n",
      "[24]\tvalidation_0-mae:199456\n",
      "[25]\tvalidation_0-mae:193039\n",
      "[26]\tvalidation_0-mae:185899\n",
      "[27]\tvalidation_0-mae:179751\n",
      "[28]\tvalidation_0-mae:173707\n",
      "[29]\tvalidation_0-mae:168907\n",
      "[30]\tvalidation_0-mae:164308\n",
      "[31]\tvalidation_0-mae:160076\n",
      "[32]\tvalidation_0-mae:156146\n",
      "[33]\tvalidation_0-mae:152976\n",
      "[34]\tvalidation_0-mae:149338\n",
      "[35]\tvalidation_0-mae:146563\n",
      "[36]\tvalidation_0-mae:143220\n",
      "[37]\tvalidation_0-mae:139596\n",
      "[38]\tvalidation_0-mae:137525\n",
      "[39]\tvalidation_0-mae:134062\n",
      "[40]\tvalidation_0-mae:131158\n",
      "[41]\tvalidation_0-mae:128448\n",
      "[42]\tvalidation_0-mae:126789\n",
      "[43]\tvalidation_0-mae:124208\n",
      "[44]\tvalidation_0-mae:122127\n",
      "[45]\tvalidation_0-mae:119971\n",
      "[46]\tvalidation_0-mae:118086\n",
      "[47]\tvalidation_0-mae:116133\n",
      "[48]\tvalidation_0-mae:113832\n",
      "[49]\tvalidation_0-mae:112258\n",
      "[50]\tvalidation_0-mae:110508\n",
      "[51]\tvalidation_0-mae:109350\n",
      "[52]\tvalidation_0-mae:108244\n",
      "[53]\tvalidation_0-mae:106741\n",
      "[54]\tvalidation_0-mae:106053\n",
      "[55]\tvalidation_0-mae:104980\n",
      "[56]\tvalidation_0-mae:103200\n",
      "[57]\tvalidation_0-mae:101522\n",
      "[58]\tvalidation_0-mae:101061\n",
      "[59]\tvalidation_0-mae:99909.7\n",
      "[60]\tvalidation_0-mae:98698.4\n",
      "[61]\tvalidation_0-mae:97551.8\n",
      "[62]\tvalidation_0-mae:96822.8\n",
      "[63]\tvalidation_0-mae:95484.1\n",
      "[64]\tvalidation_0-mae:94346.8\n",
      "[65]\tvalidation_0-mae:94018.8\n",
      "[66]\tvalidation_0-mae:93392.3\n",
      "[67]\tvalidation_0-mae:92377.4\n",
      "[68]\tvalidation_0-mae:92114.8\n",
      "[69]\tvalidation_0-mae:90935.9\n",
      "[70]\tvalidation_0-mae:90556.7\n",
      "[71]\tvalidation_0-mae:89773.5\n",
      "[72]\tvalidation_0-mae:89213.9\n",
      "[73]\tvalidation_0-mae:88810.9\n",
      "[74]\tvalidation_0-mae:87984.9\n",
      "[75]\tvalidation_0-mae:87458.9\n",
      "[76]\tvalidation_0-mae:86529.6\n",
      "[77]\tvalidation_0-mae:85892.4\n",
      "[78]\tvalidation_0-mae:85393.4\n",
      "[79]\tvalidation_0-mae:84811.1\n",
      "[80]\tvalidation_0-mae:84536.5\n",
      "[81]\tvalidation_0-mae:83878.6\n",
      "[82]\tvalidation_0-mae:83734.2\n",
      "[83]\tvalidation_0-mae:83449.9\n",
      "[84]\tvalidation_0-mae:83154.9\n",
      "[85]\tvalidation_0-mae:82637.6\n",
      "[86]\tvalidation_0-mae:82339\n",
      "[87]\tvalidation_0-mae:81716\n",
      "[88]\tvalidation_0-mae:81501.3\n",
      "[89]\tvalidation_0-mae:80282.9\n",
      "[90]\tvalidation_0-mae:79749.4\n",
      "[91]\tvalidation_0-mae:79462.1\n",
      "[92]\tvalidation_0-mae:78660.6\n",
      "[93]\tvalidation_0-mae:78065.4\n",
      "[94]\tvalidation_0-mae:77504.2\n",
      "[95]\tvalidation_0-mae:77141.5\n",
      "[96]\tvalidation_0-mae:76624.1\n",
      "[97]\tvalidation_0-mae:76183.6\n",
      "[98]\tvalidation_0-mae:75671.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99]\tvalidation_0-mae:75337.4\n",
      "[100]\tvalidation_0-mae:75180.4\n",
      "[101]\tvalidation_0-mae:74730.3\n",
      "[102]\tvalidation_0-mae:74513.2\n",
      "[103]\tvalidation_0-mae:74167.4\n",
      "[104]\tvalidation_0-mae:73517.2\n",
      "[105]\tvalidation_0-mae:73241.7\n",
      "[106]\tvalidation_0-mae:72629\n",
      "[107]\tvalidation_0-mae:72035\n",
      "[108]\tvalidation_0-mae:71428.2\n",
      "[109]\tvalidation_0-mae:70881.5\n",
      "[110]\tvalidation_0-mae:70263.9\n",
      "[111]\tvalidation_0-mae:69941.3\n",
      "[112]\tvalidation_0-mae:69759.3\n",
      "[113]\tvalidation_0-mae:69373.7\n",
      "[114]\tvalidation_0-mae:68952.5\n",
      "[115]\tvalidation_0-mae:68465.1\n",
      "[116]\tvalidation_0-mae:68303.2\n",
      "[117]\tvalidation_0-mae:68006.8\n",
      "[118]\tvalidation_0-mae:67624.8\n",
      "[119]\tvalidation_0-mae:67079.4\n",
      "[120]\tvalidation_0-mae:66610.5\n",
      "[121]\tvalidation_0-mae:66486.9\n",
      "[122]\tvalidation_0-mae:66221.9\n",
      "[123]\tvalidation_0-mae:65667.9\n",
      "[124]\tvalidation_0-mae:65594.9\n",
      "[125]\tvalidation_0-mae:65223.7\n",
      "[126]\tvalidation_0-mae:64739.5\n",
      "[127]\tvalidation_0-mae:64352.1\n",
      "[128]\tvalidation_0-mae:64154.4\n",
      "[129]\tvalidation_0-mae:63418\n",
      "[130]\tvalidation_0-mae:63221.8\n",
      "[131]\tvalidation_0-mae:62909.3\n",
      "[132]\tvalidation_0-mae:62708.7\n",
      "[133]\tvalidation_0-mae:61983.4\n",
      "[134]\tvalidation_0-mae:61685.1\n",
      "[135]\tvalidation_0-mae:61461.8\n",
      "[136]\tvalidation_0-mae:61294.5\n",
      "[137]\tvalidation_0-mae:60915.5\n",
      "[138]\tvalidation_0-mae:60577.3\n",
      "[139]\tvalidation_0-mae:60249\n",
      "[140]\tvalidation_0-mae:59768.1\n",
      "[141]\tvalidation_0-mae:59065.7\n",
      "[142]\tvalidation_0-mae:58596.7\n",
      "[143]\tvalidation_0-mae:58227.3\n",
      "[144]\tvalidation_0-mae:57964.2\n",
      "[145]\tvalidation_0-mae:57602.8\n",
      "[146]\tvalidation_0-mae:57332.8\n",
      "[147]\tvalidation_0-mae:56690.3\n",
      "[148]\tvalidation_0-mae:56562.5\n",
      "[149]\tvalidation_0-mae:56278.8\n",
      "    fold  1:  [497930.69818308]\n",
      "[22:58:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18256e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88521e+06\n",
      "[2]\tvalidation_0-mae:1.62962e+06\n",
      "[3]\tvalidation_0-mae:1.41033e+06\n",
      "[4]\tvalidation_0-mae:1.22218e+06\n",
      "[5]\tvalidation_0-mae:1.06054e+06\n",
      "[6]\tvalidation_0-mae:922606\n",
      "[7]\tvalidation_0-mae:804878\n",
      "[8]\tvalidation_0-mae:704509\n",
      "[9]\tvalidation_0-mae:619860\n",
      "[10]\tvalidation_0-mae:548802\n",
      "[11]\tvalidation_0-mae:488427\n",
      "[12]\tvalidation_0-mae:437247\n",
      "[13]\tvalidation_0-mae:395703\n",
      "[14]\tvalidation_0-mae:361046\n",
      "[15]\tvalidation_0-mae:332658\n",
      "[16]\tvalidation_0-mae:307123\n",
      "[17]\tvalidation_0-mae:286304\n",
      "[18]\tvalidation_0-mae:268575\n",
      "[19]\tvalidation_0-mae:253879\n",
      "[20]\tvalidation_0-mae:240550\n",
      "[21]\tvalidation_0-mae:229691\n",
      "[22]\tvalidation_0-mae:219965\n",
      "[23]\tvalidation_0-mae:210647\n",
      "[24]\tvalidation_0-mae:203130\n",
      "[25]\tvalidation_0-mae:196538\n",
      "[26]\tvalidation_0-mae:189611\n",
      "[27]\tvalidation_0-mae:183792\n",
      "[28]\tvalidation_0-mae:178190\n",
      "[29]\tvalidation_0-mae:173727\n",
      "[30]\tvalidation_0-mae:169407\n",
      "[31]\tvalidation_0-mae:165615\n",
      "[32]\tvalidation_0-mae:161568\n",
      "[33]\tvalidation_0-mae:158277\n",
      "[34]\tvalidation_0-mae:155088\n",
      "[35]\tvalidation_0-mae:152049\n",
      "[36]\tvalidation_0-mae:148015\n",
      "[37]\tvalidation_0-mae:143747\n",
      "[38]\tvalidation_0-mae:141466\n",
      "[39]\tvalidation_0-mae:137772\n",
      "[40]\tvalidation_0-mae:134465\n",
      "[41]\tvalidation_0-mae:131271\n",
      "[42]\tvalidation_0-mae:129504\n",
      "[43]\tvalidation_0-mae:126878\n",
      "[44]\tvalidation_0-mae:124805\n",
      "[45]\tvalidation_0-mae:122610\n",
      "[46]\tvalidation_0-mae:120601\n",
      "[47]\tvalidation_0-mae:118426\n",
      "[48]\tvalidation_0-mae:116204\n",
      "[49]\tvalidation_0-mae:115000\n",
      "[50]\tvalidation_0-mae:113654\n",
      "[51]\tvalidation_0-mae:112120\n",
      "[52]\tvalidation_0-mae:110896\n",
      "[53]\tvalidation_0-mae:109151\n",
      "[54]\tvalidation_0-mae:108360\n",
      "[55]\tvalidation_0-mae:107642\n",
      "[56]\tvalidation_0-mae:106181\n",
      "[57]\tvalidation_0-mae:104649\n",
      "[58]\tvalidation_0-mae:104022\n",
      "[59]\tvalidation_0-mae:102885\n",
      "[60]\tvalidation_0-mae:102019\n",
      "[61]\tvalidation_0-mae:100468\n",
      "[62]\tvalidation_0-mae:99080.3\n",
      "[63]\tvalidation_0-mae:97608.9\n",
      "[64]\tvalidation_0-mae:96539.5\n",
      "[65]\tvalidation_0-mae:95872.4\n",
      "[66]\tvalidation_0-mae:94761.1\n",
      "[67]\tvalidation_0-mae:94517.4\n",
      "[68]\tvalidation_0-mae:93985.8\n",
      "[69]\tvalidation_0-mae:92612.1\n",
      "[70]\tvalidation_0-mae:92260.8\n",
      "[71]\tvalidation_0-mae:91284.7\n",
      "[72]\tvalidation_0-mae:90604.8\n",
      "[73]\tvalidation_0-mae:90128.4\n",
      "[74]\tvalidation_0-mae:89460.4\n",
      "[75]\tvalidation_0-mae:88942.7\n",
      "[76]\tvalidation_0-mae:88617.8\n",
      "[77]\tvalidation_0-mae:88179.6\n",
      "[78]\tvalidation_0-mae:87441.2\n",
      "[79]\tvalidation_0-mae:86759.8\n",
      "[80]\tvalidation_0-mae:85965.1\n",
      "[81]\tvalidation_0-mae:85813\n",
      "[82]\tvalidation_0-mae:85260.9\n",
      "[83]\tvalidation_0-mae:84691.5\n",
      "[84]\tvalidation_0-mae:84184.9\n",
      "[85]\tvalidation_0-mae:83941.7\n",
      "[86]\tvalidation_0-mae:83513.7\n",
      "[87]\tvalidation_0-mae:83298\n",
      "[88]\tvalidation_0-mae:82656.2\n",
      "[89]\tvalidation_0-mae:82377.5\n",
      "[90]\tvalidation_0-mae:81740.7\n",
      "[91]\tvalidation_0-mae:81412.4\n",
      "[92]\tvalidation_0-mae:81251.2\n",
      "[93]\tvalidation_0-mae:81098.9\n",
      "[94]\tvalidation_0-mae:80585\n",
      "[95]\tvalidation_0-mae:79911.3\n",
      "[96]\tvalidation_0-mae:79245.1\n",
      "[97]\tvalidation_0-mae:78894.9\n",
      "[98]\tvalidation_0-mae:78298.2\n",
      "[99]\tvalidation_0-mae:78086.6\n",
      "[100]\tvalidation_0-mae:77918.7\n",
      "[101]\tvalidation_0-mae:77037.2\n",
      "[102]\tvalidation_0-mae:76213.3\n",
      "[103]\tvalidation_0-mae:74583.9\n",
      "[104]\tvalidation_0-mae:73714.4\n",
      "[105]\tvalidation_0-mae:73133.7\n",
      "[106]\tvalidation_0-mae:72236.8\n",
      "[107]\tvalidation_0-mae:71671.5\n",
      "[108]\tvalidation_0-mae:70982.7\n",
      "[109]\tvalidation_0-mae:70795\n",
      "[110]\tvalidation_0-mae:70572.4\n",
      "[111]\tvalidation_0-mae:69605.6\n",
      "[112]\tvalidation_0-mae:69362.7\n",
      "[113]\tvalidation_0-mae:69272.1\n",
      "[114]\tvalidation_0-mae:68987.4\n",
      "[115]\tvalidation_0-mae:68700.3\n",
      "[116]\tvalidation_0-mae:67994\n",
      "[117]\tvalidation_0-mae:67867.5\n",
      "[118]\tvalidation_0-mae:67377.3\n",
      "[119]\tvalidation_0-mae:67086.4\n",
      "[120]\tvalidation_0-mae:66969.4\n",
      "[121]\tvalidation_0-mae:66591\n",
      "[122]\tvalidation_0-mae:66170.8\n",
      "[123]\tvalidation_0-mae:66088.8\n",
      "[124]\tvalidation_0-mae:65958.2\n",
      "[125]\tvalidation_0-mae:65557.5\n",
      "[126]\tvalidation_0-mae:65171.8\n",
      "[127]\tvalidation_0-mae:64582.6\n",
      "[128]\tvalidation_0-mae:64212.5\n",
      "[129]\tvalidation_0-mae:63350.9\n",
      "[130]\tvalidation_0-mae:62977.8\n",
      "[131]\tvalidation_0-mae:62450.9\n",
      "[132]\tvalidation_0-mae:62080.1\n",
      "[133]\tvalidation_0-mae:61591.4\n",
      "[134]\tvalidation_0-mae:61321.3\n",
      "[135]\tvalidation_0-mae:61256.2\n",
      "[136]\tvalidation_0-mae:60929.3\n",
      "[137]\tvalidation_0-mae:60406.6\n",
      "[138]\tvalidation_0-mae:60288.7\n",
      "[139]\tvalidation_0-mae:59751.4\n",
      "[140]\tvalidation_0-mae:59179.8\n",
      "[141]\tvalidation_0-mae:59084.9\n",
      "[142]\tvalidation_0-mae:58557\n",
      "[143]\tvalidation_0-mae:58468.7\n",
      "[144]\tvalidation_0-mae:58111.9\n",
      "[145]\tvalidation_0-mae:57738.2\n",
      "[146]\tvalidation_0-mae:57531.4\n",
      "[147]\tvalidation_0-mae:57055\n",
      "[148]\tvalidation_0-mae:56629.8\n",
      "[149]\tvalidation_0-mae:56338.5\n",
      "    fold  2:  [490185.82285671]\n",
      "[22:59:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18252e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88503e+06\n",
      "[2]\tvalidation_0-mae:1.6293e+06\n",
      "[3]\tvalidation_0-mae:1.40981e+06\n",
      "[4]\tvalidation_0-mae:1.22175e+06\n",
      "[5]\tvalidation_0-mae:1.06038e+06\n",
      "[6]\tvalidation_0-mae:922512\n",
      "[7]\tvalidation_0-mae:804804\n",
      "[8]\tvalidation_0-mae:704580\n",
      "[9]\tvalidation_0-mae:619902\n",
      "[10]\tvalidation_0-mae:548891\n",
      "[11]\tvalidation_0-mae:488434\n",
      "[12]\tvalidation_0-mae:437301\n",
      "[13]\tvalidation_0-mae:395327\n",
      "[14]\tvalidation_0-mae:360002\n",
      "[15]\tvalidation_0-mae:331402\n",
      "[16]\tvalidation_0-mae:305738\n",
      "[17]\tvalidation_0-mae:284741\n",
      "[18]\tvalidation_0-mae:266355\n",
      "[19]\tvalidation_0-mae:251199\n",
      "[20]\tvalidation_0-mae:238011\n",
      "[21]\tvalidation_0-mae:227281\n",
      "[22]\tvalidation_0-mae:217068\n",
      "[23]\tvalidation_0-mae:206883\n",
      "[24]\tvalidation_0-mae:199436\n",
      "[25]\tvalidation_0-mae:192699\n",
      "[26]\tvalidation_0-mae:185459\n",
      "[27]\tvalidation_0-mae:179744\n",
      "[28]\tvalidation_0-mae:173606\n",
      "[29]\tvalidation_0-mae:169122\n",
      "[30]\tvalidation_0-mae:164898\n",
      "[31]\tvalidation_0-mae:161203\n",
      "[32]\tvalidation_0-mae:156940\n",
      "[33]\tvalidation_0-mae:153766\n",
      "[34]\tvalidation_0-mae:150861\n",
      "[35]\tvalidation_0-mae:148263\n",
      "[36]\tvalidation_0-mae:144348\n",
      "[37]\tvalidation_0-mae:140902\n",
      "[38]\tvalidation_0-mae:138537\n",
      "[39]\tvalidation_0-mae:135421\n",
      "[40]\tvalidation_0-mae:132298\n",
      "[41]\tvalidation_0-mae:129420\n",
      "[42]\tvalidation_0-mae:127989\n",
      "[43]\tvalidation_0-mae:125085\n",
      "[44]\tvalidation_0-mae:122206\n",
      "[45]\tvalidation_0-mae:119981\n",
      "[46]\tvalidation_0-mae:118505\n",
      "[47]\tvalidation_0-mae:116769\n",
      "[48]\tvalidation_0-mae:114450\n",
      "[49]\tvalidation_0-mae:112854\n",
      "[50]\tvalidation_0-mae:111347\n",
      "[51]\tvalidation_0-mae:109736\n",
      "[52]\tvalidation_0-mae:108186\n",
      "[53]\tvalidation_0-mae:106843\n",
      "[54]\tvalidation_0-mae:106290\n",
      "[55]\tvalidation_0-mae:104069\n",
      "[56]\tvalidation_0-mae:102971\n",
      "[57]\tvalidation_0-mae:101973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58]\tvalidation_0-mae:100951\n",
      "[59]\tvalidation_0-mae:100065\n",
      "[60]\tvalidation_0-mae:99362.9\n",
      "[61]\tvalidation_0-mae:97946.9\n",
      "[62]\tvalidation_0-mae:96594.4\n",
      "[63]\tvalidation_0-mae:95459.5\n",
      "[64]\tvalidation_0-mae:94388.5\n",
      "[65]\tvalidation_0-mae:94123.4\n",
      "[66]\tvalidation_0-mae:93565.9\n",
      "[67]\tvalidation_0-mae:93131.4\n",
      "[68]\tvalidation_0-mae:92680.9\n",
      "[69]\tvalidation_0-mae:92221.8\n",
      "[70]\tvalidation_0-mae:92052\n",
      "[71]\tvalidation_0-mae:91064.4\n",
      "[72]\tvalidation_0-mae:90213.9\n",
      "[73]\tvalidation_0-mae:88446.2\n",
      "[74]\tvalidation_0-mae:87709.7\n",
      "[75]\tvalidation_0-mae:86658.2\n",
      "[76]\tvalidation_0-mae:86005.7\n",
      "[77]\tvalidation_0-mae:85215.4\n",
      "[78]\tvalidation_0-mae:84740\n",
      "[79]\tvalidation_0-mae:84204.9\n",
      "[80]\tvalidation_0-mae:83831.8\n",
      "[81]\tvalidation_0-mae:83637.6\n",
      "[82]\tvalidation_0-mae:83479.4\n",
      "[83]\tvalidation_0-mae:82583.8\n",
      "[84]\tvalidation_0-mae:82210.9\n",
      "[85]\tvalidation_0-mae:82110.2\n",
      "[86]\tvalidation_0-mae:81526.7\n",
      "[87]\tvalidation_0-mae:80758.3\n",
      "[88]\tvalidation_0-mae:79754\n",
      "[89]\tvalidation_0-mae:79422.4\n",
      "[90]\tvalidation_0-mae:78984.6\n",
      "[91]\tvalidation_0-mae:78713.7\n",
      "[92]\tvalidation_0-mae:78081.5\n",
      "[93]\tvalidation_0-mae:77449\n",
      "[94]\tvalidation_0-mae:77253.2\n",
      "[95]\tvalidation_0-mae:76662.4\n",
      "[96]\tvalidation_0-mae:76412.5\n",
      "[97]\tvalidation_0-mae:75593\n",
      "[98]\tvalidation_0-mae:75471\n",
      "[99]\tvalidation_0-mae:75306.4\n",
      "[100]\tvalidation_0-mae:75050.6\n",
      "[101]\tvalidation_0-mae:74636.4\n",
      "[102]\tvalidation_0-mae:74230.7\n",
      "[103]\tvalidation_0-mae:72831.9\n",
      "[104]\tvalidation_0-mae:72327.7\n",
      "[105]\tvalidation_0-mae:71878.1\n",
      "[106]\tvalidation_0-mae:71261.8\n",
      "[107]\tvalidation_0-mae:70861.2\n",
      "[108]\tvalidation_0-mae:70771.3\n",
      "[109]\tvalidation_0-mae:70353.8\n",
      "[110]\tvalidation_0-mae:69722\n",
      "[111]\tvalidation_0-mae:69569.3\n",
      "[112]\tvalidation_0-mae:68935.2\n",
      "[113]\tvalidation_0-mae:68500.3\n",
      "[114]\tvalidation_0-mae:68336.6\n",
      "[115]\tvalidation_0-mae:68022\n",
      "[116]\tvalidation_0-mae:67741.2\n",
      "[117]\tvalidation_0-mae:67556.7\n",
      "[118]\tvalidation_0-mae:67057.8\n",
      "[119]\tvalidation_0-mae:66936.1\n",
      "[120]\tvalidation_0-mae:66357.4\n",
      "[121]\tvalidation_0-mae:65887.3\n",
      "[122]\tvalidation_0-mae:65421.8\n",
      "[123]\tvalidation_0-mae:65178.9\n",
      "[124]\tvalidation_0-mae:64876.3\n",
      "[125]\tvalidation_0-mae:64427.6\n",
      "[126]\tvalidation_0-mae:63977.7\n",
      "[127]\tvalidation_0-mae:63680.4\n",
      "[128]\tvalidation_0-mae:63478.8\n",
      "[129]\tvalidation_0-mae:63238.6\n",
      "[130]\tvalidation_0-mae:62899\n",
      "[131]\tvalidation_0-mae:62492.9\n",
      "[132]\tvalidation_0-mae:62416.5\n",
      "[133]\tvalidation_0-mae:62375.9\n",
      "[134]\tvalidation_0-mae:62096.8\n",
      "[135]\tvalidation_0-mae:61738.3\n",
      "[136]\tvalidation_0-mae:61401.5\n",
      "[137]\tvalidation_0-mae:61029\n",
      "[138]\tvalidation_0-mae:60948.2\n",
      "[139]\tvalidation_0-mae:60452.8\n",
      "[140]\tvalidation_0-mae:60096.4\n",
      "[141]\tvalidation_0-mae:59774.1\n",
      "[142]\tvalidation_0-mae:59338.6\n",
      "[143]\tvalidation_0-mae:58973\n",
      "[144]\tvalidation_0-mae:58772.1\n",
      "[145]\tvalidation_0-mae:58556.3\n",
      "[146]\tvalidation_0-mae:58097\n",
      "[147]\tvalidation_0-mae:57890.8\n",
      "[148]\tvalidation_0-mae:57579.2\n",
      "[149]\tvalidation_0-mae:57439.4\n",
      "    fold  3:  [493145.28574408]\n",
      "    ----\n",
      "    MEAN:     [491842.91257090] + [4311.94088658]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "features = ['antiguedad', 'metroscubiertos', 'metrostotales', 'lat', 'lng',\n",
    "       'metroscubiertos_log', 'diferencia_metros',\n",
    "       'promedio_metros_tipo_propiedad', 'dias_desde_datos', 'tam_ambientes',\n",
    "       'promedio_precio_ciudad_gen', 'varianza_precio_ciudad',\n",
    "       'promedio_id_zona_gen', 'varianza_id_zona', 'count_id_zona',\n",
    "       'promedio_precio_tipo_propiedad_ciudad',\n",
    "       'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "       'count_tipo_propiedad_ciudad', 'promedio_por_mes',\n",
    "       'promedio_precio_habitaciones_banos_garages',\n",
    "       'promedio_precio_hbg_tipo_propiedad',\n",
    "       'promedio_precio_hbg_tipo_propiedad_provincia', 'puntaje']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('lightgbm', lgb_m), \n",
    "#            ('keras', keras_m), \n",
    "           ('xgboost', xgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8999882607358867, bagging_freq=95,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.2570109385381975, importance_type='split',\n",
       "                learning_rate=0.13601832720254403, max_depth=26,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=175,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0,\n",
       "                test_size=0.08363501292068126)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8999882607358867,\n",
    " 'bagging_freq': int(95.0),\n",
    " 'feature_fraction': 0.2570109385381975,\n",
    " 'learning_rate': 0.13601832720254403,\n",
    " 'max_depth': int(26.0),\n",
    " 'num_leaves': int(175.0),\n",
    " 'test_size': 0.08363501292068126}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta26.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8924398062087346, bagging_freq=36,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.16167385124183287, importance_type='split',\n",
       "                learning_rate=0.054693418899570134, max_depth=4,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=93,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "MAE Stacking (train): 479214.56916\n",
      "MAE Stacking (test): 409282.55733\n"
     ]
    }
   ],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:48<05:53,  4.02s/it, best loss: 437714.00137358136]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_lightgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-65ee514df873>\u001b[0m in \u001b[0;36meval_lightgbm\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                     early_stopping_rounds=15,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     verbose_eval=-1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FIUBA/Datos/.venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Keras (train): 524925.45271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
