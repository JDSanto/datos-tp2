{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bcbc500d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecision_tree_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecision_tree_algorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_tree_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatures_independientes_precio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dependientes_precio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cami/Facultad/Organizaciвn de Datos/datos-tp2/features.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;34m\"            puntaje += 6\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;34m\"        elif grupo_metros_totales == 'Grupo 4':\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;34m\"            puntaje += 8\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m     \u001b[0;34m\"        elif grupo_metros_totales == 'Grupo 5':\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;34m\"            puntaje += 10\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cami/Facultad/Organizaciвn de Datos/datos-tp2/features.ipynb\u001b[0m in \u001b[0;36mfeatures_independientes_precio\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34m\"    df['tipo_propiedad_compartida'] = map_values(df['tipodepropiedad'].values, lambda x: True if x in propiedades_compartidas else False)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;34m\"    df['prop_frecuente'] = map_values(df['tipodepropiedad'].values, lambda x: True if x in propiedades_frecuentes else False)     \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"    # Por ubicación\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;34m\"    df['provincia'] = df['provincia'].fillna('otro') # Otra forma de llenar los nans para el tipo de prop?\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cami/Facultad/Organizaciвn de Datos/datos-tp2/features.ipynb\u001b[0m in \u001b[0;36mseparador_de_textos\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;34m\"    aux = re.sub('&Otilde;', 'Õ', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;34m\"    aux = re.sub('&Ouml;', 'Ö', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0;34m\"    aux = re.sub('&ograve;', 'ò', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;34m\"    aux = re.sub('&oacute;', 'ó', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;34m\"    aux = re.sub('&ocirc;', 'ô', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cami/Facultad/Organizaciвn de Datos/datos-tp2/features.ipynb\u001b[0m in \u001b[0;36msanitize\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;34m\"    aux = re.sub('&egrave;', 'è', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;34m\"    aux = re.sub('&eacute;', 'é', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0;34m\"    aux = re.sub('&ecirc;', 'ê', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;34m\"    aux = re.sub('&euml;', 'ë', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m\"    aux = re.sub('&#131;', 'ƒ', aux)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from decision_tree_functions import decision_tree_algorithm, decision_tree_predictions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.features import features_independientes_precio, features_dependientes_precio\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "column_names = []\n",
    "for column in df.columns:\n",
    "    name = column.replace(\" \", \"_\")\n",
    "    column_names.append(name)\n",
    "df.columns = column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f = features_independientes_precio(df_train)\n",
    "df_train_f = features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f = features_independientes_precio(df_test)\n",
    "df_test_f = features_dependientes_precio(df_test_f, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test_f['precio']\n",
    "y_train = df_train_f['precio']\n",
    "x_test = df_test_f.drop('precio', axis=1)\n",
    "x_train = df_train_f.drop('precio', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = ['id', 'zona', 'intervalo_metros_cubiertos', 'intervalo_metros_totales', 'provincia', 'escualas_centros_cercanos', 'tipodepropiedad']\n",
    "\n",
    "categoricos = df_train_f[categorias]\n",
    "categoricos_test =df_test_f[categorias]\n",
    "df_full = pd.concat([categoricos_test, categoricos], ignore_index=True)\n",
    "\n",
    "categoricos = pd.get_dummies(categoricos)\n",
    "df_ohe_test = pd.get_dummies(df_full).iloc[0:60000]\n",
    "categoricos_test = df_ohe_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zona = x_train.drop(['titulo', 'descripcion','direccion', 'zona', 'intervalo_metros_cubiertos', 'intervalo_metros_totales', 'provincia', 'escualas_centros_cercanos', 'tipodepropiedad', 'ciudad', 'habitaciones', 'garages', 'banos', 'antiguedad', 'idzona', 'lat', 'lng', 'promedio_precio_hbg_tipo_propiedad_provincia_gen'], axis=1)\n",
    "df_encoding = pd.merge(zona, categoricos, on= 'id', how= 'left')\n",
    "\n",
    "zona_test = x_test.drop(['titulo', 'descripcion','direccion', 'zona', 'intervalo_metros_cubiertos', 'intervalo_metros_totales', 'provincia', 'escualas_centros_cercanos', 'tipodepropiedad', 'ciudad', 'habitaciones', 'garages', 'banos', 'antiguedad', 'idzona', 'lat', 'lng', 'promedio_precio_hbg_tipo_propiedad_provincia_gen'], axis=1)\n",
    "df_encoding_test = pd.merge(zona_test, categoricos_test, on= 'id', how= 'left')\n",
    "df_encoding_test = df_encoding_test.drop(['tipodepropiedad_Garage', 'tipodepropiedad_Hospedaje'],axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "clf.fit(df_encoding,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categoricos.shape)\n",
    "print(categoricos_test.shape)\n",
    "print(df_encoding.shape)\n",
    "print(df_encoding_test.shape)\n",
    "\n",
    "set(df_encoding_test.columns)  - set(df_encoding.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(df_encoding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(df_encoding.columns, clf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance').nlargest(40, 'Gini-importance').plot(kind='bar', rot=90, figsize= (30,30), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubiertos = importances.transpose()\n",
    "cubiertos = cubiertos[['metroscubiertos', 'intervalo_metros_cubiertos_Grupo1', 'intervalo_metros_cubiertos_Grupo2', 'intervalo_metros_cubiertos_Grupo3', 'intervalo_metros_cubiertos_Grupo4', 'intervalo_metros_cubiertos_Grupo5']]\n",
    "cubiertos.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totales = importances.transpose()\n",
    "totales = totales[['metrostotales', 'intervalo_metros_totales_Grupo1', 'intervalo_metros_totales_Grupo2', 'intervalo_metros_totales_Grupo3', 'intervalo_metros_totales_Grupo4', 'intervalo_metros_totales_Grupo5']]\n",
    "totales.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
