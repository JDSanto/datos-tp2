{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import ipynb.fs.full.utils as utils\n",
    "import ipynb.fs.full.features as features\n",
    "import ipynb.fs.full.features_distancias as f_distancias\n",
    "\n",
    "df_train = pd.read_csv('./data/train_filtrado.csv')\n",
    "# Para usarse con el submit a Kaggle\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_train = features.llenar_nulls(df_train)\n",
    "df_test = features.llenar_nulls(df_test, hgb_mean=True, df_fill=df_train)\n",
    "\n",
    "# df_train, df_test = features_de_csvs(df_train, df_test)\n",
    "\n",
    "# df_train, df_test = utils.dividir_df_testeo(df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_f = features.features_independientes_precio(df_test)\n",
    "df_test_f = features.features_dependientes_precio(df_test_f, df_train)\n",
    "\n",
    "df_train_f = features.features_independientes_precio(df_train)\n",
    "df_train_f = features.features_dependientes_precio(df_train_f, df_train)\n",
    "\n",
    "df_test_f, cols_tipodepropiedad_ohe = features.columna_a_ohe(df_test_f, 'tipodepropiedad', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_provincia_ohe = features.columna_a_ohe(df_test_f, 'provincia', N=100, df_aux=df_train, devolver_cols=True)\n",
    "df_test_f, cols_zona_ohe = features.columna_a_ohe(df_test_f, 'zona', df_aux=df_train_f, devolver_cols=True)\n",
    "\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'tipodepropiedad', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'provincia', N=100, df_aux=df_test)\n",
    "df_train_f = features.columna_a_ohe(df_train_f, 'zona', df_aux=df_test_f)\n",
    "\n",
    "\n",
    "df_train_f['fecha'] = pd.to_datetime(df_train_f['fecha']).astype(int)\n",
    "df_test_f['fecha'] = pd.to_datetime(df_test_f['fecha']).astype(int)\n",
    "\n",
    "df_train_idf = pd.read_csv('./data/train_idf.csv')\n",
    "df_test_idf = pd.read_csv('./data/test_idf.csv')\n",
    "\n",
    "df_train_f = pd.merge(df_train_f, df_train_idf, on= 'id', how= 'left')\n",
    "df_test_f = pd.merge(df_test_f, df_test_idf, on= 'id', how= 'left')\n",
    "\n",
    "df_train_f = f_distancias.feature_distancias(df_train_f)\n",
    "df_test_f = f_distancias.feature_distancias(df_test_f, df_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LightGBMWrapper(lgb.LGBMRegressor):\n",
    "    \n",
    "    def fit(self, x, y):        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.08363501292068126)\n",
    "        return super(LightGBMWrapper, self).fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(LightGBMWrapper, self).predict(X, \n",
    "               num_iteration=self.best_iteration_)\n",
    "\n",
    "hps = {'bagging_fraction': 0.8994254451454451,\n",
    " 'bagging_freq': 90.0,\n",
    " 'feature_fraction': 0.22390222216361155,\n",
    " 'learning_rate': 0.09425558913069614,\n",
    " 'max_depth': 16.0,\n",
    " 'num_leaves': 179.0,\n",
    " 'test_size': 0.09437441103433714}\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae', # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "    'num_leaves': int(hps['num_leaves']),\n",
    "    'learning_rate': hps['learning_rate'],\n",
    "    'feature_fraction': hps['feature_fraction'],\n",
    "    'bagging_fraction': hps['bagging_fraction'],\n",
    "    'bagging_freq': int(hps['bagging_freq']),\n",
    "    'max_depth': int(hps['max_depth']),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_m = LightGBMWrapper(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "def keras_modelo():    \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'], validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "keras_m = KerasRegressor(build_fn=keras_modelo, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class XGBoostWrapper(xgb.XGBRegressor):\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return super(xgb.XGBRegressor, self).fit(x, y, early_stopping_rounds=2, eval_metric='mae', eval_set=[(x, y)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return super(xgb.XGBRegressor, self).predict(X)\n",
    "\n",
    "\n",
    "hps = {'alpha': 20.91434940058063,\n",
    "       'colsample_bytree': 0.65,\n",
    "       'learning_rate': 0.14,\n",
    "       'max_depth': int(16.0),\n",
    "       'n_estimators': int(150.0),\n",
    "       'test_size': 0.2,\n",
    "       'early_stopping_rounds': 5,\n",
    "       'n_jobs': 2}\n",
    "\n",
    "\n",
    "n_estimators = int(hps['n_estimators'])\n",
    "max_depth = int(hps['max_depth'])\n",
    "\n",
    "xgb_m = XGBoostWrapper(**hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    fold  0:  [529852.90197680]\n",
      "    fold  1:  [522813.81774048]\n",
      "    fold  2:  [522338.19715007]\n",
      "    fold  3:  [527725.73873998]\n",
      "    ----\n",
      "    MEAN:     [525682.66390183] + [3200.81148099]\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "[21:18:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.17484e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88023e+06\n",
      "[2]\tvalidation_0-mae:1.62506e+06\n",
      "[3]\tvalidation_0-mae:1.40694e+06\n",
      "[4]\tvalidation_0-mae:1.21945e+06\n",
      "[5]\tvalidation_0-mae:1.0593e+06\n",
      "[6]\tvalidation_0-mae:923581\n",
      "[7]\tvalidation_0-mae:806735\n",
      "[8]\tvalidation_0-mae:708459\n",
      "[9]\tvalidation_0-mae:625356\n",
      "[10]\tvalidation_0-mae:555550\n",
      "[11]\tvalidation_0-mae:497016\n",
      "[12]\tvalidation_0-mae:447898\n",
      "[13]\tvalidation_0-mae:406388\n",
      "[14]\tvalidation_0-mae:371638\n",
      "[15]\tvalidation_0-mae:341772\n",
      "[16]\tvalidation_0-mae:317558\n",
      "[17]\tvalidation_0-mae:297814\n",
      "[18]\tvalidation_0-mae:280876\n",
      "[19]\tvalidation_0-mae:265348\n",
      "[20]\tvalidation_0-mae:253770\n",
      "[21]\tvalidation_0-mae:242908\n",
      "[22]\tvalidation_0-mae:232832\n",
      "[23]\tvalidation_0-mae:224114\n",
      "[24]\tvalidation_0-mae:215418\n",
      "[25]\tvalidation_0-mae:209177\n",
      "[26]\tvalidation_0-mae:201804\n",
      "[27]\tvalidation_0-mae:196090\n",
      "[28]\tvalidation_0-mae:189315\n",
      "[29]\tvalidation_0-mae:183621\n",
      "[30]\tvalidation_0-mae:178924\n",
      "[31]\tvalidation_0-mae:175121\n",
      "[32]\tvalidation_0-mae:171449\n",
      "[33]\tvalidation_0-mae:168372\n",
      "[34]\tvalidation_0-mae:165164\n",
      "[35]\tvalidation_0-mae:161731\n",
      "[36]\tvalidation_0-mae:157717\n",
      "[37]\tvalidation_0-mae:153708\n",
      "[38]\tvalidation_0-mae:150799\n",
      "[39]\tvalidation_0-mae:147308\n",
      "[40]\tvalidation_0-mae:144254\n",
      "[41]\tvalidation_0-mae:141699\n",
      "[42]\tvalidation_0-mae:139478\n",
      "[43]\tvalidation_0-mae:136904\n",
      "[44]\tvalidation_0-mae:134111\n",
      "[45]\tvalidation_0-mae:131462\n",
      "[46]\tvalidation_0-mae:129902\n",
      "[47]\tvalidation_0-mae:127576\n",
      "[48]\tvalidation_0-mae:125596\n",
      "[49]\tvalidation_0-mae:123922\n",
      "[50]\tvalidation_0-mae:121415\n",
      "[51]\tvalidation_0-mae:119309\n",
      "[52]\tvalidation_0-mae:117663\n",
      "[53]\tvalidation_0-mae:115948\n",
      "[54]\tvalidation_0-mae:113657\n",
      "[55]\tvalidation_0-mae:112539\n",
      "[56]\tvalidation_0-mae:111043\n",
      "[57]\tvalidation_0-mae:109970\n",
      "[58]\tvalidation_0-mae:108877\n",
      "[59]\tvalidation_0-mae:107767\n",
      "[60]\tvalidation_0-mae:106529\n",
      "[61]\tvalidation_0-mae:105428\n",
      "[62]\tvalidation_0-mae:104414\n",
      "[63]\tvalidation_0-mae:102990\n",
      "[64]\tvalidation_0-mae:102095\n",
      "[65]\tvalidation_0-mae:101581\n",
      "[66]\tvalidation_0-mae:100499\n",
      "[67]\tvalidation_0-mae:99639.3\n",
      "[68]\tvalidation_0-mae:98865.8\n",
      "[69]\tvalidation_0-mae:97691.2\n",
      "[70]\tvalidation_0-mae:96302.9\n",
      "[71]\tvalidation_0-mae:95588.1\n",
      "[72]\tvalidation_0-mae:95034.5\n",
      "[73]\tvalidation_0-mae:94511.7\n",
      "[74]\tvalidation_0-mae:93623.6\n",
      "[75]\tvalidation_0-mae:92848.5\n",
      "[76]\tvalidation_0-mae:92305.1\n",
      "[77]\tvalidation_0-mae:91436.3\n",
      "[78]\tvalidation_0-mae:91055.9\n",
      "[79]\tvalidation_0-mae:89897.8\n",
      "[80]\tvalidation_0-mae:89561.6\n",
      "[81]\tvalidation_0-mae:88575.9\n",
      "[82]\tvalidation_0-mae:87683.7\n",
      "[83]\tvalidation_0-mae:87139.5\n",
      "[84]\tvalidation_0-mae:86762.8\n",
      "[85]\tvalidation_0-mae:86280\n",
      "[86]\tvalidation_0-mae:85957.4\n",
      "[87]\tvalidation_0-mae:85261.4\n",
      "[88]\tvalidation_0-mae:85024.2\n",
      "[89]\tvalidation_0-mae:84841.4\n",
      "[90]\tvalidation_0-mae:84525.5\n",
      "[91]\tvalidation_0-mae:83908.5\n",
      "[92]\tvalidation_0-mae:82874.6\n",
      "[93]\tvalidation_0-mae:82024.7\n",
      "[94]\tvalidation_0-mae:81724.8\n",
      "[95]\tvalidation_0-mae:81432.1\n",
      "[96]\tvalidation_0-mae:81353.8\n",
      "[97]\tvalidation_0-mae:81010.2\n",
      "[98]\tvalidation_0-mae:80310.9\n",
      "[99]\tvalidation_0-mae:79495.5\n",
      "[100]\tvalidation_0-mae:79018.8\n",
      "[101]\tvalidation_0-mae:78741.8\n",
      "[102]\tvalidation_0-mae:78603.8\n",
      "[103]\tvalidation_0-mae:78201.5\n",
      "[104]\tvalidation_0-mae:76969.4\n",
      "[105]\tvalidation_0-mae:76218.7\n",
      "[106]\tvalidation_0-mae:75991\n",
      "[107]\tvalidation_0-mae:75508.7\n",
      "[108]\tvalidation_0-mae:75339.4\n",
      "[109]\tvalidation_0-mae:75031.9\n",
      "[110]\tvalidation_0-mae:74753.8\n",
      "[111]\tvalidation_0-mae:73799.1\n",
      "[112]\tvalidation_0-mae:73514.9\n",
      "[113]\tvalidation_0-mae:73234.3\n",
      "[114]\tvalidation_0-mae:72473.5\n",
      "[115]\tvalidation_0-mae:72184.4\n",
      "[116]\tvalidation_0-mae:71859\n",
      "[117]\tvalidation_0-mae:71610.8\n",
      "[118]\tvalidation_0-mae:71250.6\n",
      "[119]\tvalidation_0-mae:70989.1\n",
      "[120]\tvalidation_0-mae:70914.6\n",
      "[121]\tvalidation_0-mae:70569.6\n",
      "[122]\tvalidation_0-mae:70435\n",
      "[123]\tvalidation_0-mae:70036.7\n",
      "[124]\tvalidation_0-mae:69977.9\n",
      "[125]\tvalidation_0-mae:68996.2\n",
      "[126]\tvalidation_0-mae:68099.2\n",
      "[127]\tvalidation_0-mae:67583\n",
      "[128]\tvalidation_0-mae:67363\n",
      "[129]\tvalidation_0-mae:67100.3\n",
      "[130]\tvalidation_0-mae:66861.9\n",
      "[131]\tvalidation_0-mae:66715.5\n",
      "[132]\tvalidation_0-mae:66484\n",
      "[133]\tvalidation_0-mae:66084.2\n",
      "[134]\tvalidation_0-mae:65856.4\n",
      "[135]\tvalidation_0-mae:65697.5\n",
      "[136]\tvalidation_0-mae:65334.6\n",
      "[137]\tvalidation_0-mae:65272.8\n",
      "[138]\tvalidation_0-mae:65037.5\n",
      "[139]\tvalidation_0-mae:64607.8\n",
      "[140]\tvalidation_0-mae:64278.5\n",
      "[141]\tvalidation_0-mae:64004.1\n",
      "[142]\tvalidation_0-mae:63920.7\n",
      "[143]\tvalidation_0-mae:63437.6\n",
      "[144]\tvalidation_0-mae:62997.7\n",
      "[145]\tvalidation_0-mae:62764\n",
      "[146]\tvalidation_0-mae:62419.6\n",
      "[147]\tvalidation_0-mae:62185.4\n",
      "[148]\tvalidation_0-mae:62020.4\n",
      "[149]\tvalidation_0-mae:61866.6\n",
      "    fold  0:  [485319.40392863]\n",
      "[21:20:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.17766e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88264e+06\n",
      "[2]\tvalidation_0-mae:1.62732e+06\n",
      "[3]\tvalidation_0-mae:1.40907e+06\n",
      "[4]\tvalidation_0-mae:1.22119e+06\n",
      "[5]\tvalidation_0-mae:1.06085e+06\n",
      "[6]\tvalidation_0-mae:924602\n",
      "[7]\tvalidation_0-mae:807423\n",
      "[8]\tvalidation_0-mae:708817\n",
      "[9]\tvalidation_0-mae:625496\n",
      "[10]\tvalidation_0-mae:555546\n",
      "[11]\tvalidation_0-mae:497067\n",
      "[12]\tvalidation_0-mae:447631\n",
      "[13]\tvalidation_0-mae:406043\n",
      "[14]\tvalidation_0-mae:371227\n",
      "[15]\tvalidation_0-mae:341364\n",
      "[16]\tvalidation_0-mae:316943\n",
      "[17]\tvalidation_0-mae:297119\n",
      "[18]\tvalidation_0-mae:280285\n",
      "[19]\tvalidation_0-mae:264710\n",
      "[20]\tvalidation_0-mae:253178\n",
      "[21]\tvalidation_0-mae:242275\n",
      "[22]\tvalidation_0-mae:232401\n",
      "[23]\tvalidation_0-mae:223971\n",
      "[24]\tvalidation_0-mae:215177\n",
      "[25]\tvalidation_0-mae:208942\n",
      "[26]\tvalidation_0-mae:201606\n",
      "[27]\tvalidation_0-mae:195954\n",
      "[28]\tvalidation_0-mae:189447\n",
      "[29]\tvalidation_0-mae:183975\n",
      "[30]\tvalidation_0-mae:179002\n",
      "[31]\tvalidation_0-mae:174936\n",
      "[32]\tvalidation_0-mae:171121\n",
      "[33]\tvalidation_0-mae:167313\n",
      "[34]\tvalidation_0-mae:164027\n",
      "[35]\tvalidation_0-mae:161015\n",
      "[36]\tvalidation_0-mae:156653\n",
      "[37]\tvalidation_0-mae:152692\n",
      "[38]\tvalidation_0-mae:150086\n",
      "[39]\tvalidation_0-mae:146938\n",
      "[40]\tvalidation_0-mae:143948\n",
      "[41]\tvalidation_0-mae:141334\n",
      "[42]\tvalidation_0-mae:139331\n",
      "[43]\tvalidation_0-mae:136302\n",
      "[44]\tvalidation_0-mae:133760\n",
      "[45]\tvalidation_0-mae:131371\n",
      "[46]\tvalidation_0-mae:129399\n",
      "[47]\tvalidation_0-mae:126914\n",
      "[48]\tvalidation_0-mae:125384\n",
      "[49]\tvalidation_0-mae:123733\n",
      "[50]\tvalidation_0-mae:121211\n",
      "[51]\tvalidation_0-mae:119440\n",
      "[52]\tvalidation_0-mae:117549\n",
      "[53]\tvalidation_0-mae:115592\n",
      "[54]\tvalidation_0-mae:113575\n",
      "[55]\tvalidation_0-mae:111817\n",
      "[56]\tvalidation_0-mae:110500\n",
      "[57]\tvalidation_0-mae:109480\n",
      "[58]\tvalidation_0-mae:108351\n",
      "[59]\tvalidation_0-mae:106910\n",
      "[60]\tvalidation_0-mae:106274\n",
      "[61]\tvalidation_0-mae:105333\n",
      "[62]\tvalidation_0-mae:104439\n",
      "[63]\tvalidation_0-mae:103585\n",
      "[64]\tvalidation_0-mae:103040\n",
      "[65]\tvalidation_0-mae:102482\n",
      "[66]\tvalidation_0-mae:101183\n",
      "[67]\tvalidation_0-mae:100354\n",
      "[68]\tvalidation_0-mae:99400.2\n",
      "[69]\tvalidation_0-mae:97940\n",
      "[70]\tvalidation_0-mae:97003.2\n",
      "[71]\tvalidation_0-mae:96377.7\n",
      "[72]\tvalidation_0-mae:96078.1\n",
      "[73]\tvalidation_0-mae:94933.4\n",
      "[74]\tvalidation_0-mae:94399.5\n",
      "[75]\tvalidation_0-mae:94001.2\n",
      "[76]\tvalidation_0-mae:93040.3\n",
      "[77]\tvalidation_0-mae:92566.6\n",
      "[78]\tvalidation_0-mae:91737.5\n",
      "[79]\tvalidation_0-mae:90892.6\n",
      "[80]\tvalidation_0-mae:90663.4\n",
      "[81]\tvalidation_0-mae:89296.2\n",
      "[82]\tvalidation_0-mae:88137.2\n",
      "[83]\tvalidation_0-mae:87568.7\n",
      "[84]\tvalidation_0-mae:87070.1\n",
      "[85]\tvalidation_0-mae:86727.2\n",
      "[86]\tvalidation_0-mae:86407.8\n",
      "[87]\tvalidation_0-mae:85577.5\n",
      "[88]\tvalidation_0-mae:85350.3\n",
      "[89]\tvalidation_0-mae:85067.6\n",
      "[90]\tvalidation_0-mae:84781\n",
      "[91]\tvalidation_0-mae:83929\n",
      "[92]\tvalidation_0-mae:83014.1\n",
      "[93]\tvalidation_0-mae:81748.3\n",
      "[94]\tvalidation_0-mae:81190.2\n",
      "[95]\tvalidation_0-mae:80826.6\n",
      "[96]\tvalidation_0-mae:80510.9\n",
      "[97]\tvalidation_0-mae:80102.4\n",
      "[98]\tvalidation_0-mae:78748.7\n",
      "[99]\tvalidation_0-mae:78572.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-mae:77883.4\n",
      "[101]\tvalidation_0-mae:77702.2\n",
      "[102]\tvalidation_0-mae:77505.6\n",
      "[103]\tvalidation_0-mae:76470\n",
      "[104]\tvalidation_0-mae:75780.6\n",
      "[105]\tvalidation_0-mae:75630\n",
      "[106]\tvalidation_0-mae:75282\n",
      "[107]\tvalidation_0-mae:75108.8\n",
      "[108]\tvalidation_0-mae:74693.8\n",
      "[109]\tvalidation_0-mae:74534.3\n",
      "[110]\tvalidation_0-mae:74041.1\n",
      "[111]\tvalidation_0-mae:73343.4\n",
      "[112]\tvalidation_0-mae:73066.3\n",
      "[113]\tvalidation_0-mae:72845.9\n",
      "[114]\tvalidation_0-mae:72257.4\n",
      "[115]\tvalidation_0-mae:71449.2\n",
      "[116]\tvalidation_0-mae:70401\n",
      "[117]\tvalidation_0-mae:70265.2\n",
      "[118]\tvalidation_0-mae:69551.7\n",
      "[119]\tvalidation_0-mae:69453.9\n",
      "[120]\tvalidation_0-mae:69310.8\n",
      "[121]\tvalidation_0-mae:68599.4\n",
      "[122]\tvalidation_0-mae:68207.4\n",
      "[123]\tvalidation_0-mae:67866.3\n",
      "[124]\tvalidation_0-mae:67427.5\n",
      "[125]\tvalidation_0-mae:67064.8\n",
      "[126]\tvalidation_0-mae:66244.2\n",
      "[127]\tvalidation_0-mae:66085.4\n",
      "[128]\tvalidation_0-mae:65735.3\n",
      "[129]\tvalidation_0-mae:65308.6\n",
      "[130]\tvalidation_0-mae:64795.4\n",
      "[131]\tvalidation_0-mae:64071.1\n",
      "[132]\tvalidation_0-mae:63845.3\n",
      "[133]\tvalidation_0-mae:63562\n",
      "[134]\tvalidation_0-mae:63456.5\n",
      "[135]\tvalidation_0-mae:63112.1\n",
      "[136]\tvalidation_0-mae:62896.2\n",
      "[137]\tvalidation_0-mae:62478.3\n",
      "[138]\tvalidation_0-mae:62132.7\n",
      "[139]\tvalidation_0-mae:61441.4\n",
      "[140]\tvalidation_0-mae:61184.9\n",
      "[141]\tvalidation_0-mae:61162.9\n",
      "[142]\tvalidation_0-mae:61002.9\n",
      "[143]\tvalidation_0-mae:60286.9\n",
      "[144]\tvalidation_0-mae:60061.3\n",
      "[145]\tvalidation_0-mae:59731.7\n",
      "[146]\tvalidation_0-mae:59254.4\n",
      "[147]\tvalidation_0-mae:58728\n",
      "[148]\tvalidation_0-mae:58191.1\n",
      "[149]\tvalidation_0-mae:58082.9\n",
      "    fold  1:  [481583.09292820]\n",
      "[21:21:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.18355e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88795e+06\n",
      "[2]\tvalidation_0-mae:1.63189e+06\n",
      "[3]\tvalidation_0-mae:1.41297e+06\n",
      "[4]\tvalidation_0-mae:1.22463e+06\n",
      "[5]\tvalidation_0-mae:1.06412e+06\n",
      "[6]\tvalidation_0-mae:927503\n",
      "[7]\tvalidation_0-mae:809870\n",
      "[8]\tvalidation_0-mae:710858\n",
      "[9]\tvalidation_0-mae:627268\n",
      "[10]\tvalidation_0-mae:557068\n",
      "[11]\tvalidation_0-mae:498441\n",
      "[12]\tvalidation_0-mae:449020\n",
      "[13]\tvalidation_0-mae:407576\n",
      "[14]\tvalidation_0-mae:372643\n",
      "[15]\tvalidation_0-mae:342982\n",
      "[16]\tvalidation_0-mae:318416\n",
      "[17]\tvalidation_0-mae:298668\n",
      "[18]\tvalidation_0-mae:281717\n",
      "[19]\tvalidation_0-mae:266054\n",
      "[20]\tvalidation_0-mae:254538\n",
      "[21]\tvalidation_0-mae:243883\n",
      "[22]\tvalidation_0-mae:233868\n",
      "[23]\tvalidation_0-mae:225482\n",
      "[24]\tvalidation_0-mae:217172\n",
      "[25]\tvalidation_0-mae:211081\n",
      "[26]\tvalidation_0-mae:203843\n",
      "[27]\tvalidation_0-mae:198036\n",
      "[28]\tvalidation_0-mae:191863\n",
      "[29]\tvalidation_0-mae:186244\n",
      "[30]\tvalidation_0-mae:180985\n",
      "[31]\tvalidation_0-mae:176748\n",
      "[32]\tvalidation_0-mae:172772\n",
      "[33]\tvalidation_0-mae:168963\n",
      "[34]\tvalidation_0-mae:165937\n",
      "[35]\tvalidation_0-mae:162922\n",
      "[36]\tvalidation_0-mae:159221\n",
      "[37]\tvalidation_0-mae:155085\n",
      "[38]\tvalidation_0-mae:152321\n",
      "[39]\tvalidation_0-mae:149072\n",
      "[40]\tvalidation_0-mae:145963\n",
      "[41]\tvalidation_0-mae:142953\n",
      "[42]\tvalidation_0-mae:140705\n",
      "[43]\tvalidation_0-mae:137354\n",
      "[44]\tvalidation_0-mae:135068\n",
      "[45]\tvalidation_0-mae:132518\n",
      "[46]\tvalidation_0-mae:130767\n",
      "[47]\tvalidation_0-mae:128451\n",
      "[48]\tvalidation_0-mae:127097\n",
      "[49]\tvalidation_0-mae:124789\n",
      "[50]\tvalidation_0-mae:122552\n",
      "[51]\tvalidation_0-mae:120347\n",
      "[52]\tvalidation_0-mae:118863\n",
      "[53]\tvalidation_0-mae:117008\n",
      "[54]\tvalidation_0-mae:114984\n",
      "[55]\tvalidation_0-mae:113381\n",
      "[56]\tvalidation_0-mae:111781\n",
      "[57]\tvalidation_0-mae:110381\n",
      "[58]\tvalidation_0-mae:109369\n",
      "[59]\tvalidation_0-mae:107400\n",
      "[60]\tvalidation_0-mae:106577\n",
      "[61]\tvalidation_0-mae:105759\n",
      "[62]\tvalidation_0-mae:105121\n",
      "[63]\tvalidation_0-mae:103641\n",
      "[64]\tvalidation_0-mae:103047\n",
      "[65]\tvalidation_0-mae:102319\n",
      "[66]\tvalidation_0-mae:101242\n",
      "[67]\tvalidation_0-mae:100160\n",
      "[68]\tvalidation_0-mae:99629.2\n",
      "[69]\tvalidation_0-mae:98944.2\n",
      "[70]\tvalidation_0-mae:98231\n",
      "[71]\tvalidation_0-mae:97655.7\n",
      "[72]\tvalidation_0-mae:96543.4\n",
      "[73]\tvalidation_0-mae:94640.1\n",
      "[74]\tvalidation_0-mae:94142.9\n",
      "[75]\tvalidation_0-mae:93116.5\n",
      "[76]\tvalidation_0-mae:92481.4\n",
      "[77]\tvalidation_0-mae:92125.6\n",
      "[78]\tvalidation_0-mae:91775.3\n",
      "[79]\tvalidation_0-mae:90492.9\n",
      "[80]\tvalidation_0-mae:89363.6\n",
      "[81]\tvalidation_0-mae:88148.1\n",
      "[82]\tvalidation_0-mae:87778.8\n",
      "[83]\tvalidation_0-mae:87195.3\n",
      "[84]\tvalidation_0-mae:86830.3\n",
      "[85]\tvalidation_0-mae:86022.3\n",
      "[86]\tvalidation_0-mae:85685.9\n",
      "[87]\tvalidation_0-mae:84960.4\n",
      "[88]\tvalidation_0-mae:84326.2\n",
      "[89]\tvalidation_0-mae:83858.3\n",
      "[90]\tvalidation_0-mae:83457.7\n",
      "[91]\tvalidation_0-mae:83159.3\n",
      "[92]\tvalidation_0-mae:82799.4\n",
      "[93]\tvalidation_0-mae:82228.3\n",
      "[94]\tvalidation_0-mae:81370.8\n",
      "[95]\tvalidation_0-mae:80847.7\n",
      "[96]\tvalidation_0-mae:80262.1\n",
      "[97]\tvalidation_0-mae:79751.6\n",
      "[98]\tvalidation_0-mae:78793.2\n",
      "[99]\tvalidation_0-mae:77952\n",
      "[100]\tvalidation_0-mae:77488.2\n",
      "[101]\tvalidation_0-mae:77091.5\n",
      "[102]\tvalidation_0-mae:76226\n",
      "[103]\tvalidation_0-mae:75815.4\n",
      "[104]\tvalidation_0-mae:75230.7\n",
      "[105]\tvalidation_0-mae:74121.9\n",
      "[106]\tvalidation_0-mae:73877.7\n",
      "[107]\tvalidation_0-mae:73725.4\n",
      "[108]\tvalidation_0-mae:73451.7\n",
      "[109]\tvalidation_0-mae:73358.2\n",
      "[110]\tvalidation_0-mae:73077.3\n",
      "[111]\tvalidation_0-mae:72940.8\n",
      "[112]\tvalidation_0-mae:72751.6\n",
      "[113]\tvalidation_0-mae:72422\n",
      "[114]\tvalidation_0-mae:71647.7\n",
      "[115]\tvalidation_0-mae:71410.4\n",
      "[116]\tvalidation_0-mae:70794.7\n",
      "[117]\tvalidation_0-mae:70376.8\n",
      "[118]\tvalidation_0-mae:69411.2\n",
      "[119]\tvalidation_0-mae:69304.5\n",
      "[120]\tvalidation_0-mae:68980.5\n",
      "[121]\tvalidation_0-mae:68516.2\n",
      "[122]\tvalidation_0-mae:68346.7\n",
      "[123]\tvalidation_0-mae:68254.8\n",
      "[124]\tvalidation_0-mae:68122.4\n",
      "[125]\tvalidation_0-mae:67702.5\n",
      "[126]\tvalidation_0-mae:67091.1\n",
      "[127]\tvalidation_0-mae:66741\n",
      "[128]\tvalidation_0-mae:66448.7\n",
      "[129]\tvalidation_0-mae:65880.5\n",
      "[130]\tvalidation_0-mae:65588.3\n",
      "[131]\tvalidation_0-mae:65476.5\n",
      "[132]\tvalidation_0-mae:65179.7\n",
      "[133]\tvalidation_0-mae:64881.7\n",
      "[134]\tvalidation_0-mae:64633.1\n",
      "[135]\tvalidation_0-mae:64284.9\n",
      "[136]\tvalidation_0-mae:63979.2\n",
      "[137]\tvalidation_0-mae:63843.5\n",
      "[138]\tvalidation_0-mae:63701.4\n",
      "[139]\tvalidation_0-mae:63368.1\n",
      "[140]\tvalidation_0-mae:63267.4\n",
      "[141]\tvalidation_0-mae:63146.9\n",
      "[142]\tvalidation_0-mae:63056.7\n",
      "[143]\tvalidation_0-mae:62759.6\n",
      "[144]\tvalidation_0-mae:62600\n",
      "[145]\tvalidation_0-mae:62500.7\n",
      "[146]\tvalidation_0-mae:62366.7\n",
      "[147]\tvalidation_0-mae:61708.5\n",
      "[148]\tvalidation_0-mae:61348.8\n",
      "[149]\tvalidation_0-mae:61203.1\n",
      "    fold  2:  [477727.16102519]\n",
      "[21:23:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-mae:2.17987e+06\n",
      "Will train until validation_0-mae hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-mae:1.88452e+06\n",
      "[2]\tvalidation_0-mae:1.62865e+06\n",
      "[3]\tvalidation_0-mae:1.41019e+06\n",
      "[4]\tvalidation_0-mae:1.22215e+06\n",
      "[5]\tvalidation_0-mae:1.06154e+06\n",
      "[6]\tvalidation_0-mae:925412\n",
      "[7]\tvalidation_0-mae:808165\n",
      "[8]\tvalidation_0-mae:709377\n",
      "[9]\tvalidation_0-mae:625997\n",
      "[10]\tvalidation_0-mae:555919\n",
      "[11]\tvalidation_0-mae:497064\n",
      "[12]\tvalidation_0-mae:447673\n",
      "[13]\tvalidation_0-mae:406231\n",
      "[14]\tvalidation_0-mae:371657\n",
      "[15]\tvalidation_0-mae:341905\n",
      "[16]\tvalidation_0-mae:317399\n",
      "[17]\tvalidation_0-mae:297960\n",
      "[18]\tvalidation_0-mae:281075\n",
      "[19]\tvalidation_0-mae:265856\n",
      "[20]\tvalidation_0-mae:254356\n",
      "[21]\tvalidation_0-mae:243616\n",
      "[22]\tvalidation_0-mae:234090\n",
      "[23]\tvalidation_0-mae:225830\n",
      "[24]\tvalidation_0-mae:217471\n",
      "[25]\tvalidation_0-mae:210859\n",
      "[26]\tvalidation_0-mae:203457\n",
      "[27]\tvalidation_0-mae:197916\n",
      "[28]\tvalidation_0-mae:191587\n",
      "[29]\tvalidation_0-mae:186158\n",
      "[30]\tvalidation_0-mae:181440\n",
      "[31]\tvalidation_0-mae:177304\n",
      "[32]\tvalidation_0-mae:173425\n",
      "[33]\tvalidation_0-mae:170150\n",
      "[34]\tvalidation_0-mae:167241\n",
      "[35]\tvalidation_0-mae:163953\n",
      "[36]\tvalidation_0-mae:160042\n",
      "[37]\tvalidation_0-mae:156254\n",
      "[38]\tvalidation_0-mae:153438\n",
      "[39]\tvalidation_0-mae:150229\n",
      "[40]\tvalidation_0-mae:147278\n",
      "[41]\tvalidation_0-mae:144432\n",
      "[42]\tvalidation_0-mae:142281\n",
      "[43]\tvalidation_0-mae:139071\n",
      "[44]\tvalidation_0-mae:136818\n",
      "[45]\tvalidation_0-mae:133946\n",
      "[46]\tvalidation_0-mae:132371\n",
      "[47]\tvalidation_0-mae:129411\n",
      "[48]\tvalidation_0-mae:127353\n",
      "[49]\tvalidation_0-mae:125852\n",
      "[50]\tvalidation_0-mae:123612\n",
      "[51]\tvalidation_0-mae:121586\n",
      "[52]\tvalidation_0-mae:119717\n",
      "[53]\tvalidation_0-mae:117827\n",
      "[54]\tvalidation_0-mae:116476\n",
      "[55]\tvalidation_0-mae:114093\n",
      "[56]\tvalidation_0-mae:111317\n",
      "[57]\tvalidation_0-mae:109805\n",
      "[58]\tvalidation_0-mae:108569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59]\tvalidation_0-mae:106626\n",
      "[60]\tvalidation_0-mae:105815\n",
      "[61]\tvalidation_0-mae:104584\n",
      "[62]\tvalidation_0-mae:103745\n",
      "[63]\tvalidation_0-mae:102975\n",
      "[64]\tvalidation_0-mae:102280\n",
      "[65]\tvalidation_0-mae:101619\n",
      "[66]\tvalidation_0-mae:100044\n",
      "[67]\tvalidation_0-mae:99278.3\n",
      "[68]\tvalidation_0-mae:98226.5\n",
      "[69]\tvalidation_0-mae:96938.5\n",
      "[70]\tvalidation_0-mae:95621.5\n",
      "[71]\tvalidation_0-mae:94069.4\n",
      "[72]\tvalidation_0-mae:93223.9\n",
      "[73]\tvalidation_0-mae:92352.3\n",
      "[74]\tvalidation_0-mae:91653.7\n",
      "[75]\tvalidation_0-mae:91266.6\n",
      "[76]\tvalidation_0-mae:90863.1\n",
      "[77]\tvalidation_0-mae:89981.3\n",
      "[78]\tvalidation_0-mae:89390.1\n",
      "[79]\tvalidation_0-mae:88500.8\n",
      "[80]\tvalidation_0-mae:88081.3\n",
      "[81]\tvalidation_0-mae:87250.5\n",
      "[82]\tvalidation_0-mae:86118.4\n",
      "[83]\tvalidation_0-mae:86012\n",
      "[84]\tvalidation_0-mae:85492.7\n",
      "[85]\tvalidation_0-mae:84907.6\n",
      "[86]\tvalidation_0-mae:84746.1\n",
      "[87]\tvalidation_0-mae:84053.2\n",
      "[88]\tvalidation_0-mae:83741.5\n",
      "[89]\tvalidation_0-mae:83523.6\n",
      "[90]\tvalidation_0-mae:83427.5\n",
      "[91]\tvalidation_0-mae:82872.4\n",
      "[92]\tvalidation_0-mae:82561.7\n",
      "[93]\tvalidation_0-mae:81670.6\n",
      "[94]\tvalidation_0-mae:80779.4\n",
      "[95]\tvalidation_0-mae:80430.4\n",
      "[96]\tvalidation_0-mae:79752.6\n",
      "[97]\tvalidation_0-mae:79527.6\n",
      "[98]\tvalidation_0-mae:78684\n",
      "[99]\tvalidation_0-mae:78333.5\n",
      "[100]\tvalidation_0-mae:78044.4\n",
      "[101]\tvalidation_0-mae:77737.1\n",
      "[102]\tvalidation_0-mae:77354.8\n",
      "[103]\tvalidation_0-mae:76524.3\n",
      "[104]\tvalidation_0-mae:76070\n",
      "[105]\tvalidation_0-mae:75572.6\n",
      "[106]\tvalidation_0-mae:74960.9\n",
      "[107]\tvalidation_0-mae:74283.6\n",
      "[108]\tvalidation_0-mae:73984.9\n",
      "[109]\tvalidation_0-mae:73636.8\n",
      "[110]\tvalidation_0-mae:73089.8\n",
      "[111]\tvalidation_0-mae:72796.3\n",
      "[112]\tvalidation_0-mae:72575.7\n",
      "[113]\tvalidation_0-mae:72082.7\n",
      "[114]\tvalidation_0-mae:71468.1\n",
      "[115]\tvalidation_0-mae:70989.6\n",
      "[116]\tvalidation_0-mae:70752.4\n",
      "[117]\tvalidation_0-mae:70591.4\n",
      "[118]\tvalidation_0-mae:70535.5\n",
      "[119]\tvalidation_0-mae:70316.7\n",
      "[120]\tvalidation_0-mae:70263.6\n",
      "[121]\tvalidation_0-mae:70025.5\n",
      "[122]\tvalidation_0-mae:69835.8\n",
      "[123]\tvalidation_0-mae:69647.6\n",
      "[124]\tvalidation_0-mae:69479.7\n",
      "[125]\tvalidation_0-mae:69159.8\n",
      "[126]\tvalidation_0-mae:68474.8\n",
      "[127]\tvalidation_0-mae:68400.3\n",
      "[128]\tvalidation_0-mae:67841.1\n",
      "[129]\tvalidation_0-mae:67558\n",
      "[130]\tvalidation_0-mae:67289.9\n",
      "[131]\tvalidation_0-mae:67106.8\n",
      "[132]\tvalidation_0-mae:66976.4\n",
      "[133]\tvalidation_0-mae:66642.7\n",
      "[134]\tvalidation_0-mae:66489.7\n",
      "[135]\tvalidation_0-mae:65991.9\n",
      "[136]\tvalidation_0-mae:64909.6\n",
      "[137]\tvalidation_0-mae:64494.6\n",
      "[138]\tvalidation_0-mae:64412.3\n",
      "[139]\tvalidation_0-mae:63969.2\n",
      "[140]\tvalidation_0-mae:63741.6\n",
      "[141]\tvalidation_0-mae:63437\n",
      "[142]\tvalidation_0-mae:62981.4\n",
      "[143]\tvalidation_0-mae:62508.7\n",
      "[144]\tvalidation_0-mae:61999.8\n",
      "[145]\tvalidation_0-mae:61875\n",
      "[146]\tvalidation_0-mae:61778\n",
      "[147]\tvalidation_0-mae:61397.7\n",
      "[148]\tvalidation_0-mae:61232.7\n",
      "[149]\tvalidation_0-mae:61066\n",
      "    fold  3:  [483167.48119048]\n",
      "    ----\n",
      "    MEAN:     [481949.28476813] + [2774.98338030]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "features = ['habitaciones', \n",
    "            'garages', \n",
    "            'banos',\n",
    "            'antiguedad',\n",
    "           'metroscubiertos', \n",
    "            'metrostotales',\n",
    "            'lat_norm', 'lng_norm'\n",
    "            'gimnasio', 'usosmultiples', 'piscina','prop_frecuente', 'top_provincia', 'promedio_precio_ciudad', \n",
    "                 'anio', 'promedio_id_zona', 'promedio_precio_tipo_propiedad', \n",
    "                 'count_id_zona', 'count_ciudad', 'puntaje', \n",
    "                     'count_tipo_propiedad_ciudad', \n",
    "                 'promedio_precio_tipo_propiedad_ciudad_gen',\n",
    "                 'count_id_zona'\n",
    "                 'dias_desde_datos',\n",
    "                 'meses_desde_datos',\n",
    "                 'porcentaje_metros',\n",
    "                 'distancia_ciudad_centrica']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = utils.dividir_dataset(df_train_f, 'precio', features, test_size=0.001)\n",
    "\n",
    "modelos = [('lightgbm', lgb_m), \n",
    "            #('keras', keras_m), \n",
    "           ('xgboost', xgb_m)]\n",
    "\n",
    "stack = StackingTransformer(modelos, regression=True, verbose=2)\n",
    "\n",
    "stack = stack.fit(x_train, y_train)\n",
    "\n",
    "s_train = stack.transform(x_train)\n",
    "s_test = stack.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lightgbm: LightGBMWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [xgboost: XGBoostWrapper]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_train = stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features))\n",
    "s_test = stack.transform(utils.filtrar_features(df_test_f, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion con todos los features + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s = df_train_f.copy()\n",
    "df_test_s = df_test_f.copy()\n",
    "\n",
    "df_train_s['stack01'], df_train_s['stack02'] = zip(*s_train)\n",
    "df_test_s['stack01'], df_test_s['stack02'] = zip(*s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_s['id'] = df_train['id']\n",
    "df_test_s['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBMWrapper(bagging_fraction=0.8999882607358867, bagging_freq=95,\n",
       "                boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                feature_fraction=0.2570109385381975, importance_type='split',\n",
       "                learning_rate=0.13601832720254403, max_depth=26,\n",
       "                min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=175,\n",
       "                objective=None, random_state=None, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0,\n",
       "                test_size=0.08363501292068126)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8999882607358867,\n",
    " 'bagging_freq': int(95.0),\n",
    " 'feature_fraction': 0.2570109385381975,\n",
    " 'learning_rate': 0.13601832720254403,\n",
    " 'max_depth': int(26.0),\n",
    " 'num_leaves': int(175.0),\n",
    " 'test_size': 0.08363501292068126}\n",
    "\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(utils.filtrar_features(df_train_s, features + ['stack01', 'stack02']), df_train['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s['target'] = lgb_m_2nd.predict(utils.filtrar_features(df_test_s, features + ['stack01', 'stack02']))\n",
    "df_test_s[['id', 'target']].to_csv('respuesta34.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion solo con features de stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2nd = {'bagging_fraction': 0.8924398062087346,\n",
    " 'bagging_freq': int(36.0),\n",
    " 'feature_fraction': 0.16167385124183287,\n",
    " 'learning_rate': 0.054693418899570134,\n",
    " 'max_depth': int(4.0),\n",
    " 'num_leaves': int(93.0)}\n",
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")\n",
    "lgb_m_2nd = LightGBMWrapper(**params_2nd)\n",
    "lgb_m_2nd.fit(stack.transform(utils.filtrar_features(df_train_f.drop('precio', axis=1), features)), df_train_f['precio'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_mae_train = utils.MAE(y_train, lgb_m_2nd.predict(stack.transform(x_train)))\n",
    "keras_mae_test = utils.MAE(y_test, lgb_m_2nd.predict(stack.transform(x_test)))\n",
    "print(f\"MAE Stacking (train): {keras_mae_train:.5f}\")\n",
    "print(f\"MAE Stacking (test): {keras_mae_test:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test_f = stack.transform(utils.filtrar_features(df_test_f, features))\n",
    "y_pred_test_f = lgb_m_2nd.predict(s_test_f)\n",
    "df_test_f['target'] = y_pred_test_f\n",
    "df_test_f[['id', 'target']].to_csv('respuesta21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['stack01', 'stack02', 'stack03']\n",
    "\n",
    "def eval_lightgbm(args):\n",
    "    num_leaves, learning_rate, feature_fraction, bagging_fraction, bagging_freq, max_depth = args\n",
    "\n",
    "    lgb_train = lgb.Dataset(s_train, y_train)\n",
    "#     lgb_eval = lgb.Dataset(s_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    num_leaves = int(num_leaves)\n",
    "    bagging_freq = int(bagging_freq)\n",
    "    max_depth = int(max_depth)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae'}, # Si se deja vacio se toma el ideal para llegar al 'objective'\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'max_depth': max_depth,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "#                     valid_sets=lgb_eval,\n",
    "                    num_boost_round=250,\n",
    "#                     early_stopping_rounds=15,\n",
    "                    verbose_eval=-1)\n",
    "    \n",
    "    y_pred_test = gbm.predict(s_test, num_iteration=gbm.best_iteration)\n",
    "    return utils.MAE(y_test, y_pred_test)\n",
    "\n",
    "space = [hp.quniform('num_leaves', 30, 130, 1), hp.uniform('learning_rate', 0.05, 0.9),\n",
    "        hp.uniform('feature_fraction', 0.10, 0.90), hp.uniform('bagging_fraction', 0.10, 0.90),\n",
    "        hp.quniform('bagging_freq', 1, 130, 1), hp.quniform('max_depth', 1, 20, 1)]\n",
    "\n",
    "hps = fmin(eval_lightgbm, space=space, algo=tpe.suggest, max_evals=100, verbose=1)\n",
    "\n",
    "display(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# keras_mae_train = utils.MAE(y_test, lgb_m.predict(x_test_s))\n",
    "# print(f\"MAE Keras (train): {keras_mae_train:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
